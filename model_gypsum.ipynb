{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.layers import Activation, Dropout, Dense, Input, Add, Multiply, Concatenate,Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D,  Flatten, Dot,Reshape\n",
    "from keras.models import Model\n",
    "import random, time, os\n",
    "import numpy as np\n",
    "from keras import losses\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def create_sample_size_dataset(all_ipds, sample_size, n_sample):\n",
    "    #number_of_samples = int(len(all_ipds) / sample_size)\n",
    "    all_samples = []\n",
    "    for p in range(n_sample):\n",
    "        all_samples.append(all_ipds[p * sample_size:(p + 1) * sample_size])\n",
    "    return all_samples\n",
    "\n",
    "def write_array_to_file(array, target, delimiter):\n",
    "    for k in range(0, len(array)):\n",
    "        target.write(str(array[k]) + delimiter)\n",
    "    target.write(\"\\n\")\n",
    "\n",
    "def read_from_file(path):\n",
    "    with open(path, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        return content\n",
    "\n",
    "\n",
    "def create_ipd_dataset(address):\n",
    "    files = os.listdir(address)\n",
    "    all_ipds = []\n",
    "    for f in files:\n",
    "            ipd = read_from_file(address + f).split(' ')\n",
    "            all_ipds.extend(convert_stringArrays_to_floatArray(ipd))\n",
    "    return all_ipds\n",
    "\n",
    "\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def convert_stringArrays_to_floatArray(array):\n",
    "    intArray = []\n",
    "\n",
    "    for k in array:\n",
    "        if isfloat(k):\n",
    "            intArray.append(float(k))\n",
    "    return intArray\n",
    "\n",
    "\n",
    "def convert_stringArrays_to_intArray(array):\n",
    "    intArray = []\n",
    "\n",
    "    for k in array:\n",
    "        if isfloat(k):\n",
    "            intArray.append(int(k))\n",
    "    return intArray\n",
    "\n",
    "def get_fingerprints_for_ipds(n_train, sample_size, alpha):\n",
    "    \n",
    "    #Previous one was all + and the largest value was 50.\n",
    "   \n",
    "    fingerprint_output = []\n",
    "    while len(fingerprint_output) < n_train:\n",
    "        finger = [random.uniform(0, 250)]\n",
    "        neg_numbers = 0\n",
    "        #np.random.laplace(0, std, sample_size)\n",
    "        finger = np.random.laplace(0, 1, sample_size)\n",
    "        for i in range(sample_size - 1):\n",
    "            #if random.randrange(0, 3) == 0:\n",
    "            '''if random.randrange(0, 2) == 1:\n",
    "                finger.append(random.uniform(0, alpha))#random.uniform(0, 10)\n",
    "            else:\n",
    "                finger.append(-1 * random.uniform(0, alpha))#\n",
    "            if sum(finger) < 0:\n",
    "                neg_numbers += 1'''\n",
    "#             else:\n",
    "#                 finger.append(0) \n",
    "        #if neg_numbers < 50:  ## this can be a hyperparameter\n",
    "        fingerprint_output.append(finger)\n",
    "    return fingerprint_output\n",
    "\n",
    "def get_keys_for_fingerprinting_data(size, key_options):\n",
    "    selected_keys = []#np.array([key_options[0]])\n",
    "#     print(selected_keys,type(selected_keys))\n",
    "    for i in range(size - 1):\n",
    "        rnd = random.randrange(0, len(key_options))\n",
    "#         print([key_options[rnd]],type(key_options[0]))\n",
    "        #selected_keys = np.concatenate((selected_keys, np.array([key_options[rnd]])))\n",
    "        selected_keys.append(np.array(key_options[rnd]))\n",
    "\n",
    "    return selected_keys\n",
    "#from bitarray import bitarray\n",
    "def get_keys_for_fingerprinting_data_BitVector(size, key_options):\n",
    "    selected_keys = []#np.array([key_options[0]])\n",
    "#     print(selected_keys,type(selected_keys))\n",
    "    for i in range(size):\n",
    "        rnd = random.randrange(0, len(key_options))\n",
    "#         print([key_options[rnd]],type(key_options[0]))\n",
    "        #selected_keys = np.concatenate((selected_keys, np.array([key_options[rnd]])))\n",
    "        selected_keys.append(bitarray(key_options[rnd]))\n",
    "    return selected_keys\n",
    "\n",
    "def get_false_true_data(X, key_options,alpha):\n",
    "    \n",
    "    training_keys_true = get_keys_for_fingerprinting_data(size=len(X), key_options=key_options)\n",
    "    #X_train_true =X# [x for x in X]\n",
    "    y_train_true = get_fingerprints_for_ipds(len(X), sample_size=len(X[0]),alpha=alpha)#,training_keys=training_keys_true)\n",
    "    \n",
    "    ####### changing true trianing to false\n",
    "    X_train = np.expand_dims(X, axis=1).reshape((-1, len(X[0]), 1))\n",
    "    y_train = np.expand_dims(y_train_true, axis=1).reshape((-1, len(X[0]), 1))\n",
    "    #training_keys = training_keys_true#,#np.expand_dims(training_keys_true, axis=1)\n",
    "    #training_keys_true = np.array(training_keys_true)\n",
    "    \n",
    "    return X_train, y_train, training_keys_true\n",
    "\n",
    "def selecting_valid_fingerprints(key_length):\n",
    "    all_keys = []\n",
    "    #address = '/home/fatemeh/MyProjects/Fingerprint/Synthetic dataset/keys/' + str(key_length) + \"/\"\n",
    "    key_i =np.zeros(key_length)\n",
    "    #keys = os.listdir(address)\n",
    "    for k in range(key_length):\n",
    "        key_i =np.zeros(key_length,dtype='int8')\n",
    "        key_i[k] = 1\n",
    "        #key_i = convert_stringArrays_to_intArray(read_from_file(address + k).split(\" \"))\n",
    "        #if key_i [0] == 1:\n",
    "         #   continue\n",
    "        all_keys.append(key_i)\n",
    "       # key_i[k]=0\n",
    "            \n",
    "    return all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([1,50,100,200,300,400,600,900], [0,0,0.4,0.98,0.96,0.9,0.89,0.88],marker='o',markersize=4)\n",
    "#plt.plot([sample_sizes, sample_1000,marker='o',markersize=4)\n",
    "plt.plot([1,50,100], [0,0,0,0],marker='o',markersize=4)\n",
    "plt.plot([100,300,600], [0,0,0,0],marker='o',markersize=4)\n",
    "\n",
    "plt.ylabel('Extraction Rate',fontsize=15)\n",
    "plt.xlabel('k_w',fontsize=15)\n",
    "plt.grid()\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "#plt.xscale('log',basex=2)\n",
    "#legend = ['Train size = 25,000','Train size = 100,000']\n",
    "plt.legend(['I_W = 1','I_W = 50','I_W = 100'],fontsize=14)#Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10271129616740617103\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16912667416545406007\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoder_decoder_conv_dense_slice_one_conv(sample_size, key_length, chunk,reg):\n",
    "    p = 0\n",
    "    Input_ipd = Input(shape=(sample_size, 1), name='input1')  # this is needed just for the decoding\n",
    "    Input_key = Input(shape=(key_length,), name='input2')#,dtype='float64')\n",
    "    fingerprint_mult = Input(shape=(chunk,), name='input3')\n",
    "    fingerprint_sub = Input(shape=(chunk,), name='input4')\n",
    "    network_noise = Input(shape=(sample_size,), name='input5')\n",
    "    \n",
    "    ipd = Flatten(name =\"ipd_flatten1\")(Input_ipd)\n",
    "    key1 = Dense(64, name='key1')(Input_key)\n",
    "    outputs = []\n",
    "    \n",
    "    quant = int(sample_size/chunk)\n",
    "    def slice(x):\n",
    "        return x[:, p * chunk:(1 + p) * chunk]\n",
    "    x_slices = []\n",
    "    for i in range(quant):\n",
    "        sliced_ipd = Lambda(slice)(ipd)\n",
    "        x_slices.append(sliced_ipd)\n",
    "        p += 1\n",
    "    p = 0\n",
    "    x_fingerprint = x_slices[0]\n",
    "    for i in range(quant):\n",
    "        #sliced_ipd = #Lambda(slice)(ipd)\n",
    "        ss = Concatenate(name = 'concat'+ str(p))([x_fingerprint, x_slices[i]]) \n",
    "        ipd1 = Dense(32,kernel_regularizer=l2(reg), name = 'dense'+ str(p))(ss)\n",
    "        batch_2 = BatchNormalization(name = 'batch'+ str(p))(ipd1)\n",
    "        relu_2 = Activation('relu', name = 'act'+ str(p))(batch_2)\n",
    "        \n",
    "        ipds_key_merge = Concatenate(name = 'concat_key_'+ str(p))([relu_2, key1])\n",
    "        dense_enc1 = Dense(64, kernel_regularizer=l2(reg), name = 'dense_enc1' + str(p))(ipds_key_merge)\n",
    "        batch_2 = BatchNormalization(name = 'batch2_'+ str(p))(dense_enc1)\n",
    "        relu_2 = Activation('relu', name = 'act2_'+ str(p))(batch_2)\n",
    "        dense_drop_enc1 = Dropout(0.3, name = 'dense_drop_enc1' + str(p))(relu_2)\n",
    "        \n",
    "        x_fingerprint_sig = Dense(chunk, kernel_regularizer=l2(reg), name = 'fingerprint_sig' + str(p), activation = 'sigmoid')(dense_drop_enc1)\n",
    "        x_fingerprint_mult = Multiply(name = 'fingerprint_mult' + str(p))([x_fingerprint_sig, fingerprint_mult])\n",
    "        x_fingerprint = Add(name = 'ipd_delay' + str(p))([x_fingerprint_mult, fingerprint_sub])\n",
    "        outputs.append(x_fingerprint)\n",
    "        p+=1\n",
    "       \n",
    "    x_fingerprint = Concatenate(name = 'fingerprint2')(outputs)\n",
    "    x_fingerprint_output = Reshape((sample_size, 1), name='fingerprint')(x_fingerprint)\n",
    "\n",
    "    x_ipd = Add(name = 'x_ipd')([x_fingerprint, ipd, network_noise])\n",
    "        \n",
    "    x_ipd_reshape = Reshape((sample_size, 1),name = 'reshape_dec')(x_ipd)\n",
    "    \n",
    "    conv_dec_2 = Conv1D(filters = 20, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_2')(x_ipd_reshape)\n",
    "    conv_batch_2 = BatchNormalization(name='conv_batch_2_dec')(conv_dec_2)\n",
    "    conv_relu_2 = Activation('relu', name='conv_relu_2_dec')(conv_batch_2)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_2_dec')(conv_relu_2)\n",
    "    max_pool_dec_2 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_2\")(conv_drop_2)\n",
    "    \n",
    "    '''\n",
    "    conv_dec_3 = Conv1D(filters = 10, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_3')(max_pool_dec_2)\n",
    "    conv_batch_3 = BatchNormalization(name='conv_batch_3_dec')(conv_dec_3)\n",
    "    conv_relu_3 = Activation('relu', name='conv_relu_3_dec')(conv_batch_3)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_3_dec')(conv_relu_3)\n",
    "    max_pool_dec_3 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_3\")(conv_drop_2)\n",
    "    \n",
    "    '''\n",
    "    max_pool_dec_3_f = Flatten(name =\"flate_max3_dec\")(max_pool_dec_2)\n",
    "\n",
    "    \n",
    "    dense_dec_1 = Dense(256, kernel_regularizer=l2(reg),name='dense_dec_1')(max_pool_dec_3_f)\n",
    "    \n",
    "    dense_batch_dec1 = BatchNormalization(name='dense_batch_dec1')(dense_dec_1)\n",
    "    dense_relu_dec1 = Activation('relu', name='dense_relu_dec1')(dense_batch_dec1)\n",
    "    dense_drop_dec1 = Dropout(0.3, name='dense_drop_dec1')(dense_relu_dec1) \n",
    "    \n",
    "    \n",
    "    dense_dec_2 = Dense(64,kernel_regularizer=l2(reg), name='dense_dec_2')(dense_relu_dec1)\n",
    "    dense_batch_dec2 = BatchNormalization(name='dense_batch_dec2')(dense_dec_2)\n",
    "    dense_relu_dec2 = Activation('relu', name='dense_relu_dec2')(dense_batch_dec2)\n",
    "    dense_drop_dec2 = Dropout(0.3, name='dense_drop_dec2')(dense_relu_dec2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    key_hat = Dense(key_length, activation='softmax', name='key_hat')(dense_drop_dec2)\n",
    "\n",
    "    return Model(inputs=[Input_ipd, Input_key, fingerprint_mult, fingerprint_sub, network_noise], outputs=[x_fingerprint_output, key_hat])#, key_hat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoder_decoder_conv_dense_slice_two_conv(sample_size, key_length, chunk,reg):\n",
    "    p = 0\n",
    "    Input_ipd = Input(shape=(sample_size, 1), name='input1')  # this is needed just for the decoding\n",
    "    Input_key = Input(shape=(key_length,), name='input2')#,dtype='float64')\n",
    "    fingerprint_mult = Input(shape=(chunk,), name='input3')\n",
    "    fingerprint_sub = Input(shape=(chunk,), name='input4')\n",
    "    network_noise = Input(shape=(sample_size,), name='input5')\n",
    "    \n",
    "    ipd = Flatten(name =\"ipd_flatten1\")(Input_ipd)\n",
    "    key1 = Dense(64, name='key1')(Input_key)\n",
    "    outputs = []\n",
    "    \n",
    "    quant = int(sample_size/chunk)\n",
    "    def slice(x):\n",
    "        return x[:, p * chunk:(1 + p) * chunk]\n",
    "    x_slices = []\n",
    "    for i in range(quant):\n",
    "        sliced_ipd = Lambda(slice)(ipd)\n",
    "        x_slices.append(sliced_ipd)\n",
    "        p += 1\n",
    "    p = 0\n",
    "    x_fingerprint = x_slices[0]\n",
    "    for i in range(quant):\n",
    "        #sliced_ipd = #Lambda(slice)(ipd)\n",
    "        ss = Concatenate(name = 'concat'+ str(p))([x_fingerprint, x_slices[i]]) \n",
    "        ipd1 = Dense(32,kernel_regularizer=l2(reg), name = 'dense'+ str(p))(ss)\n",
    "        batch_2 = BatchNormalization(name = 'batch'+ str(p))(ipd1)\n",
    "        relu_2 = Activation('relu', name = 'act'+ str(p))(batch_2)\n",
    "        \n",
    "        ipds_key_merge = Concatenate(name = 'concat_key_'+ str(p))([relu_2, key1])\n",
    "        dense_enc1 = Dense(64, kernel_regularizer=l2(reg), name = 'dense_enc1' + str(p))(ipds_key_merge)\n",
    "        batch_2 = BatchNormalization(name = 'batch2_'+ str(p))(dense_enc1)\n",
    "        relu_2 = Activation('relu', name = 'act2_'+ str(p))(batch_2)\n",
    "        dense_drop_enc1 = Dropout(0.3, name = 'dense_drop_enc1' + str(p))(relu_2)\n",
    "        \n",
    "        x_fingerprint_sig = Dense(chunk, kernel_regularizer=l2(reg), name = 'fingerprint_sig' + str(p), activation = 'sigmoid')(dense_drop_enc1)\n",
    "        x_fingerprint_mult = Multiply(name = 'fingerprint_mult' + str(p))([x_fingerprint_sig, fingerprint_mult])\n",
    "        x_fingerprint = Add(name = 'ipd_delay' + str(p))([x_fingerprint_mult, fingerprint_sub])\n",
    "        outputs.append(x_fingerprint)\n",
    "        p+=1\n",
    "       \n",
    "    x_fingerprint = Concatenate(name = 'fingerprint2')(outputs)\n",
    "    x_fingerprint_output = Reshape((sample_size, 1), name='fingerprint')(x_fingerprint)\n",
    "\n",
    "    x_ipd = Add(name = 'x_ipd')([x_fingerprint, ipd, network_noise])\n",
    "        \n",
    "    x_ipd_reshape = Reshape((sample_size, 1),name = 'reshape_dec')(x_ipd)\n",
    "    \n",
    "    conv_dec_2 = Conv1D(filters = 20, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_2')(x_ipd_reshape)\n",
    "    conv_batch_2 = BatchNormalization(name='conv_batch_2_dec')(conv_dec_2)\n",
    "    conv_relu_2 = Activation('relu', name='conv_relu_2_dec')(conv_batch_2)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_2_dec')(conv_relu_2)\n",
    "    max_pool_dec_2 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_2\")(conv_drop_2)\n",
    "    \n",
    "    \n",
    "    conv_dec_3 = Conv1D(filters = 10, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_3')(max_pool_dec_2)\n",
    "    conv_batch_3 = BatchNormalization(name='conv_batch_3_dec')(conv_dec_3)\n",
    "    conv_relu_3 = Activation('relu', name='conv_relu_3_dec')(conv_batch_3)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_3_dec')(conv_relu_3)\n",
    "    max_pool_dec_3 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_3\")(conv_drop_2)\n",
    "    \n",
    "    \n",
    "    max_pool_dec_3_f = Flatten(name =\"flate_max3_dec\")(max_pool_dec_3)\n",
    "\n",
    "    \n",
    "    dense_dec_1 = Dense(256, kernel_regularizer=l2(reg),name='dense_dec_1')(max_pool_dec_3_f)\n",
    "    \n",
    "    dense_batch_dec1 = BatchNormalization(name='dense_batch_dec1')(dense_dec_1)\n",
    "    dense_relu_dec1 = Activation('relu', name='dense_relu_dec1')(dense_batch_dec1)\n",
    "    dense_drop_dec1 = Dropout(0.3, name='dense_drop_dec1')(dense_relu_dec1) \n",
    "    \n",
    "    \n",
    "    dense_dec_2 = Dense(64,kernel_regularizer=l2(reg), name='dense_dec_2')(dense_relu_dec1)\n",
    "    dense_batch_dec2 = BatchNormalization(name='dense_batch_dec2')(dense_dec_2)\n",
    "    dense_relu_dec2 = Activation('relu', name='dense_relu_dec2')(dense_batch_dec2)\n",
    "    dense_drop_dec2 = Dropout(0.3, name='dense_drop_dec2')(dense_relu_dec2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    key_hat = Dense(key_length, activation='softmax', name='key_hat')(dense_drop_dec2)\n",
    "\n",
    "    return Model(inputs=[Input_ipd, Input_key, fingerprint_mult, fingerprint_sub, network_noise], outputs=[x_fingerprint_output, key_hat])#, key_hat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoder_decoder_conv_dense_slice_one_dense_dec(sample_size, key_length, chunk,reg):\n",
    "    p = 0\n",
    "    Input_ipd = Input(shape=(sample_size, 1), name='input1')  # this is needed just for the decoding\n",
    "    Input_key = Input(shape=(key_length,), name='input2')#,dtype='float64')\n",
    "    fingerprint_mult = Input(shape=(chunk,), name='input3')\n",
    "    fingerprint_sub = Input(shape=(chunk,), name='input4')\n",
    "    network_noise = Input(shape=(sample_size,), name='input5')\n",
    "    \n",
    "    ipd = Flatten(name =\"ipd_flatten1\")(Input_ipd)\n",
    "    key1 = Dense(64, name='key1')(Input_key)\n",
    "    outputs = []\n",
    "    \n",
    "    quant = int(sample_size/chunk)\n",
    "    def slice(x):\n",
    "        return x[:, p * chunk:(1 + p) * chunk]\n",
    "    x_slices = []\n",
    "    for i in range(quant):\n",
    "        sliced_ipd = Lambda(slice)(ipd)\n",
    "        x_slices.append(sliced_ipd)\n",
    "        p += 1\n",
    "    p = 0\n",
    "    x_fingerprint = x_slices[0]\n",
    "    for i in range(quant):\n",
    "        #sliced_ipd = #Lambda(slice)(ipd)\n",
    "        ss = Concatenate(name = 'concat'+ str(p))([x_fingerprint, x_slices[i]]) \n",
    "        ipd1 = Dense(32,kernel_regularizer=l2(reg), name = 'dense'+ str(p))(ss)\n",
    "        batch_2 = BatchNormalization(name = 'batch'+ str(p))(ipd1)\n",
    "        relu_2 = Activation('relu', name = 'act'+ str(p))(batch_2)\n",
    "        \n",
    "        ipds_key_merge = Concatenate(name = 'concat_key_'+ str(p))([relu_2, key1])\n",
    "        dense_enc1 = Dense(64, kernel_regularizer=l2(reg), name = 'dense_enc1' + str(p))(ipds_key_merge)\n",
    "        batch_2 = BatchNormalization(name = 'batch2_'+ str(p))(dense_enc1)\n",
    "        relu_2 = Activation('relu', name = 'act2_'+ str(p))(batch_2)\n",
    "        dense_drop_enc1 = Dropout(0.3, name = 'dense_drop_enc1' + str(p))(relu_2)\n",
    "        \n",
    "        x_fingerprint_sig = Dense(chunk, kernel_regularizer=l2(reg), name = 'fingerprint_sig' + str(p), activation = 'sigmoid')(dense_drop_enc1)\n",
    "        x_fingerprint_mult = Multiply(name = 'fingerprint_mult' + str(p))([x_fingerprint_sig, fingerprint_mult])\n",
    "        x_fingerprint = Add(name = 'ipd_delay' + str(p))([x_fingerprint_mult, fingerprint_sub])\n",
    "        outputs.append(x_fingerprint)\n",
    "        p+=1\n",
    "       \n",
    "    x_fingerprint = Concatenate(name = 'fingerprint2')(outputs)\n",
    "    x_fingerprint_output = Reshape((sample_size, 1), name='fingerprint')(x_fingerprint)\n",
    "\n",
    "    x_ipd = Add(name = 'x_ipd')([x_fingerprint, ipd, network_noise])\n",
    "        \n",
    "    x_ipd_reshape = Reshape((sample_size, 1),name = 'reshape_dec')(x_ipd)\n",
    "    \n",
    "    conv_dec_2 = Conv1D(filters = 20, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_2')(x_ipd_reshape)\n",
    "    conv_batch_2 = BatchNormalization(name='conv_batch_2_dec')(conv_dec_2)\n",
    "    conv_relu_2 = Activation('relu', name='conv_relu_2_dec')(conv_batch_2)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_2_dec')(conv_relu_2)\n",
    "    max_pool_dec_2 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_2\")(conv_drop_2)\n",
    "    \n",
    "    \n",
    "    conv_dec_3 = Conv1D(filters = 10, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_3')(max_pool_dec_2)\n",
    "    conv_batch_3 = BatchNormalization(name='conv_batch_3_dec')(conv_dec_3)\n",
    "    conv_relu_3 = Activation('relu', name='conv_relu_3_dec')(conv_batch_3)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_3_dec')(conv_relu_3)\n",
    "    max_pool_dec_3 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_3\")(conv_drop_2)\n",
    "    \n",
    "    \n",
    "    max_pool_dec_3_f = Flatten(name =\"flate_max3_dec\")(max_pool_dec_3)\n",
    "\n",
    "    \n",
    "    dense_dec_1 = Dense(256, kernel_regularizer=l2(reg),name='dense_dec_1')(max_pool_dec_3_f)\n",
    "    \n",
    "    dense_batch_dec1 = BatchNormalization(name='dense_batch_dec1')(dense_dec_1)\n",
    "    dense_relu_dec1 = Activation('relu', name='dense_relu_dec1')(dense_batch_dec1)\n",
    "    dense_drop_dec1 = Dropout(0.3, name='dense_drop_dec1')(dense_relu_dec1) \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    dense_dec_2 = Dense(64,kernel_regularizer=l2(reg), name='dense_dec_2')(dense_relu_dec1)\n",
    "    dense_batch_dec2 = BatchNormalization(name='dense_batch_dec2')(dense_dec_2)\n",
    "    dense_relu_dec2 = Activation('relu', name='dense_relu_dec2')(dense_batch_dec2)\n",
    "    dense_drop_dec2 = Dropout(0.3, name='dense_drop_dec2')(dense_relu_dec2)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    key_hat = Dense(key_length, activation='softmax', name='key_hat')(dense_drop_dec1)\n",
    "\n",
    "    return Model(inputs=[Input_ipd, Input_key, fingerprint_mult, fingerprint_sub, network_noise], outputs=[x_fingerprint_output, key_hat])#, key_hat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoder_decoder_conv_dense_slice_three_dense_dec(sample_size, key_length, chunk,reg):\n",
    "    p = 0\n",
    "    Input_ipd = Input(shape=(sample_size, 1), name='input1')  # this is needed just for the decoding\n",
    "    Input_key = Input(shape=(key_length,), name='input2')#,dtype='float64')\n",
    "    fingerprint_mult = Input(shape=(chunk,), name='input3')\n",
    "    fingerprint_sub = Input(shape=(chunk,), name='input4')\n",
    "    network_noise = Input(shape=(sample_size,), name='input5')\n",
    "    \n",
    "    ipd = Flatten(name =\"ipd_flatten1\")(Input_ipd)\n",
    "    key1 = Dense(64, name='key1')(Input_key)\n",
    "    outputs = []\n",
    "    \n",
    "    quant = int(sample_size/chunk)\n",
    "    def slice(x):\n",
    "        return x[:, p * chunk:(1 + p) * chunk]\n",
    "    x_slices = []\n",
    "    for i in range(quant):\n",
    "        sliced_ipd = Lambda(slice)(ipd)\n",
    "        x_slices.append(sliced_ipd)\n",
    "        p += 1\n",
    "    p = 0\n",
    "    x_fingerprint = x_slices[0]\n",
    "    for i in range(quant):\n",
    "        #sliced_ipd = #Lambda(slice)(ipd)\n",
    "        ss = Concatenate(name = 'concat'+ str(p))([x_fingerprint, x_slices[i]]) \n",
    "        ipd1 = Dense(32,kernel_regularizer=l2(reg), name = 'dense'+ str(p))(ss)\n",
    "        batch_2 = BatchNormalization(name = 'batch'+ str(p))(ipd1)\n",
    "        relu_2 = Activation('relu', name = 'act'+ str(p))(batch_2)\n",
    "        \n",
    "        ipds_key_merge = Concatenate(name = 'concat_key_'+ str(p))([relu_2, key1])\n",
    "        dense_enc1 = Dense(64, kernel_regularizer=l2(reg), name = 'dense_enc1' + str(p))(ipds_key_merge)\n",
    "        batch_2 = BatchNormalization(name = 'batch2_'+ str(p))(dense_enc1)\n",
    "        relu_2 = Activation('relu', name = 'act2_'+ str(p))(batch_2)\n",
    "        dense_drop_enc1 = Dropout(0.3, name = 'dense_drop_enc1' + str(p))(relu_2)\n",
    "        \n",
    "        x_fingerprint_sig = Dense(chunk, kernel_regularizer=l2(reg), name = 'fingerprint_sig' + str(p), activation = 'sigmoid')(dense_drop_enc1)\n",
    "        x_fingerprint_mult = Multiply(name = 'fingerprint_mult' + str(p))([x_fingerprint_sig, fingerprint_mult])\n",
    "        x_fingerprint = Add(name = 'ipd_delay' + str(p))([x_fingerprint_mult, fingerprint_sub])\n",
    "        outputs.append(x_fingerprint)\n",
    "        p+=1\n",
    "       \n",
    "    x_fingerprint = Concatenate(name = 'fingerprint2')(outputs)\n",
    "    x_fingerprint_output = Reshape((sample_size, 1), name='fingerprint')(x_fingerprint)\n",
    "\n",
    "    x_ipd = Add(name = 'x_ipd')([x_fingerprint, ipd, network_noise])\n",
    "        \n",
    "    x_ipd_reshape = Reshape((sample_size, 1),name = 'reshape_dec')(x_ipd)\n",
    "    \n",
    "    conv_dec_2 = Conv1D(filters = 20, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_2')(x_ipd_reshape)\n",
    "    conv_batch_2 = BatchNormalization(name='conv_batch_2_dec')(conv_dec_2)\n",
    "    conv_relu_2 = Activation('relu', name='conv_relu_2_dec')(conv_batch_2)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_2_dec')(conv_relu_2)\n",
    "    max_pool_dec_2 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_2\")(conv_drop_2)\n",
    "    \n",
    "    \n",
    "    conv_dec_3 = Conv1D(filters = 10, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_3')(max_pool_dec_2)\n",
    "    conv_batch_3 = BatchNormalization(name='conv_batch_3_dec')(conv_dec_3)\n",
    "    conv_relu_3 = Activation('relu', name='conv_relu_3_dec')(conv_batch_3)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_3_dec')(conv_relu_3)\n",
    "    max_pool_dec_3 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_3\")(conv_drop_2)\n",
    "    \n",
    "    \n",
    "    max_pool_dec_3_f = Flatten(name =\"flate_max3_dec\")(max_pool_dec_3)\n",
    "\n",
    "    \n",
    "    dense_dec_1 = Dense(256, kernel_regularizer=l2(reg),name='dense_dec_1')(max_pool_dec_3_f)\n",
    "    \n",
    "    dense_batch_dec1 = BatchNormalization(name='dense_batch_dec1')(dense_dec_1)\n",
    "    dense_relu_dec1 = Activation('relu', name='dense_relu_dec1')(dense_batch_dec1)\n",
    "    dense_drop_dec1 = Dropout(0.3, name='dense_drop_dec1')(dense_relu_dec1) \n",
    "    \n",
    "    \n",
    "    \n",
    "    dense_dec_2 = Dense(64,kernel_regularizer=l2(reg), name='dense_dec_2')(dense_relu_dec1)\n",
    "    dense_batch_dec2 = BatchNormalization(name='dense_batch_dec2')(dense_dec_2)\n",
    "    dense_relu_dec2 = Activation('relu', name='dense_relu_dec2')(dense_batch_dec2)\n",
    "    dense_drop_dec2 = Dropout(0.3, name='dense_drop_dec2')(dense_relu_dec2)\n",
    "    \n",
    "    dense_dec_3 = Dense(512,kernel_regularizer=l2(reg), name='dense_dec_3')(dense_drop_dec2)\n",
    "    dense_batch_dec3 = BatchNormalization(name='dense_batch_dec3')(dense_dec_3)\n",
    "    dense_relu_dec3 = Activation('relu', name='dense_relu_dec3')(dense_batch_dec3)\n",
    "    dense_drop_dec3 = Dropout(0.3, name='dense_drop_dec3')(dense_relu_dec3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    key_hat = Dense(key_length, activation='softmax', name='key_hat')(dense_drop_dec3)\n",
    "\n",
    "    return Model(inputs=[Input_ipd, Input_key, fingerprint_mult, fingerprint_sub, network_noise], outputs=[x_fingerprint_output, key_hat])#, key_hat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoder_decoder_conv_dense_slice_zero_dense_dec(sample_size, key_length, chunk,reg):\n",
    "    p = 0\n",
    "    Input_ipd = Input(shape=(sample_size, 1), name='input1')  # this is needed just for the decoding\n",
    "    Input_key = Input(shape=(key_length,), name='input2')#,dtype='float64')\n",
    "    fingerprint_mult = Input(shape=(chunk,), name='input3')\n",
    "    fingerprint_sub = Input(shape=(chunk,), name='input4')\n",
    "    network_noise = Input(shape=(sample_size,), name='input5')\n",
    "    \n",
    "    ipd = Flatten(name =\"ipd_flatten1\")(Input_ipd)\n",
    "    key1 = Dense(64, name='key1')(Input_key)\n",
    "    outputs = []\n",
    "    \n",
    "    quant = int(sample_size/chunk)\n",
    "    def slice(x):\n",
    "        return x[:, p * chunk:(1 + p) * chunk]\n",
    "    x_slices = []\n",
    "    for i in range(quant):\n",
    "        sliced_ipd = Lambda(slice)(ipd)\n",
    "        x_slices.append(sliced_ipd)\n",
    "        p += 1\n",
    "    p = 0\n",
    "    x_fingerprint = x_slices[0]\n",
    "    for i in range(quant):\n",
    "        #sliced_ipd = #Lambda(slice)(ipd)\n",
    "        ss = Concatenate(name = 'concat'+ str(p))([x_fingerprint, x_slices[i]]) \n",
    "        ipd1 = Dense(32,kernel_regularizer=l2(reg), name = 'dense'+ str(p))(ss)\n",
    "        batch_2 = BatchNormalization(name = 'batch'+ str(p))(ipd1)\n",
    "        relu_2 = Activation('relu', name = 'act'+ str(p))(batch_2)\n",
    "        \n",
    "        ipds_key_merge = Concatenate(name = 'concat_key_'+ str(p))([relu_2, key1])\n",
    "        dense_enc1 = Dense(64, kernel_regularizer=l2(reg), name = 'dense_enc1' + str(p))(ipds_key_merge)\n",
    "        batch_2 = BatchNormalization(name = 'batch2_'+ str(p))(dense_enc1)\n",
    "        relu_2 = Activation('relu', name = 'act2_'+ str(p))(batch_2)\n",
    "        dense_drop_enc1 = Dropout(0.3, name = 'dense_drop_enc1' + str(p))(relu_2)\n",
    "        \n",
    "        x_fingerprint_sig = Dense(chunk, kernel_regularizer=l2(reg), name = 'fingerprint_sig' + str(p), activation = 'sigmoid')(dense_drop_enc1)\n",
    "        x_fingerprint_mult = Multiply(name = 'fingerprint_mult' + str(p))([x_fingerprint_sig, fingerprint_mult])\n",
    "        x_fingerprint = Add(name = 'ipd_delay' + str(p))([x_fingerprint_mult, fingerprint_sub])\n",
    "        outputs.append(x_fingerprint)\n",
    "        p+=1\n",
    "       \n",
    "    x_fingerprint = Concatenate(name = 'fingerprint2')(outputs)\n",
    "    x_fingerprint_output = Reshape((sample_size, 1), name='fingerprint')(x_fingerprint)\n",
    "\n",
    "    x_ipd = Add(name = 'x_ipd')([x_fingerprint, ipd, network_noise])\n",
    "        \n",
    "    x_ipd_reshape = Reshape((sample_size, 1),name = 'reshape_dec')(x_ipd)\n",
    "    \n",
    "    conv_dec_2 = Conv1D(filters = 20, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_2')(x_ipd_reshape)\n",
    "    conv_batch_2 = BatchNormalization(name='conv_batch_2_dec')(conv_dec_2)\n",
    "    conv_relu_2 = Activation('relu', name='conv_relu_2_dec')(conv_batch_2)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_2_dec')(conv_relu_2)\n",
    "    max_pool_dec_2 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_2\")(conv_drop_2)\n",
    "    \n",
    "    \n",
    "    conv_dec_3 = Conv1D(filters = 10, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_3')(max_pool_dec_2)\n",
    "    conv_batch_3 = BatchNormalization(name='conv_batch_3_dec')(conv_dec_3)\n",
    "    conv_relu_3 = Activation('relu', name='conv_relu_3_dec')(conv_batch_3)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_3_dec')(conv_relu_3)\n",
    "    max_pool_dec_3 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_3\")(conv_drop_2)\n",
    "    \n",
    "    \n",
    "    max_pool_dec_3_f = Flatten(name =\"flate_max3_dec\")(max_pool_dec_3)\n",
    "\n",
    "    \n",
    "    '''dense_dec_1 = Dense(256, kernel_regularizer=l2(reg),name='dense_dec_1')(max_pool_dec_3_f)\n",
    "    \n",
    "    dense_batch_dec1 = BatchNormalization(name='dense_batch_dec1')(dense_dec_1)\n",
    "    dense_relu_dec1 = Activation('relu', name='dense_relu_dec1')(dense_batch_dec1)\n",
    "    dense_drop_dec1 = Dropout(0.3, name='dense_drop_dec1')(dense_relu_dec1) \n",
    "    \n",
    "    \n",
    "    \n",
    "    dense_dec_2 = Dense(64,kernel_regularizer=l2(reg), name='dense_dec_2')(dense_relu_dec1)\n",
    "    dense_batch_dec2 = BatchNormalization(name='dense_batch_dec2')(dense_dec_2)\n",
    "    dense_relu_dec2 = Activation('relu', name='dense_relu_dec2')(dense_batch_dec2)\n",
    "    dense_drop_dec2 = Dropout(0.3, name='dense_drop_dec2')(dense_relu_dec2)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    key_hat = Dense(key_length, activation='softmax', name='key_hat')(max_pool_dec_3_f)\n",
    "\n",
    "    return Model(inputs=[Input_ipd, Input_key, fingerprint_mult, fingerprint_sub, network_noise], outputs=[x_fingerprint_output, key_hat])#, key_hat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoder_decoder_conv_dense_slice_zero_conv(sample_size, key_length, chunk,reg):\n",
    "    p = 0\n",
    "    Input_ipd = Input(shape=(sample_size, 1), name='input1')  # this is needed just for the decoding\n",
    "    Input_key = Input(shape=(key_length,), name='input2')#,dtype='float64')\n",
    "    fingerprint_mult = Input(shape=(chunk,), name='input3')\n",
    "    fingerprint_sub = Input(shape=(chunk,), name='input4')\n",
    "    network_noise = Input(shape=(sample_size,), name='input5')\n",
    "    \n",
    "    ipd = Flatten(name =\"ipd_flatten1\")(Input_ipd)\n",
    "    key1 = Dense(64, name='key1')(Input_key)\n",
    "    outputs = []\n",
    "    \n",
    "    quant = int(sample_size/chunk)\n",
    "    def slice(x):\n",
    "        return x[:, p * chunk:(1 + p) * chunk]\n",
    "    x_slices = []\n",
    "    for i in range(quant):\n",
    "        sliced_ipd = Lambda(slice)(ipd)\n",
    "        x_slices.append(sliced_ipd)\n",
    "        p += 1\n",
    "    p = 0\n",
    "    x_fingerprint = x_slices[0]\n",
    "    for i in range(quant):\n",
    "        #sliced_ipd = #Lambda(slice)(ipd)\n",
    "        ss = Concatenate(name = 'concat'+ str(p))([x_fingerprint, x_slices[i]]) \n",
    "        ipd1 = Dense(32,kernel_regularizer=l2(reg), name = 'dense'+ str(p))(ss)\n",
    "        batch_2 = BatchNormalization(name = 'batch'+ str(p))(ipd1)\n",
    "        relu_2 = Activation('relu', name = 'act'+ str(p))(batch_2)\n",
    "        \n",
    "        ipds_key_merge = Concatenate(name = 'concat_key_'+ str(p))([relu_2, key1])\n",
    "        dense_enc1 = Dense(64, kernel_regularizer=l2(reg), name = 'dense_enc1' + str(p))(ipds_key_merge)\n",
    "        batch_2 = BatchNormalization(name = 'batch2_'+ str(p))(dense_enc1)\n",
    "        relu_2 = Activation('relu', name = 'act2_'+ str(p))(batch_2)\n",
    "        dense_drop_enc1 = Dropout(0.3, name = 'dense_drop_enc1' + str(p))(relu_2)\n",
    "        \n",
    "        x_fingerprint_sig = Dense(chunk, kernel_regularizer=l2(reg), name = 'fingerprint_sig' + str(p), activation = 'sigmoid')(dense_drop_enc1)\n",
    "        x_fingerprint_mult = Multiply(name = 'fingerprint_mult' + str(p))([x_fingerprint_sig, fingerprint_mult])\n",
    "        x_fingerprint = Add(name = 'ipd_delay' + str(p))([x_fingerprint_mult, fingerprint_sub])\n",
    "        outputs.append(x_fingerprint)\n",
    "        p+=1\n",
    "       \n",
    "    x_fingerprint = Concatenate(name = 'fingerprint2')(outputs)\n",
    "    x_fingerprint_output = Reshape((sample_size, 1), name='fingerprint')(x_fingerprint)\n",
    "\n",
    "    x_ipd = Add(name = 'x_ipd')([x_fingerprint, ipd, network_noise])\n",
    "        \n",
    "    x_ipd_reshape = Reshape((sample_size, 1),name = 'reshape_dec')(x_ipd)\n",
    "    \n",
    "   \n",
    "    max_pool_dec_3_f = Flatten(name =\"flate_max3_dec\")(x_ipd_reshape)\n",
    "\n",
    "    \n",
    "    dense_dec_1 = Dense(256, kernel_regularizer=l2(reg),name='dense_dec_1')(max_pool_dec_3_f)\n",
    "    \n",
    "    dense_batch_dec1 = BatchNormalization(name='dense_batch_dec1')(dense_dec_1)\n",
    "    dense_relu_dec1 = Activation('relu', name='dense_relu_dec1')(dense_batch_dec1)\n",
    "    dense_drop_dec1 = Dropout(0.3, name='dense_drop_dec1')(dense_relu_dec1) \n",
    "    \n",
    "    \n",
    "    dense_dec_2 = Dense(64,kernel_regularizer=l2(reg), name='dense_dec_2')(dense_relu_dec1)\n",
    "    dense_batch_dec2 = BatchNormalization(name='dense_batch_dec2')(dense_dec_2)\n",
    "    dense_relu_dec2 = Activation('relu', name='dense_relu_dec2')(dense_batch_dec2)\n",
    "    dense_drop_dec2 = Dropout(0.3, name='dense_drop_dec2')(dense_relu_dec2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    key_hat = Dense(key_length, activation='softmax', name='key_hat')(dense_drop_dec2)\n",
    "\n",
    "    return Model(inputs=[Input_ipd, Input_key, fingerprint_mult, fingerprint_sub, network_noise], outputs=[x_fingerprint_output, key_hat])#, key_hat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoder_decoder_conv_dense_slice_one_dense(sample_size, key_length, chunk,reg):\n",
    "    p = 0\n",
    "    Input_ipd = Input(shape=(sample_size, 1), name='input1')  # this is needed just for the decoding\n",
    "    Input_key = Input(shape=(key_length,), name='input2')#,dtype='float64')\n",
    "    fingerprint_mult = Input(shape=(chunk,), name='input3')\n",
    "    fingerprint_sub = Input(shape=(chunk,), name='input4')\n",
    "    network_noise = Input(shape=(sample_size,), name='input5')\n",
    "    \n",
    "    ipd = Flatten(name =\"ipd_flatten1\")(Input_ipd)\n",
    "    key1 = Dense(64, name='key1')(Input_key)\n",
    "    outputs = []\n",
    "    \n",
    "    quant = int(sample_size/chunk)\n",
    "    def slice(x):\n",
    "        return x[:, p * chunk:(1 + p) * chunk]\n",
    "    x_slices = []\n",
    "    for i in range(quant):\n",
    "        sliced_ipd = Lambda(slice)(ipd)\n",
    "        x_slices.append(sliced_ipd)\n",
    "        p += 1\n",
    "    p = 0\n",
    "    x_fingerprint = x_slices[0]\n",
    "    for i in range(quant):\n",
    "        #sliced_ipd = #Lambda(slice)(ipd)\n",
    "        ss = Concatenate(name = 'concat'+ str(p))([x_fingerprint, x_slices[i]]) \n",
    "        ipd1 = Dense(32,kernel_regularizer=l2(reg), name = 'dense'+ str(p))(ss)\n",
    "        batch_2 = BatchNormalization(name = 'batch'+ str(p))(ipd1)\n",
    "        relu_2 = Activation('relu', name = 'act'+ str(p))(batch_2)\n",
    "        \n",
    "        ipds_key_merge = Concatenate(name = 'concat_key_'+ str(p))([relu_2, key1])\n",
    "        '''\n",
    "        dense_enc1 = Dense(64, kernel_regularizer=l2(reg), name = 'dense_enc1' + str(p))(ipds_key_merge)\n",
    "        batch_2 = BatchNormalization(name = 'batch2_'+ str(p))(dense_enc1)\n",
    "        relu_2 = Activation('relu', name = 'act2_'+ str(p))(batch_2)\n",
    "        dense_drop_enc1 = Dropout(0.3, name = 'dense_drop_enc1' + str(p))(relu_2)\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        x_fingerprint_sig = Dense(chunk, kernel_regularizer=l2(reg), name = 'fingerprint_sig' + str(p), activation = 'sigmoid')(ipds_key_merge)\n",
    "        x_fingerprint_mult = Multiply(name = 'fingerprint_mult' + str(p))([x_fingerprint_sig, fingerprint_mult])\n",
    "        x_fingerprint = Add(name = 'ipd_delay' + str(p))([x_fingerprint_mult, fingerprint_sub])\n",
    "        outputs.append(x_fingerprint)\n",
    "        p+=1\n",
    "       \n",
    "    x_fingerprint = Concatenate(name = 'fingerprint2')(outputs)\n",
    "    x_fingerprint_output = Reshape((sample_size, 1), name='fingerprint')(x_fingerprint)\n",
    "\n",
    "    x_ipd = Add(name = 'x_ipd')([x_fingerprint, ipd, network_noise])\n",
    "        \n",
    "    x_ipd_reshape = Reshape((sample_size, 1),name = 'reshape_dec')(x_ipd)\n",
    "    \n",
    "    conv_dec_2 = Conv1D(filters = 20, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_2')(x_ipd_reshape)\n",
    "    conv_batch_2 = BatchNormalization(name='conv_batch_2_dec')(conv_dec_2)\n",
    "    conv_relu_2 = Activation('relu', name='conv_relu_2_dec')(conv_batch_2)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_2_dec')(conv_relu_2)\n",
    "    max_pool_dec_2 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_2\")(conv_drop_2)\n",
    "    \n",
    "    \n",
    "    conv_dec_3 = Conv1D(filters = 10, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_3')(max_pool_dec_2)\n",
    "    conv_batch_3 = BatchNormalization(name='conv_batch_3_dec')(conv_dec_3)\n",
    "    conv_relu_3 = Activation('relu', name='conv_relu_3_dec')(conv_batch_3)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_3_dec')(conv_relu_3)\n",
    "    max_pool_dec_3 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_3\")(conv_drop_2)\n",
    "    \n",
    "    \n",
    "    max_pool_dec_3_f = Flatten(name =\"flate_max3_dec\")(max_pool_dec_3)\n",
    "\n",
    "    \n",
    "    dense_dec_1 = Dense(256, kernel_regularizer=l2(reg),name='dense_dec_1')(max_pool_dec_3_f)\n",
    "    \n",
    "    dense_batch_dec1 = BatchNormalization(name='dense_batch_dec1')(dense_dec_1)\n",
    "    dense_relu_dec1 = Activation('relu', name='dense_relu_dec1')(dense_batch_dec1)\n",
    "    dense_drop_dec1 = Dropout(0.3, name='dense_drop_dec1')(dense_relu_dec1) \n",
    "    \n",
    "    \n",
    "    dense_dec_2 = Dense(64,kernel_regularizer=l2(reg), name='dense_dec_2')(dense_relu_dec1)\n",
    "    dense_batch_dec2 = BatchNormalization(name='dense_batch_dec2')(dense_dec_2)\n",
    "    dense_relu_dec2 = Activation('relu', name='dense_relu_dec2')(dense_batch_dec2)\n",
    "    dense_drop_dec2 = Dropout(0.3, name='dense_drop_dec2')(dense_relu_dec2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    key_hat = Dense(key_length, activation='softmax', name='key_hat')(dense_drop_dec2)\n",
    "\n",
    "    return Model(inputs=[Input_ipd, Input_key, fingerprint_mult, fingerprint_sub, network_noise], outputs=[x_fingerprint_output, key_hat])#, key_hat])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_extract_rate(keys, true_keys):\n",
    "    correct = 0 \n",
    "    for i in range(len(keys)): \n",
    "        if np.argmax(keys[i]) == np.argmax(true_keys[i]):\n",
    "            correct +=1\n",
    "    return correct/float(len(keys))\n",
    "\n",
    "def get_mult_sub_for_fingerprinting(n_data, max_delay, chunk, sample_size):\n",
    "    array_mult, array_sub = [], []\n",
    "    for x in range(0, n_data):\n",
    "        array_mult.append([max_delay] * chunk)\n",
    "        array_sub.append([-max_delay/2] * chunk)\n",
    "    array_mult = np.array(array_mult)\n",
    "    array_sub = np.array(array_sub)\n",
    "    return array_mult, array_sub\n",
    "\n",
    "def get_noise_simulation_array(n_data, std, sample_size):\n",
    "    noise = []\n",
    "    for x in range(0, n_data):\n",
    "        #noise.append(np.random.normal(0, std, sample_size))\n",
    "        #noise.append(np.random.uniform(0, std, sample_size))\n",
    "        noise.append(np.random.laplace(0, std, sample_size));\n",
    "    noise = np.array(noise)\n",
    "    return noise\n",
    "def mean_pred_loss(y_true, y_pred):\n",
    "    #when the coeficent is smaller, performance is better. When increasing, noise improves\n",
    "    sum_abs = K.abs(y_pred)\n",
    "    tmp =  K.mean(sum_abs) - 0.3 * K.mean(y_pred)# + K.epsilon()\n",
    "    return 100 * (K.abs(K.mean(y_pred)))# 1/tmp  keras.losses.mean_absolute_error(y_true, y_pred) + \n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/home/fatemeh/MyProjects/Fingerprint/models/\"\n",
    "rate = '10'\n",
    "all_ipds_for_test = create_ipd_dataset(\n",
    "    address='/home/fatemeh/MyProjects/Fingerprint/Synthetic dataset/in/' + rate + '/test/')\n",
    "all_ipds_for_train = create_ipd_dataset(\n",
    "    address='/home/fatemeh/MyProjects/Fingerprint/Synthetic dataset/in/' + rate + '/train/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_diff(str1,str2):\n",
    "   \n",
    "    str22 = \"\"\n",
    "    if len(str1)>len(str2):\n",
    "        for i in range(len(str1)-len(str2)):\n",
    "            str22+='0'\n",
    "    str22+=str2\n",
    "    str11 = \"\"\n",
    "    if len(str2)>len(str1):\n",
    "        for i in range(len(str2)-len(str1)):\n",
    "            str11 += '0'\n",
    "    str11 += str1\n",
    "    leng = len(str11)\n",
    "    diff = 0\n",
    "    #print(leng, len(str22),str22, str11)\n",
    "    for i in range(leng):\n",
    "        if str11[i] != str22[i]:\n",
    "            diff+=1\n",
    "    \n",
    "    return diff\n",
    "def bit_rate_error(ext_keys, true_keys,key_bin_size):\n",
    "    error_bits = 0\n",
    "    all_bits = 0\n",
    "    for f in range(len(ext_keys)):\n",
    "        ext = bin(np.argmax(ext_keys[f]))[2:]\n",
    "        tru = bin(np.argmax(true_keys[f]))[2:]\n",
    "        \n",
    "        error_bits += compute_diff(ext,tru)\n",
    "        all_bits += key_bin_size\n",
    "    return error_bits/float(all_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 5000 Numbre of training and testing data\n"
     ]
    }
   ],
   "source": [
    "n_true_train, n_test = 100000, 5000\n",
    "sample_size= 400#*32#* 32\n",
    "\n",
    "X_train_all = create_sample_size_dataset(all_ipds_for_train, sample_size = sample_size,n_sample=n_true_train)\n",
    "X_test_all = create_sample_size_dataset(all_ipds_for_test, sample_size = sample_size,n_sample=n_test)\n",
    "print(len(X_train_all), len(X_test_all), \"Numbre of training and testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise and subtract and multiply arrays are built!...\n",
      "2.5301716327667236\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "alpha, chunk = 25, 10\n",
    "std, max_fing_delay = 1, alpha\n",
    "array_mult_test, array_sub_test = get_mult_sub_for_fingerprinting(n_test, max_delay=max_fing_delay, chunk=chunk,\n",
    "                                                                  sample_size=sample_size)\n",
    "noise_for_test = get_noise_simulation_array(n_test, std=std, sample_size=sample_size)\n",
    "array_mult_train, array_sub_train = get_mult_sub_for_fingerprinting(n_true_train, max_delay=max_fing_delay, chunk=chunk,\n",
    "                                                                    sample_size=sample_size)\n",
    "noise_for_train = get_noise_simulation_array(n_true_train, std=std, sample_size=sample_size)\n",
    "print(\"Noise and subtract and multiply arrays are built!...\")\n",
    "\n",
    "key_length  = 1024#*32#1024*16\n",
    "beg = time.time()\n",
    "key_options = selecting_valid_fingerprints(key_length = key_length)\n",
    "X_train, y_train, train_keys = get_false_true_data(X_train_all, key_options, alpha=alpha)#get_only_true_data\n",
    "print(time.time() - beg)\n",
    "train_keys = np.array(train_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date :  2019-12-02 20:50:07.434451\n",
      "Model 24999 is Built and Compiled in 6.941010\n",
      "Train on 22499 samples, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "22499/22499 [==============================] - 26s 1ms/step - loss: 1399.7016 - fingerprint_loss: 5.5400 - key_hat_loss: 6.9708 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 8.8893e-04 - val_loss: 1389.3277 - val_fingerprint_loss: 1.5127 - val_key_hat_loss: 6.9391 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 8.0000e-04\n",
      "Epoch 2/100\n",
      "22499/22499 [==============================] - 10s 425us/step - loss: 1385.1557 - fingerprint_loss: 3.0016 - key_hat_loss: 6.9108 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0020 - val_loss: 1392.6135 - val_fingerprint_loss: 2.2288 - val_key_hat_loss: 6.9519 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "22499/22499 [==============================] - 9s 421us/step - loss: 1377.1210 - fingerprint_loss: 2.6754 - key_hat_loss: 6.8722 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0024 - val_loss: 1394.4130 - val_fingerprint_loss: 0.8733 - val_key_hat_loss: 6.9677 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 8.0000e-04\n",
      "Epoch 4/100\n",
      "22499/22499 [==============================] - 10s 456us/step - loss: 1369.8464 - fingerprint_loss: 1.9136 - key_hat_loss: 6.8396 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0030 - val_loss: 1397.8616 - val_fingerprint_loss: 2.0667 - val_key_hat_loss: 6.9790 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 4.0000e-04\n",
      "Epoch 5/100\n",
      "22499/22499 [==============================] - 10s 431us/step - loss: 1363.4262 - fingerprint_loss: 4.0192 - key_hat_loss: 6.7970 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0042 - val_loss: 1399.6912 - val_fingerprint_loss: 0.6447 - val_key_hat_loss: 6.9952 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 6/100\n",
      "22499/22499 [==============================] - 10s 431us/step - loss: 1353.8191 - fingerprint_loss: 2.0208 - key_hat_loss: 6.7590 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0059 - val_loss: 1399.6792 - val_fingerprint_loss: 0.5565 - val_key_hat_loss: 6.9956 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 7/100\n",
      "22499/22499 [==============================] - 9s 416us/step - loss: 1344.8810 - fingerprint_loss: 2.3854 - key_hat_loss: 6.7125 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0077 - val_loss: 1402.0905 - val_fingerprint_loss: 1.1482 - val_key_hat_loss: 7.0047 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 8/100\n",
      "22499/22499 [==============================] - 9s 419us/step - loss: 1335.4808 - fingerprint_loss: 2.6739 - key_hat_loss: 6.6640 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0087 - val_loss: 1404.4382 - val_fingerprint_loss: 0.8562 - val_key_hat_loss: 7.0179 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 9/100\n",
      "22499/22499 [==============================] - 9s 403us/step - loss: 1325.0689 - fingerprint_loss: 3.5844 - key_hat_loss: 6.6074 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0118 - val_loss: 1406.0480 - val_fingerprint_loss: 0.7769 - val_key_hat_loss: 7.0263 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0016\n",
      "Epoch 10/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 1313.3215 - fingerprint_loss: 3.5295 - key_hat_loss: 6.5489 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0123 - val_loss: 1406.9699 - val_fingerprint_loss: 0.7346 - val_key_hat_loss: 7.0312 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 11/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 1299.7314 - fingerprint_loss: 2.8637 - key_hat_loss: 6.4843 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0160 - val_loss: 1409.3585 - val_fingerprint_loss: 1.1632 - val_key_hat_loss: 7.0410 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0020\n",
      "Epoch 12/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 1285.0167 - fingerprint_loss: 3.3653 - key_hat_loss: 6.4082 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0191 - val_loss: 1412.6885 - val_fingerprint_loss: 0.7564 - val_key_hat_loss: 7.0596 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0016\n",
      "Epoch 13/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 1268.3307 - fingerprint_loss: 2.1164 - key_hat_loss: 6.3311 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0227 - val_loss: 1415.1233 - val_fingerprint_loss: 0.9214 - val_key_hat_loss: 7.0710 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0020\n",
      "Epoch 14/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 1252.3359 - fingerprint_loss: 3.0706 - key_hat_loss: 6.2463 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0275 - val_loss: 1417.6127 - val_fingerprint_loss: 1.1564 - val_key_hat_loss: 7.0823 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 15/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 1234.9420 - fingerprint_loss: 3.1208 - key_hat_loss: 6.1591 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0334 - val_loss: 1422.5877 - val_fingerprint_loss: 3.9256 - val_key_hat_loss: 7.0933 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0016\n",
      "Epoch 16/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 1214.1819 - fingerprint_loss: 2.0020 - key_hat_loss: 6.0609 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0366 - val_loss: 1420.1288 - val_fingerprint_loss: 0.9514 - val_key_hat_loss: 7.0959 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 17/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 1193.2013 - fingerprint_loss: 2.7041 - key_hat_loss: 5.9525 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0430 - val_loss: 1419.1573 - val_fingerprint_loss: 3.5549 - val_key_hat_loss: 7.0780 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0028\n",
      "Epoch 18/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 1167.8851 - fingerprint_loss: 4.4854 - key_hat_loss: 5.8170 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0522 - val_loss: 1416.9518 - val_fingerprint_loss: 4.1681 - val_key_hat_loss: 7.0639 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0028\n",
      "Epoch 19/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 1137.1720 - fingerprint_loss: 2.1459 - key_hat_loss: 5.6751 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0624 - val_loss: 1406.3557 - val_fingerprint_loss: 3.1232 - val_key_hat_loss: 7.0161 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0016\n",
      "Epoch 20/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 1106.1460 - fingerprint_loss: 2.5707 - key_hat_loss: 5.5179 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0716 - val_loss: 1395.9237 - val_fingerprint_loss: 1.3930 - val_key_hat_loss: 6.9726 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0024\n",
      "Epoch 21/100\n",
      "22499/22499 [==============================] - 9s 407us/step - loss: 1075.8280 - fingerprint_loss: 1.7696 - key_hat_loss: 5.3703 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0816 - val_loss: 1384.2542 - val_fingerprint_loss: 1.5198 - val_key_hat_loss: 6.9137 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0040\n",
      "Epoch 22/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 1043.4919 - fingerprint_loss: 2.1673 - key_hat_loss: 5.2066 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0896 - val_loss: 1368.8668 - val_fingerprint_loss: 1.0735 - val_key_hat_loss: 6.8389 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0056\n",
      "Epoch 23/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 1008.9736 - fingerprint_loss: 1.8182 - key_hat_loss: 5.0358 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.1113 - val_loss: 1351.7373 - val_fingerprint_loss: 2.2039 - val_key_hat_loss: 6.7476 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0048\n",
      "Epoch 24/100\n",
      "22499/22499 [==============================] - 9s 402us/step - loss: 977.9715 - fingerprint_loss: 2.0636 - key_hat_loss: 4.8795 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.1183 - val_loss: 1326.5018 - val_fingerprint_loss: 0.9620 - val_key_hat_loss: 6.6277 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0052\n",
      "Epoch 25/100\n",
      "22499/22499 [==============================] - 9s 402us/step - loss: 944.4766 - fingerprint_loss: 1.7459 - key_hat_loss: 4.7136 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.1326 - val_loss: 1291.8070 - val_fingerprint_loss: 3.4713 - val_key_hat_loss: 6.4416 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0104\n",
      "Epoch 26/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 905.7700 - fingerprint_loss: 3.0213 - key_hat_loss: 4.5137 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.1557 - val_loss: 1251.7899 - val_fingerprint_loss: 1.0722 - val_key_hat_loss: 6.2536 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0168\n",
      "Epoch 27/100\n",
      "22499/22499 [==============================] - 9s 408us/step - loss: 862.0230 - fingerprint_loss: 1.8734 - key_hat_loss: 4.3007 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.1753 - val_loss: 1228.0065 - val_fingerprint_loss: 5.3752 - val_key_hat_loss: 6.1131 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0220\n",
      "Epoch 28/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 811.5726 - fingerprint_loss: 1.7131 - key_hat_loss: 4.0493 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.2024 - val_loss: 1207.2538 - val_fingerprint_loss: 1.7039 - val_key_hat_loss: 6.0277 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0256\n",
      "Epoch 29/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 760.5362 - fingerprint_loss: 1.7999 - key_hat_loss: 3.7937 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.2370 - val_loss: 1200.3062 - val_fingerprint_loss: 1.6905 - val_key_hat_loss: 5.9930 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0304\n",
      "Epoch 30/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 714.6440 - fingerprint_loss: 2.2547 - key_hat_loss: 3.5619 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.2684 - val_loss: 1132.0018 - val_fingerprint_loss: 1.5966 - val_key_hat_loss: 5.6520 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0488\n",
      "Epoch 31/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 681.0844 - fingerprint_loss: 3.7273 - key_hat_loss: 3.3868 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.2887 - val_loss: 1049.9620 - val_fingerprint_loss: 1.4470 - val_key_hat_loss: 5.2425 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0724\n",
      "Epoch 32/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 644.7569 - fingerprint_loss: 1.9936 - key_hat_loss: 3.2138 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.3114 - val_loss: 1008.7325 - val_fingerprint_loss: 1.5042 - val_key_hat_loss: 5.0361 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0904\n",
      "Epoch 33/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 611.9231 - fingerprint_loss: 1.8117 - key_hat_loss: 3.0505 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.3386 - val_loss: 914.8876 - val_fingerprint_loss: 9.2935 - val_key_hat_loss: 4.5279 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.1364\n",
      "Epoch 34/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 582.9053 - fingerprint_loss: 2.1741 - key_hat_loss: 2.9036 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.3553 - val_loss: 858.0976 - val_fingerprint_loss: 6.4896 - val_key_hat_loss: 4.2580 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.1632\n",
      "Epoch 35/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 557.7012 - fingerprint_loss: 1.4876 - key_hat_loss: 2.7810 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.3768 - val_loss: 831.7874 - val_fingerprint_loss: 2.4264 - val_key_hat_loss: 4.1468 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.1760\n",
      "Epoch 36/100\n",
      "22499/22499 [==============================] - 9s 407us/step - loss: 533.4135 - fingerprint_loss: 1.6671 - key_hat_loss: 2.6587 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.3960 - val_loss: 784.2944 - val_fingerprint_loss: 4.4407 - val_key_hat_loss: 3.8992 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.1968\n",
      "Epoch 37/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 515.8253 - fingerprint_loss: 2.1932 - key_hat_loss: 2.5681 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.4107 - val_loss: 754.2374 - val_fingerprint_loss: 10.6645 - val_key_hat_loss: 3.7178 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.2200\n",
      "Epoch 38/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 495.9458 - fingerprint_loss: 3.0340 - key_hat_loss: 2.4645 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.4265 - val_loss: 735.9820 - val_fingerprint_loss: 8.8933 - val_key_hat_loss: 3.6354 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.2244\n",
      "Epoch 39/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 476.4335 - fingerprint_loss: 2.0896 - key_hat_loss: 2.3717 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.4445 - val_loss: 718.6932 - val_fingerprint_loss: 5.6027 - val_key_hat_loss: 3.5654 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.2424\n",
      "Epoch 40/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 454.4234 - fingerprint_loss: 1.7110 - key_hat_loss: 2.2635 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.4648 - val_loss: 698.3671 - val_fingerprint_loss: 7.0681 - val_key_hat_loss: 3.4565 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.2508\n",
      "Epoch 41/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 443.4775 - fingerprint_loss: 2.8570 - key_hat_loss: 2.2031 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.4756 - val_loss: 678.2362 - val_fingerprint_loss: 2.5355 - val_key_hat_loss: 3.3785 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.2576\n",
      "Epoch 42/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 428.3510 - fingerprint_loss: 1.8256 - key_hat_loss: 2.1326 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.4861 - val_loss: 677.9144 - val_fingerprint_loss: 13.6416 - val_key_hat_loss: 3.3213 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.2724\n",
      "Epoch 43/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 416.3396 - fingerprint_loss: 1.8563 - key_hat_loss: 2.0724 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.4952 - val_loss: 646.4299 - val_fingerprint_loss: 9.7532 - val_key_hat_loss: 3.1833 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.2956\n",
      "Epoch 44/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 399.9927 - fingerprint_loss: 1.7723 - key_hat_loss: 1.9911 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5156 - val_loss: 617.8620 - val_fingerprint_loss: 2.2483 - val_key_hat_loss: 3.0780 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3112\n",
      "Epoch 45/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 390.9499 - fingerprint_loss: 3.1483 - key_hat_loss: 1.9390 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5250 - val_loss: 616.8954 - val_fingerprint_loss: 9.7185 - val_key_hat_loss: 3.0358 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3096\n",
      "Epoch 46/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 379.3304 - fingerprint_loss: 1.4967 - key_hat_loss: 1.8891 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5311 - val_loss: 610.7309 - val_fingerprint_loss: 9.1974 - val_key_hat_loss: 3.0076 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3188\n",
      "Epoch 47/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 368.4268 - fingerprint_loss: 2.0709 - key_hat_loss: 1.8317 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5425 - val_loss: 591.6117 - val_fingerprint_loss: 11.2241 - val_key_hat_loss: 2.9019 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3344\n",
      "Epoch 48/100\n",
      "22499/22499 [==============================] - 9s 407us/step - loss: 356.6289 - fingerprint_loss: 1.7184 - key_hat_loss: 1.7745 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5541 - val_loss: 591.1792 - val_fingerprint_loss: 16.8032 - val_key_hat_loss: 2.8718 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3384\n",
      "Epoch 49/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 349.2258 - fingerprint_loss: 2.6346 - key_hat_loss: 1.7329 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5611 - val_loss: 593.6836 - val_fingerprint_loss: 11.3245 - val_key_hat_loss: 2.9118 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3348\n",
      "Epoch 50/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 336.6742 - fingerprint_loss: 2.0769 - key_hat_loss: 1.6729 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5768 - val_loss: 567.4280 - val_fingerprint_loss: 12.1360 - val_key_hat_loss: 2.7764 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3524\n",
      "Epoch 51/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 334.4697 - fingerprint_loss: 1.6762 - key_hat_loss: 1.6639 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5752 - val_loss: 562.1097 - val_fingerprint_loss: 5.4611 - val_key_hat_loss: 2.7832 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3576\n",
      "Epoch 52/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 325.5120 - fingerprint_loss: 2.5383 - key_hat_loss: 1.6148 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5841 - val_loss: 555.7087 - val_fingerprint_loss: 6.2311 - val_key_hat_loss: 2.7473 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3528\n",
      "Epoch 53/100\n",
      "22499/22499 [==============================] - 9s 407us/step - loss: 313.7405 - fingerprint_loss: 1.5082 - key_hat_loss: 1.5611 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5983 - val_loss: 534.7820 - val_fingerprint_loss: 4.9179 - val_key_hat_loss: 2.6493 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3692\n",
      "Epoch 54/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 309.5386 - fingerprint_loss: 1.8425 - key_hat_loss: 1.5384 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6002 - val_loss: 544.2919 - val_fingerprint_loss: 4.7812 - val_key_hat_loss: 2.6975 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3584\n",
      "Epoch 55/100\n",
      "22499/22499 [==============================] - 9s 407us/step - loss: 301.6086 - fingerprint_loss: 2.9451 - key_hat_loss: 1.4933 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6110 - val_loss: 546.1063 - val_fingerprint_loss: 10.6750 - val_key_hat_loss: 2.6771 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3608\n",
      "Epoch 56/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 294.8475 - fingerprint_loss: 1.9838 - key_hat_loss: 1.4643 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6158 - val_loss: 529.1666 - val_fingerprint_loss: 8.8938 - val_key_hat_loss: 2.6013 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3788\n",
      "Epoch 57/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 290.0792 - fingerprint_loss: 2.1820 - key_hat_loss: 1.4394 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6240 - val_loss: 532.4624 - val_fingerprint_loss: 9.1069 - val_key_hat_loss: 2.6167 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3812\n",
      "Epoch 58/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 285.0637 - fingerprint_loss: 1.3952 - key_hat_loss: 1.4183 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6286 - val_loss: 522.7826 - val_fingerprint_loss: 14.6035 - val_key_hat_loss: 2.5409 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3932\n",
      "Epoch 59/100\n",
      "22499/22499 [==============================] - 9s 403us/step - loss: 277.4669 - fingerprint_loss: 1.9381 - key_hat_loss: 1.3776 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6389 - val_loss: 524.4459 - val_fingerprint_loss: 14.4177 - val_key_hat_loss: 2.5501 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3880\n",
      "Epoch 60/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 273.2630 - fingerprint_loss: 1.4401 - key_hat_loss: 1.3591 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6438 - val_loss: 509.1116 - val_fingerprint_loss: 14.8204 - val_key_hat_loss: 2.4714 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3980\n",
      "Epoch 61/100\n",
      "22499/22499 [==============================] - 9s 408us/step - loss: 269.1530 - fingerprint_loss: 1.9999 - key_hat_loss: 1.3357 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6456 - val_loss: 504.8548 - val_fingerprint_loss: 12.3397 - val_key_hat_loss: 2.4625 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4076\n",
      "Epoch 62/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 258.2321 - fingerprint_loss: 1.5722 - key_hat_loss: 1.2833 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6591 - val_loss: 505.0891 - val_fingerprint_loss: 8.8774 - val_key_hat_loss: 2.4810 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4052\n",
      "Epoch 63/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 256.7226 - fingerprint_loss: 2.4239 - key_hat_loss: 1.2715 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6595 - val_loss: 505.5205 - val_fingerprint_loss: 16.1341 - val_key_hat_loss: 2.4469 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4196\n",
      "Epoch 64/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 254.2957 - fingerprint_loss: 2.1838 - key_hat_loss: 1.2605 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6607 - val_loss: 511.3692 - val_fingerprint_loss: 16.3784 - val_key_hat_loss: 2.4749 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4028\n",
      "Epoch 65/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 250.0080 - fingerprint_loss: 2.2890 - key_hat_loss: 1.2386 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6678 - val_loss: 497.7842 - val_fingerprint_loss: 14.4167 - val_key_hat_loss: 2.4168 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4196\n",
      "Epoch 66/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 241.8661 - fingerprint_loss: 1.4174 - key_hat_loss: 1.2022 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6741 - val_loss: 487.9223 - val_fingerprint_loss: 9.7415 - val_key_hat_loss: 2.3909 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4268\n",
      "Epoch 67/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 239.3976 - fingerprint_loss: 2.3925 - key_hat_loss: 1.1850 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6804 - val_loss: 488.3430 - val_fingerprint_loss: 14.3179 - val_key_hat_loss: 2.3701 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4220\n",
      "Epoch 68/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 236.6738 - fingerprint_loss: 1.8461 - key_hat_loss: 1.1741 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6834 - val_loss: 497.7648 - val_fingerprint_loss: 12.1890 - val_key_hat_loss: 2.4278 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4164\n",
      "Epoch 69/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 233.1527 - fingerprint_loss: 1.5781 - key_hat_loss: 1.1578 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6852 - val_loss: 478.8714 - val_fingerprint_loss: 7.6998 - val_key_hat_loss: 2.3558 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4252\n",
      "Epoch 70/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 224.9278 - fingerprint_loss: 1.7656 - key_hat_loss: 1.1158 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6943 - val_loss: 467.7057 - val_fingerprint_loss: 8.0415 - val_key_hat_loss: 2.2983 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4424\n",
      "Epoch 71/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 224.6130 - fingerprint_loss: 2.1347 - key_hat_loss: 1.1123 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6970 - val_loss: 477.9834 - val_fingerprint_loss: 8.2711 - val_key_hat_loss: 2.3485 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4352\n",
      "Epoch 72/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 221.2625 - fingerprint_loss: 1.3470 - key_hat_loss: 1.0995 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7014 - val_loss: 477.0153 - val_fingerprint_loss: 4.4706 - val_key_hat_loss: 2.3627 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4236\n",
      "Epoch 73/100\n",
      "22499/22499 [==============================] - 9s 407us/step - loss: 217.9399 - fingerprint_loss: 2.4650 - key_hat_loss: 1.0773 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7054 - val_loss: 471.0305 - val_fingerprint_loss: 5.6613 - val_key_hat_loss: 2.3268 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4320\n",
      "Epoch 74/100\n",
      "22499/22499 [==============================] - 10s 428us/step - loss: 214.5403 - fingerprint_loss: 2.7909 - key_hat_loss: 1.0587 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7083 - val_loss: 459.6258 - val_fingerprint_loss: 2.8887 - val_key_hat_loss: 2.2836 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4464\n",
      "Epoch 75/100\n",
      "22499/22499 [==============================] - 10s 429us/step - loss: 211.7840 - fingerprint_loss: 3.3148 - key_hat_loss: 1.0423 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7117 - val_loss: 453.7829 - val_fingerprint_loss: 3.2088 - val_key_hat_loss: 2.2528 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4504\n",
      "Epoch 76/100\n",
      "22499/22499 [==============================] - 10s 433us/step - loss: 210.1413 - fingerprint_loss: 2.8128 - key_hat_loss: 1.0366 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7116 - val_loss: 457.3146 - val_fingerprint_loss: 10.1185 - val_key_hat_loss: 2.2359 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4596\n",
      "Epoch 77/100\n",
      "22499/22499 [==============================] - 10s 448us/step - loss: 202.9082 - fingerprint_loss: 2.0056 - key_hat_loss: 1.0045 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7241 - val_loss: 465.0936 - val_fingerprint_loss: 8.7808 - val_key_hat_loss: 2.2815 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4440\n",
      "Epoch 78/100\n",
      "22499/22499 [==============================] - 10s 442us/step - loss: 202.1632 - fingerprint_loss: 1.9134 - key_hat_loss: 1.0012 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7236 - val_loss: 457.8430 - val_fingerprint_loss: 6.6117 - val_key_hat_loss: 2.2561 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4588\n",
      "Epoch 79/100\n",
      "22499/22499 [==============================] - 9s 422us/step - loss: 199.6415 - fingerprint_loss: 2.6795 - key_hat_loss: 0.9848 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7239 - val_loss: 457.2016 - val_fingerprint_loss: 4.6205 - val_key_hat_loss: 2.2629 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4500\n",
      "Epoch 80/100\n",
      "22499/22499 [==============================] - 9s 420us/step - loss: 200.3986 - fingerprint_loss: 4.1833 - key_hat_loss: 0.9810 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7262 - val_loss: 457.9646 - val_fingerprint_loss: 7.5863 - val_key_hat_loss: 2.2518 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4564\n",
      "Epoch 81/100\n",
      "22499/22499 [==============================] - 10s 439us/step - loss: 194.1505 - fingerprint_loss: 1.8708 - key_hat_loss: 0.9614 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7339 - val_loss: 450.3218 - val_fingerprint_loss: 6.7885 - val_key_hat_loss: 2.2176 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4656\n",
      "Epoch 82/100\n",
      "22499/22499 [==============================] - 10s 437us/step - loss: 192.8425 - fingerprint_loss: 1.4481 - key_hat_loss: 0.9569 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7322 - val_loss: 451.5184 - val_fingerprint_loss: 9.4874 - val_key_hat_loss: 2.2101 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4588\n",
      "Epoch 83/100\n",
      "22499/22499 [==============================] - 10s 432us/step - loss: 188.0747 - fingerprint_loss: 1.6992 - key_hat_loss: 0.9318 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7410 - val_loss: 443.0209 - val_fingerprint_loss: 5.8359 - val_key_hat_loss: 2.1859 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4684\n",
      "Epoch 84/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 186.6100 - fingerprint_loss: 2.5442 - key_hat_loss: 0.9203 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7416 - val_loss: 455.5276 - val_fingerprint_loss: 12.4152 - val_key_hat_loss: 2.2155 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4612\n",
      "Epoch 85/100\n",
      "22499/22499 [==============================] - 10s 427us/step - loss: 184.6265 - fingerprint_loss: 2.3670 - key_hat_loss: 0.9113 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7430 - val_loss: 434.0022 - val_fingerprint_loss: 7.5213 - val_key_hat_loss: 2.1324 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4676\n",
      "Epoch 86/100\n",
      "22499/22499 [==============================] - 10s 430us/step - loss: 182.6987 - fingerprint_loss: 2.4188 - key_hat_loss: 0.9014 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7471 - val_loss: 453.7250 - val_fingerprint_loss: 13.8746 - val_key_hat_loss: 2.1992 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4624\n",
      "Epoch 87/100\n",
      "22499/22499 [==============================] - 10s 431us/step - loss: 180.9389 - fingerprint_loss: 1.8794 - key_hat_loss: 0.8953 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7460 - val_loss: 434.0846 - val_fingerprint_loss: 8.8898 - val_key_hat_loss: 2.1259 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4756\n",
      "Epoch 88/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 178.3112 - fingerprint_loss: 2.5930 - key_hat_loss: 0.8785 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7509 - val_loss: 435.3945 - val_fingerprint_loss: 7.8621 - val_key_hat_loss: 2.1376 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4672\n",
      "Epoch 89/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 177.4435 - fingerprint_loss: 2.1015 - key_hat_loss: 0.8767 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7532 - val_loss: 428.5537 - val_fingerprint_loss: 5.9511 - val_key_hat_loss: 2.1130 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4728\n",
      "Epoch 90/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 174.8335 - fingerprint_loss: 1.9508 - key_hat_loss: 0.8644 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7552 - val_loss: 439.7101 - val_fingerprint_loss: 10.2210 - val_key_hat_loss: 2.1474 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4720\n",
      "Epoch 91/100\n",
      "22499/22499 [==============================] - 9s 407us/step - loss: 168.8734 - fingerprint_loss: 1.6523 - key_hat_loss: 0.8361 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7622 - val_loss: 436.2845 - val_fingerprint_loss: 8.5041 - val_key_hat_loss: 2.1389 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4780\n",
      "Epoch 92/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 171.3405 - fingerprint_loss: 2.7760 - key_hat_loss: 0.8428 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7585 - val_loss: 439.9206 - val_fingerprint_loss: 13.9587 - val_key_hat_loss: 2.1298 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4776\n",
      "Epoch 93/100\n",
      "22499/22499 [==============================] - 9s 409us/step - loss: 168.2440 - fingerprint_loss: 2.7501 - key_hat_loss: 0.8274 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7631 - val_loss: 433.7346 - val_fingerprint_loss: 6.7162 - val_key_hat_loss: 2.1350 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4808\n",
      "Epoch 94/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 166.6582 - fingerprint_loss: 1.9980 - key_hat_loss: 0.8233 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7667 - val_loss: 442.3100 - val_fingerprint_loss: 13.1211 - val_key_hat_loss: 2.1459 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4768\n",
      "Epoch 95/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 164.2928 - fingerprint_loss: 2.6279 - key_hat_loss: 0.8083 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7693 - val_loss: 435.3617 - val_fingerprint_loss: 8.2520 - val_key_hat_loss: 2.1355 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4892\n",
      "Epoch 96/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 161.7366 - fingerprint_loss: 2.2901 - key_hat_loss: 0.7972 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7731 - val_loss: 445.1719 - val_fingerprint_loss: 11.2083 - val_key_hat_loss: 2.1698 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4772\n",
      "Epoch 97/100\n",
      "22499/22499 [==============================] - 9s 405us/step - loss: 160.4674 - fingerprint_loss: 2.7193 - key_hat_loss: 0.7887 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7765 - val_loss: 443.6722 - val_fingerprint_loss: 11.0482 - val_key_hat_loss: 2.1631 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4820\n",
      "Epoch 98/100\n",
      "22499/22499 [==============================] - 9s 406us/step - loss: 158.5018 - fingerprint_loss: 2.7254 - key_hat_loss: 0.7788 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7757 - val_loss: 429.9337 - val_fingerprint_loss: 6.5536 - val_key_hat_loss: 2.1169 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4860\n",
      "Epoch 99/100\n",
      "22499/22499 [==============================] - 9s 404us/step - loss: 155.8376 - fingerprint_loss: 1.9757 - key_hat_loss: 0.7693 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7794 - val_loss: 428.3777 - val_fingerprint_loss: 10.4303 - val_key_hat_loss: 2.0897 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4876\n",
      "Epoch 100/100\n",
      "22499/22499 [==============================] - 9s 415us/step - loss: 152.3558 - fingerprint_loss: 2.4113 - key_hat_loss: 0.7497 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7859 - val_loss: 425.1764 - val_fingerprint_loss: 9.6989 - val_key_hat_loss: 2.0773 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4980\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'histories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f75f7fafa5f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#models.append(model_10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time to Fit the Model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeg_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'histories' is not defined"
     ]
    }
   ],
   "source": [
    "r = 1e-6\n",
    "#histories=[]\n",
    "n_true_train, n_test = 25000 - 1, 5000 - 1\n",
    "t = n_true_train\n",
    "beg_time = time.time()\n",
    "x_fing_w, key_hat_w, epoch, batch = 1, 200, 100, 512\n",
    "std, max_fing_delay = 1, alpha\n",
    "\n",
    "print(\"Date : \", datetime.datetime.now())\n",
    "\n",
    "model_10 = get_encoder_decoder_conv_dense_slice_two_conv(sample_size=sample_size, key_length=key_length, chunk=chunk, reg = r)\n",
    "# losses.mean_squared_error# 0.001\n",
    "adam =optimizers.Adam(lr = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-7, decay = 0.0, amsgrad=False)\n",
    "\n",
    "model_10.compile(optimizer=adam, loss={'fingerprint': mean_pred_loss, 'key_hat': losses.categorical_crossentropy},\n",
    "          loss_weights={'fingerprint': x_fing_w, 'key_hat': key_hat_w},metrics=['accuracy'])#acc\n",
    "\n",
    "# model.summary()\n",
    "print(\"Model %s is Built and Compiled in %f\" % (t, time.time() - beg_time))\n",
    "beg_time = time.time()\n",
    "\n",
    "history = model_10.fit([X_train[0:t], train_keys[0:t], array_mult_train[0:t], array_sub_train[0:t], noise_for_train[0:t]],\n",
    "      [y_train[0:t], train_keys[0:t]], epochs=epoch, validation_split=0.1,batch_size=batch)  # callbacks=callbacks_list, verbose=0)\n",
    "#models.append(model_10)\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "print(\"Time to Fit the Model\", time.time() - beg_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_length:  1024\n",
      "Ext Rate:   0.4926956173704223\n",
      "Error: 0.2539523714228537\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(X_test_all[0:n_test-2]).reshape((-1, sample_size, 1))\n",
    "key_options = selecting_valid_fingerprints(key_length=key_length)  # we use 100 keys.\n",
    "test_keys = np.array(get_keys_for_fingerprinting_data(size=n_test, key_options=key_options))\n",
    "noise_for_test = np.squeeze(noise_for_test)\n",
    "pred = model_10.predict([x_test, test_keys, array_mult_test, array_sub_test, noise_for_test])\n",
    "\n",
    "fingerprint_x22, keys_true = pred[0], pred[1]\n",
    "ext_rate = compute_extract_rate(keys_true, true_keys=test_keys)\n",
    "print(\"key_length: \", key_length)\n",
    "print(\"Ext Rate:  \", ext_rate)\n",
    "key_bin_size = math.log2(key_length)\n",
    "error = bit_rate_error(keys_true,test_keys, key_bin_size)\n",
    "print('Error:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 5000 Numbre of training and testing data\n",
      "Noise and subtract and multiply arrays are built!...\n"
     ]
    }
   ],
   "source": [
    "n_true_train, n_test = 100000, 5000\n",
    "sample_size= 400#*32#* 32\n",
    "\n",
    "X_train_all = create_sample_size_dataset(all_ipds_for_train, sample_size = sample_size,n_sample=n_true_train)\n",
    "X_test_all = create_sample_size_dataset(all_ipds_for_test, sample_size = sample_size,n_sample=n_test)\n",
    "print(len(X_train_all), len(X_test_all), \"Numbre of training and testing data\")\n",
    "\n",
    "alpha, chunk = 25, 10\n",
    "std, max_fing_delay = 1, alpha\n",
    "array_mult_test, array_sub_test = get_mult_sub_for_fingerprinting(n_test, max_delay=max_fing_delay, chunk=chunk,\n",
    "                                                                  sample_size=sample_size)\n",
    "noise_for_test = get_noise_simulation_array(n_test, std=std, sample_size=sample_size)\n",
    "array_mult_train, array_sub_train = get_mult_sub_for_fingerprinting(n_true_train, max_delay=max_fing_delay, chunk=chunk,\n",
    "                                                                    sample_size=sample_size)\n",
    "noise_for_train = get_noise_simulation_array(n_true_train, std=std, sample_size=sample_size)\n",
    "print(\"Noise and subtract and multiply arrays are built!...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.698707103729248\n"
     ]
    }
   ],
   "source": [
    "key_length  = 1024#*32#1024*16\n",
    "beg = time.time()\n",
    "key_options = selecting_valid_fingerprints(key_length = key_length)\n",
    "X_train, y_train, train_keys = get_false_true_data(X_train_all, key_options, alpha=alpha)#get_only_true_data\n",
    "print(time.time() - beg)\n",
    "train_keys = np.array(train_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 400\n"
     ]
    }
   ],
   "source": [
    "print(key_length, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date :  2019-12-02 21:33:19.313430\n",
      "Model 24999 is Built and Compiled in 14.352504\n",
      "Train on 22499 samples, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "22499/22499 [==============================] - 55s 2ms/step - loss: 1398.0759 - fingerprint_loss: 3.7051 - key_hat_loss: 6.9718 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 6.6670e-04 - val_loss: 1391.9642 - val_fingerprint_loss: 2.4587 - val_key_hat_loss: 6.9475 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 8.0000e-04\n",
      "Epoch 2/100\n",
      "22499/22499 [==============================] - 18s 802us/step - loss: 1383.6756 - fingerprint_loss: 4.4357 - key_hat_loss: 6.8962 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0022 - val_loss: 1394.0039 - val_fingerprint_loss: 1.9250 - val_key_hat_loss: 6.9604 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 4.0000e-04\n",
      "Epoch 3/100\n",
      "22499/22499 [==============================] - 18s 801us/step - loss: 1372.5098 - fingerprint_loss: 4.2736 - key_hat_loss: 6.8412 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0037 - val_loss: 1397.2804 - val_fingerprint_loss: 0.7799 - val_key_hat_loss: 6.9825 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 4.0000e-04\n",
      "Epoch 4/100\n",
      "22499/22499 [==============================] - 18s 802us/step - loss: 1361.4732 - fingerprint_loss: 3.2338 - key_hat_loss: 6.7912 - fingerprint_acc: 1.1112e-07 - key_hat_acc: 0.0055 - val_loss: 1402.0547 - val_fingerprint_loss: 1.8323 - val_key_hat_loss: 7.0011 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 5/100\n",
      "22499/22499 [==============================] - 18s 800us/step - loss: 1348.9541 - fingerprint_loss: 2.0053 - key_hat_loss: 6.7347 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0075 - val_loss: 1402.4707 - val_fingerprint_loss: 1.3108 - val_key_hat_loss: 7.0058 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 8.0000e-04\n",
      "Epoch 6/100\n",
      "22499/22499 [==============================] - 18s 803us/step - loss: 1336.5075 - fingerprint_loss: 2.0733 - key_hat_loss: 6.6721 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0107 - val_loss: 1405.5875 - val_fingerprint_loss: 0.9715 - val_key_hat_loss: 7.0231 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 8.0000e-04\n",
      "Epoch 7/100\n",
      "22499/22499 [==============================] - 18s 806us/step - loss: 1323.0159 - fingerprint_loss: 2.2819 - key_hat_loss: 6.6036 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0132 - val_loss: 1406.6437 - val_fingerprint_loss: 0.8921 - val_key_hat_loss: 7.0287 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 8/100\n",
      "22499/22499 [==============================] - 18s 808us/step - loss: 1305.4320 - fingerprint_loss: 2.1101 - key_hat_loss: 6.5166 - fingerprint_acc: 1.1112e-07 - key_hat_acc: 0.0171 - val_loss: 1409.0640 - val_fingerprint_loss: 0.8466 - val_key_hat_loss: 7.0411 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 9/100\n",
      "22499/22499 [==============================] - 18s 805us/step - loss: 1286.8058 - fingerprint_loss: 1.4890 - key_hat_loss: 6.4266 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0218 - val_loss: 1409.4339 - val_fingerprint_loss: 0.6329 - val_key_hat_loss: 7.0440 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "22499/22499 [==============================] - 18s 808us/step - loss: 1267.1079 - fingerprint_loss: 2.0948 - key_hat_loss: 6.3250 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0285 - val_loss: 1410.6126 - val_fingerprint_loss: 0.9606 - val_key_hat_loss: 7.0482 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 11/100\n",
      "22499/22499 [==============================] - 19s 845us/step - loss: 1243.8258 - fingerprint_loss: 3.3311 - key_hat_loss: 6.2024 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0352 - val_loss: 1411.7919 - val_fingerprint_loss: 1.4191 - val_key_hat_loss: 7.0518 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0012\n",
      "Epoch 12/100\n",
      "22499/22499 [==============================] - 19s 860us/step - loss: 1219.1764 - fingerprint_loss: 4.3130 - key_hat_loss: 6.0743 - fingerprint_acc: 1.1112e-07 - key_hat_acc: 0.0436 - val_loss: 1411.8706 - val_fingerprint_loss: 2.0339 - val_key_hat_loss: 7.0492 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0028\n",
      "Epoch 13/100\n",
      "22499/22499 [==============================] - 18s 811us/step - loss: 1187.4998 - fingerprint_loss: 3.3158 - key_hat_loss: 5.9209 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0545 - val_loss: 1410.4384 - val_fingerprint_loss: 1.5788 - val_key_hat_loss: 7.0443 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0020\n",
      "Epoch 14/100\n",
      "22499/22499 [==============================] - 18s 807us/step - loss: 1144.9452 - fingerprint_loss: 2.1085 - key_hat_loss: 5.7142 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0711 - val_loss: 1401.4309 - val_fingerprint_loss: 2.4428 - val_key_hat_loss: 6.9949 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 8.0000e-04\n",
      "Epoch 15/100\n",
      "22499/22499 [==============================] - 18s 807us/step - loss: 1097.0815 - fingerprint_loss: 1.8313 - key_hat_loss: 5.4762 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.0934 - val_loss: 1385.6514 - val_fingerprint_loss: 1.8674 - val_key_hat_loss: 6.9189 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0016\n",
      "Epoch 16/100\n",
      "22499/22499 [==============================] - 19s 849us/step - loss: 1043.9989 - fingerprint_loss: 1.8264 - key_hat_loss: 5.2108 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.1154 - val_loss: 1356.2777 - val_fingerprint_loss: 1.1529 - val_key_hat_loss: 6.7756 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0064\n",
      "Epoch 17/100\n",
      "22499/22499 [==============================] - 19s 830us/step - loss: 987.8631 - fingerprint_loss: 1.8882 - key_hat_loss: 4.9298 - fingerprint_acc: 1.1112e-07 - key_hat_acc: 0.1444 - val_loss: 1326.8096 - val_fingerprint_loss: 0.6165 - val_key_hat_loss: 6.6309 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0084\n",
      "Epoch 18/100\n",
      "22499/22499 [==============================] - 20s 875us/step - loss: 930.3110 - fingerprint_loss: 2.1494 - key_hat_loss: 4.6408 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.1731 - val_loss: 1291.8706 - val_fingerprint_loss: 4.7373 - val_key_hat_loss: 6.4356 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0124\n",
      "Epoch 19/100\n",
      "22499/22499 [==============================] - 19s 831us/step - loss: 869.6223 - fingerprint_loss: 2.6119 - key_hat_loss: 4.3350 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.2051 - val_loss: 1244.2090 - val_fingerprint_loss: 0.6974 - val_key_hat_loss: 6.2175 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0224\n",
      "Epoch 20/100\n",
      "22499/22499 [==============================] - 19s 846us/step - loss: 803.3270 - fingerprint_loss: 1.9514 - key_hat_loss: 4.0068 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.2464 - val_loss: 1187.5939 - val_fingerprint_loss: 2.3520 - val_key_hat_loss: 5.9262 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0352\n",
      "Epoch 21/100\n",
      "22499/22499 [==============================] - 19s 845us/step - loss: 734.5071 - fingerprint_loss: 2.1551 - key_hat_loss: 3.6617 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.2927 - val_loss: 1148.7319 - val_fingerprint_loss: 3.1822 - val_key_hat_loss: 5.7277 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0532\n",
      "Epoch 22/100\n",
      "22499/22499 [==============================] - 19s 848us/step - loss: 653.3923 - fingerprint_loss: 1.3927 - key_hat_loss: 3.2600 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.3573 - val_loss: 1156.5035 - val_fingerprint_loss: 1.3630 - val_key_hat_loss: 5.7756 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0424\n",
      "Epoch 23/100\n",
      "22499/22499 [==============================] - 19s 853us/step - loss: 575.5195 - fingerprint_loss: 2.0394 - key_hat_loss: 2.8674 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.4257 - val_loss: 1154.6605 - val_fingerprint_loss: 8.1720 - val_key_hat_loss: 5.7324 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.0440\n",
      "Epoch 24/100\n",
      "22499/22499 [==============================] - 20s 881us/step - loss: 509.4339 - fingerprint_loss: 3.0282 - key_hat_loss: 2.5320 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.4886 - val_loss: 1033.5481 - val_fingerprint_loss: 7.2156 - val_key_hat_loss: 5.1316 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.1120\n",
      "Epoch 25/100\n",
      "22499/22499 [==============================] - 18s 819us/step - loss: 459.1018 - fingerprint_loss: 1.9284 - key_hat_loss: 2.2858 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5317 - val_loss: 921.6993 - val_fingerprint_loss: 4.4518 - val_key_hat_loss: 4.5862 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.1912\n",
      "Epoch 26/100\n",
      "22499/22499 [==============================] - 18s 814us/step - loss: 407.3855 - fingerprint_loss: 1.7847 - key_hat_loss: 2.0279 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.5781 - val_loss: 768.5129 - val_fingerprint_loss: 1.5170 - val_key_hat_loss: 3.8349 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.3160\n",
      "Epoch 27/100\n",
      "22499/22499 [==============================] - 18s 818us/step - loss: 369.6247 - fingerprint_loss: 1.4947 - key_hat_loss: 1.8406 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6087 - val_loss: 653.1985 - val_fingerprint_loss: 1.2170 - val_key_hat_loss: 3.2599 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4192\n",
      "Epoch 28/100\n",
      "22499/22499 [==============================] - 19s 833us/step - loss: 336.5443 - fingerprint_loss: 1.7168 - key_hat_loss: 1.6741 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6381 - val_loss: 583.6284 - val_fingerprint_loss: 2.6488 - val_key_hat_loss: 2.9048 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.4768\n",
      "Epoch 29/100\n",
      "22499/22499 [==============================] - 20s 902us/step - loss: 307.9222 - fingerprint_loss: 2.7974 - key_hat_loss: 1.5256 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6649 - val_loss: 496.4684 - val_fingerprint_loss: 1.5725 - val_key_hat_loss: 2.4744 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.5520\n",
      "Epoch 30/100\n",
      "22499/22499 [==============================] - 20s 869us/step - loss: 282.1230 - fingerprint_loss: 2.5604 - key_hat_loss: 1.3977 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.6930 - val_loss: 446.1439 - val_fingerprint_loss: 5.5225 - val_key_hat_loss: 2.2030 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.5832\n",
      "Epoch 31/100\n",
      "22499/22499 [==============================] - 19s 850us/step - loss: 264.0255 - fingerprint_loss: 1.3897 - key_hat_loss: 1.3131 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7059 - val_loss: 391.4011 - val_fingerprint_loss: 3.7942 - val_key_hat_loss: 1.9380 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.6236\n",
      "Epoch 32/100\n",
      "22499/22499 [==============================] - 19s 842us/step - loss: 244.6846 - fingerprint_loss: 1.7994 - key_hat_loss: 1.2144 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7261 - val_loss: 372.1551 - val_fingerprint_loss: 4.5913 - val_key_hat_loss: 1.8378 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.6372\n",
      "Epoch 33/100\n",
      "22499/22499 [==============================] - 19s 830us/step - loss: 225.9761 - fingerprint_loss: 1.1619 - key_hat_loss: 1.1240 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7438 - val_loss: 334.9513 - val_fingerprint_loss: 4.6636 - val_key_hat_loss: 1.6514 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.6760\n",
      "Epoch 34/100\n",
      "22499/22499 [==============================] - 20s 883us/step - loss: 213.3775 - fingerprint_loss: 1.3907 - key_hat_loss: 1.0599 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7583 - val_loss: 326.6736 - val_fingerprint_loss: 4.1540 - val_key_hat_loss: 1.6125 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.6748\n",
      "Epoch 35/100\n",
      "22499/22499 [==============================] - 19s 837us/step - loss: 199.9265 - fingerprint_loss: 1.4669 - key_hat_loss: 0.9922 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7707 - val_loss: 301.7579 - val_fingerprint_loss: 6.1658 - val_key_hat_loss: 1.4779 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.6884\n",
      "Epoch 36/100\n",
      "22499/22499 [==============================] - 19s 832us/step - loss: 190.4656 - fingerprint_loss: 2.7855 - key_hat_loss: 0.9383 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7827 - val_loss: 284.0229 - val_fingerprint_loss: 2.6012 - val_key_hat_loss: 1.4070 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7060\n",
      "Epoch 37/100\n",
      "22499/22499 [==============================] - 19s 854us/step - loss: 180.7487 - fingerprint_loss: 3.1676 - key_hat_loss: 0.8878 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.7934 - val_loss: 270.3644 - val_fingerprint_loss: 9.1723 - val_key_hat_loss: 1.3059 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7232\n",
      "Epoch 38/100\n",
      "22499/22499 [==============================] - 19s 842us/step - loss: 166.9641 - fingerprint_loss: 1.5004 - key_hat_loss: 0.8273 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8059 - val_loss: 248.4974 - val_fingerprint_loss: 7.7844 - val_key_hat_loss: 1.2035 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7436\n",
      "Epoch 39/100\n",
      "22499/22499 [==============================] - 19s 840us/step - loss: 158.8993 - fingerprint_loss: 1.5656 - key_hat_loss: 0.7866 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8150 - val_loss: 239.4612 - val_fingerprint_loss: 5.4069 - val_key_hat_loss: 1.1702 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7428\n",
      "Epoch 40/100\n",
      "22499/22499 [==============================] - 19s 839us/step - loss: 151.2009 - fingerprint_loss: 2.0421 - key_hat_loss: 0.7457 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8232 - val_loss: 227.9129 - val_fingerprint_loss: 8.0726 - val_key_hat_loss: 1.0991 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7528\n",
      "Epoch 41/100\n",
      "22499/22499 [==============================] - 19s 838us/step - loss: 146.3541 - fingerprint_loss: 1.7296 - key_hat_loss: 0.7231 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8263 - val_loss: 219.8216 - val_fingerprint_loss: 4.9072 - val_key_hat_loss: 1.0745 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7560\n",
      "Epoch 42/100\n",
      "22499/22499 [==============================] - 20s 886us/step - loss: 139.6108 - fingerprint_loss: 3.0959 - key_hat_loss: 0.6825 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8380 - val_loss: 200.1542 - val_fingerprint_loss: 8.7340 - val_key_hat_loss: 0.9570 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7728\n",
      "Epoch 43/100\n",
      "22499/22499 [==============================] - 19s 865us/step - loss: 131.3989 - fingerprint_loss: 1.8792 - key_hat_loss: 0.6475 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8441 - val_loss: 207.7056 - val_fingerprint_loss: 5.4371 - val_key_hat_loss: 1.0113 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7708\n",
      "Epoch 44/100\n",
      "22499/22499 [==============================] - 19s 838us/step - loss: 127.8240 - fingerprint_loss: 1.9310 - key_hat_loss: 0.6294 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8468 - val_loss: 195.5157 - val_fingerprint_loss: 6.0750 - val_key_hat_loss: 0.9471 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7836\n",
      "Epoch 45/100\n",
      "22499/22499 [==============================] - 21s 926us/step - loss: 123.0966 - fingerprint_loss: 1.8400 - key_hat_loss: 0.6062 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8512 - val_loss: 181.9835 - val_fingerprint_loss: 4.5263 - val_key_hat_loss: 0.8872 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7916\n",
      "Epoch 46/100\n",
      "22499/22499 [==============================] - 19s 854us/step - loss: 115.8896 - fingerprint_loss: 2.1855 - key_hat_loss: 0.5685 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8606 - val_loss: 177.2206 - val_fingerprint_loss: 2.3732 - val_key_hat_loss: 0.8742 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7980\n",
      "Epoch 47/100\n",
      "22499/22499 [==============================] - 19s 850us/step - loss: 110.9468 - fingerprint_loss: 1.7977 - key_hat_loss: 0.5457 - fingerprint_acc: 1.1112e-07 - key_hat_acc: 0.8663 - val_loss: 177.8216 - val_fingerprint_loss: 5.9513 - val_key_hat_loss: 0.8593 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.7948\n",
      "Epoch 48/100\n",
      "22499/22499 [==============================] - 19s 842us/step - loss: 107.6943 - fingerprint_loss: 1.2514 - key_hat_loss: 0.5321 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8676 - val_loss: 168.7629 - val_fingerprint_loss: 3.9914 - val_key_hat_loss: 0.8238 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8032\n",
      "Epoch 49/100\n",
      "22499/22499 [==============================] - 19s 863us/step - loss: 105.2476 - fingerprint_loss: 2.1547 - key_hat_loss: 0.5154 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8722 - val_loss: 167.7847 - val_fingerprint_loss: 8.3672 - val_key_hat_loss: 0.7970 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8140\n",
      "Epoch 50/100\n",
      "22499/22499 [==============================] - 19s 844us/step - loss: 102.9085 - fingerprint_loss: 2.0648 - key_hat_loss: 0.5041 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8751 - val_loss: 170.7425 - val_fingerprint_loss: 8.5203 - val_key_hat_loss: 0.8110 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8048\n",
      "Epoch 51/100\n",
      "22499/22499 [==============================] - 19s 842us/step - loss: 98.9561 - fingerprint_loss: 1.4450 - key_hat_loss: 0.4875 - fingerprint_acc: 1.1112e-07 - key_hat_acc: 0.8774 - val_loss: 166.2384 - val_fingerprint_loss: 6.2023 - val_key_hat_loss: 0.8001 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8020\n",
      "Epoch 52/100\n",
      "22499/22499 [==============================] - 19s 861us/step - loss: 95.1157 - fingerprint_loss: 1.5361 - key_hat_loss: 0.4678 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8812 - val_loss: 170.7012 - val_fingerprint_loss: 8.0929 - val_key_hat_loss: 0.8130 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8040\n",
      "Epoch 53/100\n",
      "22499/22499 [==============================] - 19s 861us/step - loss: 93.5423 - fingerprint_loss: 2.3889 - key_hat_loss: 0.4557 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8864 - val_loss: 159.8040 - val_fingerprint_loss: 7.5973 - val_key_hat_loss: 0.7610 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8104\n",
      "Epoch 54/100\n",
      "22499/22499 [==============================] - 19s 848us/step - loss: 91.3833 - fingerprint_loss: 3.4877 - key_hat_loss: 0.4394 - fingerprint_acc: 1.1112e-07 - key_hat_acc: 0.8894 - val_loss: 153.5620 - val_fingerprint_loss: 7.0971 - val_key_hat_loss: 0.7323 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8220\n",
      "Epoch 55/100\n",
      "22499/22499 [==============================] - 19s 849us/step - loss: 87.3043 - fingerprint_loss: 2.7897 - key_hat_loss: 0.4225 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8936 - val_loss: 145.8478 - val_fingerprint_loss: 7.4422 - val_key_hat_loss: 0.6920 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8300\n",
      "Epoch 56/100\n",
      "22499/22499 [==============================] - 20s 896us/step - loss: 84.9971 - fingerprint_loss: 1.7278 - key_hat_loss: 0.4163 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8942 - val_loss: 143.4706 - val_fingerprint_loss: 3.1509 - val_key_hat_loss: 0.7015 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8292\n",
      "Epoch 57/100\n",
      "22499/22499 [==============================] - 21s 914us/step - loss: 81.4880 - fingerprint_loss: 1.7430 - key_hat_loss: 0.3987 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.8980 - val_loss: 137.4010 - val_fingerprint_loss: 4.0706 - val_key_hat_loss: 0.6666 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8320\n",
      "Epoch 58/100\n",
      "22499/22499 [==============================] - 20s 892us/step - loss: 78.0256 - fingerprint_loss: 1.8194 - key_hat_loss: 0.3810 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9031 - val_loss: 132.0097 - val_fingerprint_loss: 1.5681 - val_key_hat_loss: 0.6521 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8324\n",
      "Epoch 59/100\n",
      "22499/22499 [==============================] - 20s 886us/step - loss: 77.7124 - fingerprint_loss: 2.2677 - key_hat_loss: 0.3772 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9036 - val_loss: 134.7002 - val_fingerprint_loss: 2.7575 - val_key_hat_loss: 0.6596 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8392\n",
      "Epoch 60/100\n",
      "22499/22499 [==============================] - 19s 851us/step - loss: 74.4290 - fingerprint_loss: 1.6457 - key_hat_loss: 0.3638 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9090 - val_loss: 131.4939 - val_fingerprint_loss: 4.2984 - val_key_hat_loss: 0.6359 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8388\n",
      "Epoch 61/100\n",
      "22499/22499 [==============================] - 19s 847us/step - loss: 71.8403 - fingerprint_loss: 1.3441 - key_hat_loss: 0.3524 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9101 - val_loss: 127.1127 - val_fingerprint_loss: 6.9649 - val_key_hat_loss: 0.6007 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8440\n",
      "Epoch 62/100\n",
      "22499/22499 [==============================] - 19s 851us/step - loss: 70.5821 - fingerprint_loss: 1.1232 - key_hat_loss: 0.3472 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9108 - val_loss: 125.3517 - val_fingerprint_loss: 6.0924 - val_key_hat_loss: 0.5962 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8404\n",
      "Epoch 63/100\n",
      "22499/22499 [==============================] - 19s 853us/step - loss: 69.2814 - fingerprint_loss: 1.7582 - key_hat_loss: 0.3375 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9128 - val_loss: 116.9813 - val_fingerprint_loss: 2.9849 - val_key_hat_loss: 0.5699 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8504\n",
      "Epoch 64/100\n",
      "22499/22499 [==============================] - 19s 866us/step - loss: 69.5606 - fingerprint_loss: 1.7625 - key_hat_loss: 0.3389 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9101 - val_loss: 114.7899 - val_fingerprint_loss: 1.9875 - val_key_hat_loss: 0.5639 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8552\n",
      "Epoch 65/100\n",
      "22499/22499 [==============================] - 19s 858us/step - loss: 67.0370 - fingerprint_loss: 1.6297 - key_hat_loss: 0.3270 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9154 - val_loss: 125.1354 - val_fingerprint_loss: 8.5524 - val_key_hat_loss: 0.5828 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8476\n",
      "Epoch 66/100\n",
      "22499/22499 [==============================] - 19s 856us/step - loss: 66.4397 - fingerprint_loss: 3.3903 - key_hat_loss: 0.3152 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9163 - val_loss: 116.4807 - val_fingerprint_loss: 4.8744 - val_key_hat_loss: 0.5580 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8552\n",
      "Epoch 67/100\n",
      "22499/22499 [==============================] - 19s 849us/step - loss: 64.9016 - fingerprint_loss: 1.5019 - key_hat_loss: 0.3169 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9148 - val_loss: 111.8748 - val_fingerprint_loss: 4.1213 - val_key_hat_loss: 0.5387 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8520\n",
      "Epoch 68/100\n",
      "22499/22499 [==============================] - 19s 857us/step - loss: 62.4415 - fingerprint_loss: 1.3430 - key_hat_loss: 0.3054 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9193 - val_loss: 120.3577 - val_fingerprint_loss: 11.6402 - val_key_hat_loss: 0.5435 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8548\n",
      "Epoch 69/100\n",
      "22499/22499 [==============================] - 19s 854us/step - loss: 61.5428 - fingerprint_loss: 1.2291 - key_hat_loss: 0.3015 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9228 - val_loss: 114.2419 - val_fingerprint_loss: 6.9831 - val_key_hat_loss: 0.5362 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8596\n",
      "Epoch 70/100\n",
      "22499/22499 [==============================] - 19s 854us/step - loss: 61.2182 - fingerprint_loss: 2.0633 - key_hat_loss: 0.2957 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9218 - val_loss: 104.9348 - val_fingerprint_loss: 1.7400 - val_key_hat_loss: 0.5159 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8612\n",
      "Epoch 71/100\n",
      "22499/22499 [==============================] - 19s 856us/step - loss: 60.0886 - fingerprint_loss: 2.8465 - key_hat_loss: 0.2861 - fingerprint_acc: 1.1112e-07 - key_hat_acc: 0.9250 - val_loss: 110.8255 - val_fingerprint_loss: 8.6749 - val_key_hat_loss: 0.5107 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8648\n",
      "Epoch 72/100\n",
      "22499/22499 [==============================] - 19s 851us/step - loss: 58.5646 - fingerprint_loss: 2.2964 - key_hat_loss: 0.2813 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9259 - val_loss: 115.8148 - val_fingerprint_loss: 8.3972 - val_key_hat_loss: 0.5370 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8568\n",
      "Epoch 73/100\n",
      "22499/22499 [==============================] - 19s 859us/step - loss: 55.4652 - fingerprint_loss: 1.6972 - key_hat_loss: 0.2688 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9284 - val_loss: 106.5741 - val_fingerprint_loss: 7.3337 - val_key_hat_loss: 0.4961 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8696\n",
      "Epoch 74/100\n",
      "22499/22499 [==============================] - 19s 856us/step - loss: 56.0714 - fingerprint_loss: 1.9110 - key_hat_loss: 0.2707 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9288 - val_loss: 111.9438 - val_fingerprint_loss: 4.5158 - val_key_hat_loss: 0.5371 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8564\n",
      "Epoch 75/100\n",
      "22499/22499 [==============================] - 19s 852us/step - loss: 55.5223 - fingerprint_loss: 2.4821 - key_hat_loss: 0.2651 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9296 - val_loss: 111.9365 - val_fingerprint_loss: 8.9553 - val_key_hat_loss: 0.5148 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8576\n",
      "Epoch 76/100\n",
      "22499/22499 [==============================] - 19s 857us/step - loss: 52.8884 - fingerprint_loss: 1.8320 - key_hat_loss: 0.2552 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9325 - val_loss: 110.8532 - val_fingerprint_loss: 10.1673 - val_key_hat_loss: 0.5034 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8604\n",
      "Epoch 77/100\n",
      "22499/22499 [==============================] - 19s 854us/step - loss: 51.0795 - fingerprint_loss: 1.2178 - key_hat_loss: 0.2492 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9343 - val_loss: 103.8417 - val_fingerprint_loss: 7.3238 - val_key_hat_loss: 0.4825 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8644\n",
      "Epoch 78/100\n",
      "22499/22499 [==============================] - 19s 856us/step - loss: 50.2962 - fingerprint_loss: 1.7474 - key_hat_loss: 0.2427 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9351 - val_loss: 104.0883 - val_fingerprint_loss: 5.7513 - val_key_hat_loss: 0.4916 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8656\n",
      "Epoch 79/100\n",
      "22499/22499 [==============================] - 21s 919us/step - loss: 50.7053 - fingerprint_loss: 1.7424 - key_hat_loss: 0.2447 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9340 - val_loss: 93.5206 - val_fingerprint_loss: 1.7409 - val_key_hat_loss: 0.4588 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8756\n",
      "Epoch 80/100\n",
      "22499/22499 [==============================] - 20s 871us/step - loss: 49.4582 - fingerprint_loss: 1.7586 - key_hat_loss: 0.2384 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9353 - val_loss: 99.5393 - val_fingerprint_loss: 4.5297 - val_key_hat_loss: 0.4750 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8660\n",
      "Epoch 81/100\n",
      "22499/22499 [==============================] - 19s 863us/step - loss: 49.1735 - fingerprint_loss: 1.4872 - key_hat_loss: 0.2384 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9352 - val_loss: 99.1100 - val_fingerprint_loss: 5.8921 - val_key_hat_loss: 0.4660 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8704\n",
      "Epoch 82/100\n",
      "22499/22499 [==============================] - 19s 853us/step - loss: 47.1383 - fingerprint_loss: 1.6292 - key_hat_loss: 0.2275 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9394 - val_loss: 93.7962 - val_fingerprint_loss: 1.7002 - val_key_hat_loss: 0.4604 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8696\n",
      "Epoch 83/100\n",
      "22499/22499 [==============================] - 19s 851us/step - loss: 46.1601 - fingerprint_loss: 1.5390 - key_hat_loss: 0.2230 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9408 - val_loss: 102.1257 - val_fingerprint_loss: 6.2693 - val_key_hat_loss: 0.4792 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8712\n",
      "Epoch 84/100\n",
      "22499/22499 [==============================] - 20s 880us/step - loss: 47.4177 - fingerprint_loss: 2.1028 - key_hat_loss: 0.2265 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9375 - val_loss: 103.7217 - val_fingerprint_loss: 9.5600 - val_key_hat_loss: 0.4707 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8720\n",
      "Epoch 85/100\n",
      "22499/22499 [==============================] - 20s 870us/step - loss: 46.7737 - fingerprint_loss: 2.4984 - key_hat_loss: 0.2213 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9387 - val_loss: 100.6935 - val_fingerprint_loss: 11.6505 - val_key_hat_loss: 0.4451 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8732\n",
      "Epoch 86/100\n",
      "22499/22499 [==============================] - 19s 850us/step - loss: 47.1125 - fingerprint_loss: 3.0609 - key_hat_loss: 0.2202 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9408 - val_loss: 89.7583 - val_fingerprint_loss: 3.8896 - val_key_hat_loss: 0.4293 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8808\n",
      "Epoch 87/100\n",
      "22499/22499 [==============================] - 19s 859us/step - loss: 44.0900 - fingerprint_loss: 1.4014 - key_hat_loss: 0.2134 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9419 - val_loss: 92.0221 - val_fingerprint_loss: 3.0924 - val_key_hat_loss: 0.4446 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8780\n",
      "Epoch 88/100\n",
      "22499/22499 [==============================] - 20s 879us/step - loss: 45.1028 - fingerprint_loss: 1.7901 - key_hat_loss: 0.2165 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9402 - val_loss: 88.6875 - val_fingerprint_loss: 4.0044 - val_key_hat_loss: 0.4233 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8812\n",
      "Epoch 89/100\n",
      "22499/22499 [==============================] - 20s 872us/step - loss: 41.5530 - fingerprint_loss: 1.5404 - key_hat_loss: 0.2000 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9450 - val_loss: 88.2347 - val_fingerprint_loss: 2.4975 - val_key_hat_loss: 0.4286 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8784\n",
      "Epoch 90/100\n",
      "22499/22499 [==============================] - 20s 871us/step - loss: 42.0714 - fingerprint_loss: 1.4810 - key_hat_loss: 0.2029 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9445 - val_loss: 96.5405 - val_fingerprint_loss: 8.9592 - val_key_hat_loss: 0.4378 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8800\n",
      "Epoch 91/100\n",
      "22499/22499 [==============================] - 20s 877us/step - loss: 43.6120 - fingerprint_loss: 2.0347 - key_hat_loss: 0.2078 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9418 - val_loss: 94.5185 - val_fingerprint_loss: 5.1413 - val_key_hat_loss: 0.4468 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8788\n",
      "Epoch 92/100\n",
      "22499/22499 [==============================] - 20s 870us/step - loss: 42.2707 - fingerprint_loss: 2.3296 - key_hat_loss: 0.1996 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9451 - val_loss: 90.9029 - val_fingerprint_loss: 6.6107 - val_key_hat_loss: 0.4214 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8792\n",
      "Epoch 93/100\n",
      "22499/22499 [==============================] - 20s 872us/step - loss: 40.8227 - fingerprint_loss: 1.6660 - key_hat_loss: 0.1957 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9460 - val_loss: 95.9135 - val_fingerprint_loss: 10.6517 - val_key_hat_loss: 0.4262 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8764\n",
      "Epoch 94/100\n",
      "22499/22499 [==============================] - 20s 869us/step - loss: 41.1689 - fingerprint_loss: 1.4451 - key_hat_loss: 0.1985 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9458 - val_loss: 94.0494 - val_fingerprint_loss: 9.1553 - val_key_hat_loss: 0.4244 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8780\n",
      "Epoch 95/100\n",
      "22499/22499 [==============================] - 20s 873us/step - loss: 40.7838 - fingerprint_loss: 1.9725 - key_hat_loss: 0.1940 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9454 - val_loss: 93.8677 - val_fingerprint_loss: 6.1898 - val_key_hat_loss: 0.4383 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8744\n",
      "Epoch 96/100\n",
      "22499/22499 [==============================] - 20s 870us/step - loss: 39.3649 - fingerprint_loss: 2.1569 - key_hat_loss: 0.1860 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9487 - val_loss: 95.6988 - val_fingerprint_loss: 9.6872 - val_key_hat_loss: 0.4300 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8780\n",
      "Epoch 97/100\n",
      "22499/22499 [==============================] - 20s 869us/step - loss: 39.1804 - fingerprint_loss: 2.2757 - key_hat_loss: 0.1844 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9480 - val_loss: 87.4388 - val_fingerprint_loss: 3.5924 - val_key_hat_loss: 0.4192 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8748\n",
      "Epoch 98/100\n",
      "22499/22499 [==============================] - 20s 888us/step - loss: 39.0655 - fingerprint_loss: 1.9732 - key_hat_loss: 0.1854 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9471 - val_loss: 87.4531 - val_fingerprint_loss: 4.9728 - val_key_hat_loss: 0.4123 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8748\n",
      "Epoch 99/100\n",
      "22499/22499 [==============================] - 20s 874us/step - loss: 39.9382 - fingerprint_loss: 2.0884 - key_hat_loss: 0.1892 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9465 - val_loss: 87.9167 - val_fingerprint_loss: 5.2131 - val_key_hat_loss: 0.4134 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8772\n",
      "Epoch 100/100\n",
      "22499/22499 [==============================] - 20s 867us/step - loss: 38.2271 - fingerprint_loss: 1.6534 - key_hat_loss: 0.1828 - fingerprint_acc: 0.0000e+00 - key_hat_acc: 0.9486 - val_loss: 87.1823 - val_fingerprint_loss: 4.6875 - val_key_hat_loss: 0.4124 - val_fingerprint_acc: 0.0000e+00 - val_key_hat_acc: 0.8836\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-467b8bf7841f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m history_dense_decoder = model_10.fit([X_train[0:t], train_keys[0:t], array_mult_train[0:t], array_sub_train[0:t], noise_for_train[0:t]],\n\u001b[0;32m     21\u001b[0m       [y_train[0:t], train_keys[0:t]], epochs=epoch, validation_split=0.1,batch_size=batch)  # callbacks=callbacks_list, verbose=0)\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time to Fit the Model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeg_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "n_true_train, n_test = 25000-1, 5000-1\n",
    "t = n_true_train\n",
    "beg_time = time.time()\n",
    "x_fing_w, key_hat_w, epoch, batch = 1, 200, 100, 512\n",
    "std, max_fing_delay = 1, alpha\n",
    "\n",
    "print(\"Date : \", datetime.datetime.now())\n",
    "\n",
    "model_10 = get_encoder_decoder_conv_dense_slice_two_conv(sample_size=sample_size, key_length=key_length, chunk=chunk, reg = r)\n",
    "# losses.mean_squared_error# 0.001\n",
    "adam =optimizers.Adam(lr = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-7, decay = 0.0, amsgrad=False)\n",
    "\n",
    "model_10.compile(optimizer=adam, loss={'fingerprint': mean_pred_loss, 'key_hat': losses.categorical_crossentropy},\n",
    "          loss_weights={'fingerprint': x_fing_w, 'key_hat': key_hat_w},metrics=['accuracy'])#acc\n",
    "\n",
    "# model.summary()\n",
    "print(\"Model %s is Built and Compiled in %f\" % (t, time.time() - beg_time))\n",
    "beg_time = time.time()\n",
    "\n",
    "history_dense_decoder = model_10.fit([X_train[0:t], train_keys[0:t], array_mult_train[0:t], array_sub_train[0:t], noise_for_train[0:t]],\n",
    "      [y_train[0:t], train_keys[0:t]], epochs=epoch, validation_split=0.1,batch_size=batch)  # callbacks=callbacks_list, verbose=0)\n",
    "models.append(model_10)\n",
    "\n",
    "print(\"Time to Fit the Model\", time.time() - beg_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_length:  1024\n",
      "Ext Rate:   0.884930958575145\n",
      "Error: 0.05711426856113668\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(X_test_all[0:n_test-2]).reshape((-1, sample_size, 1))\n",
    "key_options = selecting_valid_fingerprints(key_length=key_length)  # we use 100 keys.\n",
    "test_keys = np.array(get_keys_for_fingerprinting_data(size=n_test, key_options=key_options))\n",
    "noise_for_test = np.squeeze(noise_for_test)\n",
    "pred = model_10.predict([x_test, test_keys, array_mult_test, array_sub_test, noise_for_test])\n",
    "\n",
    "fingerprint_x22, keys_true = pred[0], pred[1]\n",
    "ext_rate = compute_extract_rate(keys_true, true_keys=test_keys)\n",
    "print(\"key_length: \", key_length)\n",
    "print(\"Ext Rate:  \", ext_rate)\n",
    "key_bin_size = math.log2(key_length)\n",
    "error = bit_rate_error(keys_true,test_keys, key_bin_size)\n",
    "print('Error:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_length  = 512*32#1024*16\n",
    "beg = time.time()\n",
    "key_options = selecting_valid_fingerprints(key_length = key_length)\n",
    "X_train, y_train, train_keys = get_false_true_data(X_train_all, key_options, alpha=alpha)#get_only_true_data\n",
    "print(time.time() - beg)\n",
    "train_keys = np.array(train_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.563378095626831\n",
      "Date :  2019-12-02 16:37:25.433005\n",
      "Model 25000 is Built and Compiled in 73173.561874\n",
      "Time to Fit the Model 1575.06112074852\n",
      "key_length:  128\n",
      "Ext Rate:   0.9911947168300981\n",
      "Error: 0.004402641584950971\n",
      "5.344136476516724\n",
      "Date :  2019-12-02 17:05:27.457042\n",
      "Model 25000 is Built and Compiled in 1682.027918\n",
      "Time to Fit the Model 1624.5191638469696\n",
      "key_length:  512\n",
      "Ext Rate:   0.8931358815289173\n",
      "Error: 0.05263157894736842\n",
      "5.41720175743103\n",
      "Date :  2019-12-02 17:34:19.318069\n",
      "Model 25000 is Built and Compiled in 1731.909239\n",
      "Time to Fit the Model 1664.5833988189697\n",
      "key_length:  2048\n",
      "Ext Rate:   0.4790874524714829\n",
      "Error: 0.2621027161751596\n",
      "6.689152479171753\n",
      "Date :  2019-12-02 18:03:55.645071\n",
      "Model 25000 is Built and Compiled in 1776.367744\n",
      "Time to Fit the Model 1776.4521505832672\n",
      "key_length:  16384\n",
      "Ext Rate:   0.005003001801080648\n",
      "Error: 0.49611195288601734\n"
     ]
    }
   ],
   "source": [
    "keys = [128, 512, 512*4, 512*32]# I should run the 1024 too\n",
    "# key_length = 128\n",
    "for key_length in keys:\n",
    "    \n",
    "    n_true_train = 25000 \n",
    "    t = n_true_train\n",
    "    beg = time.time()\n",
    "    key_options = selecting_valid_fingerprints(key_length = key_length)\n",
    "    X_train, y_train, train_keys = get_false_true_data(X_train_all, key_options, alpha=alpha)#get_only_true_data\n",
    "    print(time.time() - beg)\n",
    "    train_keys = np.array(train_keys)\n",
    "    \n",
    "    print(\"Date : \", datetime.datetime.now())\n",
    "\n",
    "    model_10 = get_encoder_decoder_conv_dense_slice_two_conv(sample_size=sample_size, key_length=key_length, chunk=chunk, reg = r)\n",
    "    # losses.mean_squared_error# 0.001\n",
    "    adam =optimizers.Adam(lr = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-7, decay = 0.0, amsgrad=False)\n",
    "\n",
    "    model_10.compile(optimizer=adam, loss={'fingerprint': mean_pred_loss, 'key_hat': losses.categorical_crossentropy},\n",
    "              loss_weights={'fingerprint': x_fing_w, 'key_hat': key_hat_w},metrics=['accuracy'])#acc\n",
    "\n",
    "    # model.summary()\n",
    "    print(\"Model %s is Built and Compiled in %f\" % (t, time.time() - beg_time))\n",
    "    beg_time = time.time()\n",
    "\n",
    "    history_dense_decoder = model_10.fit([X_train[0:t], train_keys[0:t], array_mult_train[0:t], array_sub_train[0:t], noise_for_train[0:t]],\n",
    "          [y_train[0:t], train_keys[0:t]], epochs=epoch, validation_split=0.1,batch_size=batch,verbose=0)  # callbacks=callbacks_list, verbose=0)\n",
    "    #models.append(model_10)\n",
    "\n",
    "    print(\"Time to Fit the Model\", time.time() - beg_time)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_test = np.array(X_test_all[0:n_test-2]).reshape((-1, sample_size, 1))\n",
    "    key_options = selecting_valid_fingerprints(key_length=key_length)  # we use 100 keys.\n",
    "    test_keys = np.array(get_keys_for_fingerprinting_data(size=n_test, key_options=key_options))\n",
    "    noise_for_test = np.squeeze(noise_for_test)\n",
    "    pred = model_10.predict([x_test, test_keys, array_mult_test, array_sub_test, noise_for_test])\n",
    "\n",
    "    fingerprint_x22, keys_true = pred[0], pred[1]\n",
    "    ext_rate = compute_extract_rate(keys_true, true_keys=test_keys)\n",
    "    print(\"key_length: \", key_length)\n",
    "    print(\"Ext Rate:  \", ext_rate)\n",
    "    key_bin_size = math.log2(key_length)\n",
    "    error = bit_rate_error(keys_true,test_keys, key_bin_size)\n",
    "    print('Error:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "For 50,000\n",
    "[128, 512, 512*4, 512*32] \n",
    "\n",
    "key_length:  128\n",
    "Ext Rate:   0.9903942365419252\n",
    "Error: 0.0050601789645215705\n",
    "\n",
    "key_length:  512\n",
    "Ext Rate:   0.9479687812687613\n",
    "Error: 0.026571498454628334\n",
    "\n",
    "key_length:  2048\n",
    "Ext Rate:   0.8282969781869122\n",
    "Error: 0.08494187421543835\n",
    "\n",
    "key_length:  16384\n",
    "Ext Rate:   0.12607564538723234\n",
    "Error: 0.4401926870407959\n",
    "\n",
    "    \n",
    "train = 25, 000\n",
    "ext = [0.99, 0.89, 0.48,0.005]\n",
    "err = [0.004,0.05, 0.26,0.5]\n",
    "    \n",
    "train = 50, 000\n",
    "Ext_Rate = [0.99, 0.95, 0.83, 0.12]\n",
    "error = [0.005, 0.026, 0.085, 0.44]\n",
    "\n",
    "train = 100, 000\n",
    "ext_rate = [0.994, 0.95, 0.84, 0.5]\n",
    "error = [0.003, 0.02, 0.09,0.25 ]\n",
    "\n",
    "\n",
    "###bit_rate-error = 0.0007004202521512907 and ext_rate: 0.0.9987992795677406 for : 64\n",
    "### bit_rate-error = 0.0031161554075302324 and ext_rate: 0.9939963978387032 for : 128\n",
    "### bit_rate-error = 0.0095 and ext_rate: 0.9815889533720232 for : 256\n",
    "###  bit rate error:0.022 andExt Rate: 0.95    : 512\n",
    "### bit rate error: 0.009443777511004402  and ext_rate: 0.98: 512*2\n",
    "###bit rate error: 0.08749249549729837 and Ext Rate:   0.839703822293376  : 512*4\n",
    "###bit rate error: 0.093 and Ext Rate:  0.81   : 512*8\n",
    "### bit rate error: 0.248        Ext rate:   0.498       : 512*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#train = 25, 000\n",
    "ext = [0.99, 0.89,0.75, 0.48,0.005]\n",
    "err = [0.004,0.05, 0.26, 50]\n",
    "\n",
    "#train = 50, 000\n",
    "Ext_Rate = [0.99, 0.95,0.9, 0.83, 0.12]\n",
    "error = [0.005, 0.026, 0.085, 0.44]\n",
    "\n",
    "#train = 100, 000\n",
    "ext_rate = [0.994, 0.98,0.97 0.84, 0.5]\n",
    "error = [0.003, 0.02, 0.09,0.25 ]\n",
    "# Plot training & validation loss values history2_just_last_conv\n",
    "#plt.plot(history.history['loss'])\n",
    "plt.plot([128, 512,512*2, 512*4, 512*32],ext,marker='o',markersize=4)##our arch\n",
    "\n",
    "plt.plot([128, 512, 512*2,512*4, 512*32],Ext_Rate,marker='s',markersize=4)# with just one conv\n",
    "plt.plot([128, 512, 512*2,512*4, 512*32],ext_rate,marker='v',markersize=4)\n",
    "\n",
    "#plt.title('Model loss',fontsize=15)\n",
    "plt.ylabel('Extraction Rate',fontsize=15)\n",
    "plt.xlabel('Key Length',fontsize=15)\n",
    "plt.grid()\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.xscale('log',basex=2)\n",
    "legend = ['Train size = 25,000','Train size = 50,000','Train size = 100,000']\n",
    "plt.legend(legend,fontsize=14)#Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date :  2019-12-01 15:49:45.558450\n",
      "Model 99999 is Built and Compiled in 7.056780\n",
      "Train on 89999 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "89999/89999 [==============================] - 130s 1ms/step - loss: 1952.7144 - fingerprint_loss: 2.2552 - key_hat_loss: 9.7523 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 4.4445e-05 - val_loss: 1964.5285 - val_fingerprint_loss: 14.9786 - val_key_hat_loss: 9.7487 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 3.0000e-04\n",
      "Epoch 2/100\n",
      "89999/89999 [==============================] - 53s 589us/step - loss: 1917.8088 - fingerprint_loss: 2.8457 - key_hat_loss: 9.5748 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 1.6667e-04 - val_loss: 1979.8661 - val_fingerprint_loss: 4.6276 - val_key_hat_loss: 9.8774 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "89999/89999 [==============================] - 52s 578us/step - loss: 1892.1041 - fingerprint_loss: 2.8928 - key_hat_loss: 9.4460 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 5.0001e-04 - val_loss: 1996.5584 - val_fingerprint_loss: 1.4335 - val_key_hat_loss: 9.9774 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "89999/89999 [==============================] - 52s 575us/step - loss: 1860.9048 - fingerprint_loss: 2.5397 - key_hat_loss: 9.2918 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 7.8890e-04 - val_loss: 2021.5163 - val_fingerprint_loss: 1.4310 - val_key_hat_loss: 10.1024 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 1.0000e-04\n",
      "Epoch 5/100\n",
      "89999/89999 [==============================] - 52s 583us/step - loss: 1820.9867 - fingerprint_loss: 2.3648 - key_hat_loss: 9.0931 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.0015 - val_loss: 2054.7791 - val_fingerprint_loss: 0.8882 - val_key_hat_loss: 10.2720 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 1.0000e-04\n",
      "Epoch 6/100\n",
      "89999/89999 [==============================] - 52s 578us/step - loss: 1770.5357 - fingerprint_loss: 2.6216 - key_hat_loss: 8.8396 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.0030 - val_loss: 2089.9800 - val_fingerprint_loss: 2.3362 - val_key_hat_loss: 10.4402 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 1.0000e-04\n",
      "Epoch 7/100\n",
      "89999/89999 [==============================] - 51s 570us/step - loss: 1702.2522 - fingerprint_loss: 2.2964 - key_hat_loss: 8.4996 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.0061 - val_loss: 2099.7355 - val_fingerprint_loss: 6.0735 - val_key_hat_loss: 10.4717 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 2.0000e-04\n",
      "Epoch 8/100\n",
      "89999/89999 [==============================] - 52s 577us/step - loss: 1608.5930 - fingerprint_loss: 2.4084 - key_hat_loss: 8.0308 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.0115 - val_loss: 2088.5236 - val_fingerprint_loss: 8.7311 - val_key_hat_loss: 10.4024 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 2.0000e-04\n",
      "Epoch 9/100\n",
      "89999/89999 [==============================] - 54s 595us/step - loss: 1499.5940 - fingerprint_loss: 2.3458 - key_hat_loss: 7.4861 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.0220 - val_loss: 2057.4909 - val_fingerprint_loss: 15.5893 - val_key_hat_loss: 10.2138 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.0012\n",
      "Epoch 10/100\n",
      "89999/89999 [==============================] - 52s 579us/step - loss: 1347.5629 - fingerprint_loss: 1.6039 - key_hat_loss: 6.7296 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.0446 - val_loss: 1955.7190 - val_fingerprint_loss: 6.3256 - val_key_hat_loss: 9.7507 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.0023\n",
      "Epoch 11/100\n",
      "89999/89999 [==============================] - 51s 567us/step - loss: 1188.1740 - fingerprint_loss: 1.5056 - key_hat_loss: 5.9331 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.0809 - val_loss: 1652.5480 - val_fingerprint_loss: 2.9781 - val_key_hat_loss: 8.2531 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.0174\n",
      "Epoch 12/100\n",
      "89999/89999 [==============================] - 53s 588us/step - loss: 1050.6847 - fingerprint_loss: 1.6605 - key_hat_loss: 5.2449 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.1270 - val_loss: 1443.3063 - val_fingerprint_loss: 2.3381 - val_key_hat_loss: 7.2116 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.0474\n",
      "Epoch 13/100\n",
      "89999/89999 [==============================] - 51s 569us/step - loss: 931.5479 - fingerprint_loss: 1.4987 - key_hat_loss: 4.6501 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.1769 - val_loss: 1319.9948 - val_fingerprint_loss: 6.8472 - val_key_hat_loss: 6.5733 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.0769\n",
      "Epoch 14/100\n",
      "89999/89999 [==============================] - 52s 574us/step - loss: 829.3998 - fingerprint_loss: 1.8045 - key_hat_loss: 4.1381 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.2261 - val_loss: 1217.3881 - val_fingerprint_loss: 2.4103 - val_key_hat_loss: 6.0833 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.1039\n",
      "Epoch 15/100\n",
      "89999/89999 [==============================] - 51s 567us/step - loss: 749.1853 - fingerprint_loss: 1.1775 - key_hat_loss: 3.7400 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.2712 - val_loss: 1154.9709 - val_fingerprint_loss: 3.5134 - val_key_hat_loss: 5.7674 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.1279\n",
      "Epoch 16/100\n",
      "89999/89999 [==============================] - 51s 572us/step - loss: 678.0207 - fingerprint_loss: 1.6924 - key_hat_loss: 3.3816 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.3168 - val_loss: 1075.6024 - val_fingerprint_loss: 2.6509 - val_key_hat_loss: 5.3746 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.1602\n",
      "Epoch 17/100\n",
      "89999/89999 [==============================] - 53s 590us/step - loss: 618.2067 - fingerprint_loss: 1.4208 - key_hat_loss: 3.0839 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.3564 - val_loss: 1025.0590 - val_fingerprint_loss: 7.5474 - val_key_hat_loss: 5.0974 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.1830\n",
      "Epoch 18/100\n",
      "89999/89999 [==============================] - 53s 585us/step - loss: 565.4082 - fingerprint_loss: 1.6350 - key_hat_loss: 2.8188 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.3962 - val_loss: 972.3234 - val_fingerprint_loss: 1.2203 - val_key_hat_loss: 4.8642 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.2109\n",
      "Epoch 19/100\n",
      "89999/89999 [==============================] - 53s 592us/step - loss: 524.2753 - fingerprint_loss: 1.9442 - key_hat_loss: 2.6116 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.4275 - val_loss: 953.7410 - val_fingerprint_loss: 1.1926 - val_key_hat_loss: 4.7722 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.2207\n",
      "Epoch 20/100\n",
      "89999/89999 [==============================] - 52s 580us/step - loss: 489.9760 - fingerprint_loss: 1.5269 - key_hat_loss: 2.4424 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.4523 - val_loss: 907.8693 - val_fingerprint_loss: 2.6345 - val_key_hat_loss: 4.5364 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.2430\n",
      "Epoch 21/100\n",
      "89999/89999 [==============================] - 53s 594us/step - loss: 455.6876 - fingerprint_loss: 1.2216 - key_hat_loss: 2.2723 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.4809 - val_loss: 885.2786 - val_fingerprint_loss: 3.2658 - val_key_hat_loss: 4.4190 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.2574\n",
      "Epoch 22/100\n",
      "89999/89999 [==============================] - 55s 612us/step - loss: 426.8521 - fingerprint_loss: 1.4410 - key_hat_loss: 2.1271 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.5072 - val_loss: 877.5632 - val_fingerprint_loss: 2.9740 - val_key_hat_loss: 4.3813 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.2639\n",
      "Epoch 23/100\n",
      "89999/89999 [==============================] - 54s 601us/step - loss: 401.4431 - fingerprint_loss: 1.3255 - key_hat_loss: 2.0008 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.5285 - val_loss: 857.6005 - val_fingerprint_loss: 5.0478 - val_key_hat_loss: 4.2718 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.2786\n",
      "Epoch 24/100\n",
      "89999/89999 [==============================] - 54s 598us/step - loss: 379.6884 - fingerprint_loss: 1.1984 - key_hat_loss: 1.8925 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.5490 - val_loss: 843.2204 - val_fingerprint_loss: 1.8298 - val_key_hat_loss: 4.2173 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.2848\n",
      "Epoch 25/100\n",
      "89999/89999 [==============================] - 53s 594us/step - loss: 362.5635 - fingerprint_loss: 1.3754 - key_hat_loss: 1.8061 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.5625 - val_loss: 831.8401 - val_fingerprint_loss: 3.5759 - val_key_hat_loss: 4.1524 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.2997\n",
      "Epoch 26/100\n",
      "89999/89999 [==============================] - 54s 598us/step - loss: 345.5178 - fingerprint_loss: 1.2944 - key_hat_loss: 1.7211 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.5807 - val_loss: 808.4099 - val_fingerprint_loss: 3.1587 - val_key_hat_loss: 4.0378 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3085\n",
      "Epoch 27/100\n",
      "89999/89999 [==============================] - 53s 588us/step - loss: 329.8393 - fingerprint_loss: 1.1867 - key_hat_loss: 1.6433 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.5955 - val_loss: 801.8772 - val_fingerprint_loss: 2.7388 - val_key_hat_loss: 4.0076 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3177\n",
      "Epoch 28/100\n",
      "89999/89999 [==============================] - 51s 572us/step - loss: 314.6583 - fingerprint_loss: 1.1377 - key_hat_loss: 1.5674 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.6101 - val_loss: 786.3807 - val_fingerprint_loss: 4.6694 - val_key_hat_loss: 3.9209 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3287\n",
      "Epoch 29/100\n",
      "89999/89999 [==============================] - 53s 589us/step - loss: 298.4311 - fingerprint_loss: 1.0815 - key_hat_loss: 1.4869 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.6275 - val_loss: 777.0683 - val_fingerprint_loss: 0.8806 - val_key_hat_loss: 3.8946 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3313\n",
      "Epoch 30/100\n",
      "89999/89999 [==============================] - 53s 591us/step - loss: 287.5787 - fingerprint_loss: 1.2310 - key_hat_loss: 1.4316 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.6368 - val_loss: 760.2612 - val_fingerprint_loss: 1.6302 - val_key_hat_loss: 3.8048 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3481\n",
      "Epoch 31/100\n",
      "89999/89999 [==============================] - 51s 570us/step - loss: 278.3114 - fingerprint_loss: 1.1462 - key_hat_loss: 1.3856 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.6456 - val_loss: 767.6366 - val_fingerprint_loss: 2.2860 - val_key_hat_loss: 3.8352 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3443\n",
      "Epoch 32/100\n",
      "89999/89999 [==============================] - 53s 587us/step - loss: 265.9226 - fingerprint_loss: 1.6005 - key_hat_loss: 1.3217 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.6601 - val_loss: 747.6377 - val_fingerprint_loss: 0.9555 - val_key_hat_loss: 3.7447 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3582\n",
      "Epoch 33/100\n",
      "89999/89999 [==============================] - 53s 586us/step - loss: 257.7071 - fingerprint_loss: 1.2449 - key_hat_loss: 1.2823 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.6665 - val_loss: 747.2425 - val_fingerprint_loss: 1.2460 - val_key_hat_loss: 3.7415 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3563\n",
      "Epoch 34/100\n",
      "89999/89999 [==============================] - 52s 581us/step - loss: 249.3434 - fingerprint_loss: 0.9996 - key_hat_loss: 1.2416 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.6760 - val_loss: 739.3173 - val_fingerprint_loss: 2.3306 - val_key_hat_loss: 3.6949 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3685\n",
      "Epoch 35/100\n",
      "89999/89999 [==============================] - 53s 590us/step - loss: 242.1415 - fingerprint_loss: 1.2934 - key_hat_loss: 1.2042 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.6850 - val_loss: 753.2643 - val_fingerprint_loss: 2.5089 - val_key_hat_loss: 3.7656 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3658\n",
      "Epoch 36/100\n",
      "89999/89999 [==============================] - 53s 590us/step - loss: 235.0475 - fingerprint_loss: 1.3310 - key_hat_loss: 1.1686 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.6915 - val_loss: 738.2609 - val_fingerprint_loss: 2.1370 - val_key_hat_loss: 3.6930 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3767\n",
      "Epoch 37/100\n",
      "89999/89999 [==============================] - 52s 577us/step - loss: 227.0992 - fingerprint_loss: 1.1838 - key_hat_loss: 1.1296 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7022 - val_loss: 736.6996 - val_fingerprint_loss: 1.1053 - val_key_hat_loss: 3.6891 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3767\n",
      "Epoch 38/100\n",
      "89999/89999 [==============================] - 53s 590us/step - loss: 221.5485 - fingerprint_loss: 1.4273 - key_hat_loss: 1.1006 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7072 - val_loss: 725.9492 - val_fingerprint_loss: 0.8062 - val_key_hat_loss: 3.6372 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3853\n",
      "Epoch 39/100\n",
      "89999/89999 [==============================] - 54s 601us/step - loss: 215.8143 - fingerprint_loss: 1.2848 - key_hat_loss: 1.0726 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7129 - val_loss: 713.6970 - val_fingerprint_loss: 3.0383 - val_key_hat_loss: 3.5647 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3964\n",
      "Epoch 40/100\n",
      "89999/89999 [==============================] - 54s 605us/step - loss: 210.2790 - fingerprint_loss: 1.3128 - key_hat_loss: 1.0448 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7190 - val_loss: 723.1637 - val_fingerprint_loss: 2.2224 - val_key_hat_loss: 3.6165 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3961\n",
      "Epoch 41/100\n",
      "89999/89999 [==============================] - 53s 594us/step - loss: 203.9374 - fingerprint_loss: 1.3046 - key_hat_loss: 1.0133 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7265 - val_loss: 731.1811 - val_fingerprint_loss: 5.0226 - val_key_hat_loss: 3.6433 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3959\n",
      "Epoch 42/100\n",
      "89999/89999 [==============================] - 54s 603us/step - loss: 199.6016 - fingerprint_loss: 1.1018 - key_hat_loss: 0.9925 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7319 - val_loss: 713.0315 - val_fingerprint_loss: 0.9162 - val_key_hat_loss: 3.5733 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.3968\n",
      "Epoch 43/100\n",
      "89999/89999 [==============================] - 53s 586us/step - loss: 195.2699 - fingerprint_loss: 1.2627 - key_hat_loss: 0.9701 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7354 - val_loss: 716.0667 - val_fingerprint_loss: 2.0137 - val_key_hat_loss: 3.5840 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4045\n",
      "Epoch 44/100\n",
      "89999/89999 [==============================] - 54s 598us/step - loss: 190.7239 - fingerprint_loss: 0.8900 - key_hat_loss: 0.9492 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7406 - val_loss: 716.6362 - val_fingerprint_loss: 3.9260 - val_key_hat_loss: 3.5760 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4068\n",
      "Epoch 45/100\n",
      "89999/89999 [==============================] - 54s 598us/step - loss: 187.9860 - fingerprint_loss: 1.2796 - key_hat_loss: 0.9334 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7453 - val_loss: 710.7545 - val_fingerprint_loss: 2.6528 - val_key_hat_loss: 3.5520 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4047\n",
      "Epoch 46/100\n",
      "89999/89999 [==============================] - 53s 591us/step - loss: 183.0957 - fingerprint_loss: 1.1084 - key_hat_loss: 0.9098 - fingerprint_accuracy: 3.7037e-08 - key_hat_accuracy: 0.7489 - val_loss: 708.0841 - val_fingerprint_loss: 0.9728 - val_key_hat_loss: 3.5471 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4120\n",
      "Epoch 47/100\n",
      "89999/89999 [==============================] - 54s 599us/step - loss: 179.6699 - fingerprint_loss: 1.3594 - key_hat_loss: 0.8914 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7547 - val_loss: 706.4326 - val_fingerprint_loss: 2.5884 - val_key_hat_loss: 3.5302 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4175\n",
      "Epoch 48/100\n",
      "89999/89999 [==============================] - 56s 625us/step - loss: 174.1884 - fingerprint_loss: 1.1565 - key_hat_loss: 0.8651 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7600 - val_loss: 707.7170 - val_fingerprint_loss: 0.8675 - val_key_hat_loss: 3.5455 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4190\n",
      "Epoch 49/100\n",
      "89999/89999 [==============================] - 55s 614us/step - loss: 171.6691 - fingerprint_loss: 1.1130 - key_hat_loss: 0.8528 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7626 - val_loss: 715.4243 - val_fingerprint_loss: 3.3916 - val_key_hat_loss: 3.5731 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4129\n",
      "Epoch 50/100\n",
      "89999/89999 [==============================] - 51s 571us/step - loss: 168.8068 - fingerprint_loss: 0.9886 - key_hat_loss: 0.8391 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7675 - val_loss: 693.4044 - val_fingerprint_loss: 1.1317 - val_key_hat_loss: 3.4740 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4239\n",
      "Epoch 51/100\n",
      "89999/89999 [==============================] - 51s 566us/step - loss: 168.3416 - fingerprint_loss: 1.3234 - key_hat_loss: 0.8350 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7675 - val_loss: 702.6983 - val_fingerprint_loss: 1.0279 - val_key_hat_loss: 3.5221 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4167\n",
      "Epoch 52/100\n",
      "89999/89999 [==============================] - 50s 557us/step - loss: 163.4705 - fingerprint_loss: 1.0101 - key_hat_loss: 0.8123 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7713 - val_loss: 696.6607 - val_fingerprint_loss: 3.6709 - val_key_hat_loss: 3.4779 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4352\n",
      "Epoch 53/100\n",
      "89999/89999 [==============================] - 48s 528us/step - loss: 158.5099 - fingerprint_loss: 1.0898 - key_hat_loss: 0.7870 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7801 - val_loss: 699.5238 - val_fingerprint_loss: 2.1731 - val_key_hat_loss: 3.4997 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4321\n",
      "Epoch 54/100\n",
      "89999/89999 [==============================] - 47s 519us/step - loss: 157.6104 - fingerprint_loss: 1.2004 - key_hat_loss: 0.7820 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7789 - val_loss: 696.1632 - val_fingerprint_loss: 0.8121 - val_key_hat_loss: 3.4887 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4374\n",
      "Epoch 55/100\n",
      "89999/89999 [==============================] - 48s 535us/step - loss: 154.7786 - fingerprint_loss: 1.1501 - key_hat_loss: 0.7681 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7837 - val_loss: 692.5477 - val_fingerprint_loss: 3.8879 - val_key_hat_loss: 3.4537 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4435\n",
      "Epoch 56/100\n",
      "89999/89999 [==============================] - 48s 534us/step - loss: 153.7332 - fingerprint_loss: 1.0526 - key_hat_loss: 0.7634 - fingerprint_accuracy: 3.7037e-08 - key_hat_accuracy: 0.7850 - val_loss: 695.6844 - val_fingerprint_loss: 1.7894 - val_key_hat_loss: 3.4827 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4407\n",
      "Epoch 57/100\n",
      "89999/89999 [==============================] - 48s 539us/step - loss: 150.9584 - fingerprint_loss: 1.0266 - key_hat_loss: 0.7497 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7879 - val_loss: 689.0276 - val_fingerprint_loss: 0.8081 - val_key_hat_loss: 3.4514 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4432\n",
      "Epoch 58/100\n",
      "89999/89999 [==============================] - 47s 521us/step - loss: 147.5908 - fingerprint_loss: 1.0210 - key_hat_loss: 0.7328 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7920 - val_loss: 680.9683 - val_fingerprint_loss: 1.5318 - val_key_hat_loss: 3.4065 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4481\n",
      "Epoch 59/100\n",
      "89999/89999 [==============================] - 48s 530us/step - loss: 144.9433 - fingerprint_loss: 1.1028 - key_hat_loss: 0.7192 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7953 - val_loss: 685.8008 - val_fingerprint_loss: 1.7661 - val_key_hat_loss: 3.4308 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4507\n",
      "Epoch 60/100\n",
      "89999/89999 [==============================] - 45s 502us/step - loss: 143.3010 - fingerprint_loss: 0.8895 - key_hat_loss: 0.7119 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7973 - val_loss: 694.0539 - val_fingerprint_loss: 1.4261 - val_key_hat_loss: 3.4734 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4492\n",
      "Epoch 61/100\n",
      "89999/89999 [==============================] - 46s 510us/step - loss: 142.6453 - fingerprint_loss: 1.2160 - key_hat_loss: 0.7071 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.7986 - val_loss: 688.7770 - val_fingerprint_loss: 0.8159 - val_key_hat_loss: 3.4476 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4468\n",
      "Epoch 62/100\n",
      "89999/89999 [==============================] - 47s 518us/step - loss: 137.4777 - fingerprint_loss: 1.2865 - key_hat_loss: 0.6809 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8057 - val_loss: 671.6918 - val_fingerprint_loss: 1.9965 - val_key_hat_loss: 3.3552 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4541\n",
      "Epoch 63/100\n",
      "89999/89999 [==============================] - 46s 506us/step - loss: 137.3350 - fingerprint_loss: 1.2950 - key_hat_loss: 0.6802 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8052 - val_loss: 684.0085 - val_fingerprint_loss: 2.6959 - val_key_hat_loss: 3.4173 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4521\n",
      "Epoch 64/100\n",
      "89999/89999 [==============================] - 48s 530us/step - loss: 135.9183 - fingerprint_loss: 1.2796 - key_hat_loss: 0.6731 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8068 - val_loss: 687.2389 - val_fingerprint_loss: 0.8289 - val_key_hat_loss: 3.4423 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4537\n",
      "Epoch 65/100\n",
      "89999/89999 [==============================] - 46s 509us/step - loss: 133.9899 - fingerprint_loss: 0.9740 - key_hat_loss: 0.6650 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8089 - val_loss: 686.4366 - val_fingerprint_loss: 0.9296 - val_key_hat_loss: 3.4382 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4590\n",
      "Epoch 66/100\n",
      "89999/89999 [==============================] - 47s 521us/step - loss: 131.7248 - fingerprint_loss: 1.0677 - key_hat_loss: 0.6533 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8122 - val_loss: 681.8825 - val_fingerprint_loss: 3.1512 - val_key_hat_loss: 3.4018 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4600\n",
      "Epoch 67/100\n",
      "89999/89999 [==============================] - 48s 536us/step - loss: 130.3129 - fingerprint_loss: 1.1651 - key_hat_loss: 0.6457 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8152 - val_loss: 676.1483 - val_fingerprint_loss: 1.8180 - val_key_hat_loss: 3.3801 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4571\n",
      "Epoch 68/100\n",
      "89999/89999 [==============================] - 46s 513us/step - loss: 129.3244 - fingerprint_loss: 1.3946 - key_hat_loss: 0.6395 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8156 - val_loss: 678.8158 - val_fingerprint_loss: 3.6921 - val_key_hat_loss: 3.3832 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4652\n",
      "Epoch 69/100\n",
      "89999/89999 [==============================] - 47s 517us/step - loss: 127.0845 - fingerprint_loss: 1.0866 - key_hat_loss: 0.6299 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8193 - val_loss: 680.7325 - val_fingerprint_loss: 0.8288 - val_key_hat_loss: 3.4060 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4620\n",
      "Epoch 70/100\n",
      "89999/89999 [==============================] - 47s 519us/step - loss: 126.9917 - fingerprint_loss: 1.1264 - key_hat_loss: 0.6292 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8179 - val_loss: 674.8152 - val_fingerprint_loss: 0.8381 - val_key_hat_loss: 3.3799 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4658\n",
      "Epoch 71/100\n",
      "89999/89999 [==============================] - 48s 532us/step - loss: 124.8383 - fingerprint_loss: 0.8937 - key_hat_loss: 0.6196 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8217 - val_loss: 677.9996 - val_fingerprint_loss: 3.9456 - val_key_hat_loss: 3.3777 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4680\n",
      "Epoch 72/100\n",
      "89999/89999 [==============================] - 47s 523us/step - loss: 123.0931 - fingerprint_loss: 1.4824 - key_hat_loss: 0.6080 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8241 - val_loss: 682.4295 - val_fingerprint_loss: 4.7200 - val_key_hat_loss: 3.3994 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4726\n",
      "Epoch 73/100\n",
      "89999/89999 [==============================] - 46s 515us/step - loss: 122.0990 - fingerprint_loss: 1.0272 - key_hat_loss: 0.6054 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8240 - val_loss: 682.7744 - val_fingerprint_loss: 3.5103 - val_key_hat_loss: 3.4084 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4695\n",
      "Epoch 74/100\n",
      "89999/89999 [==============================] - 48s 532us/step - loss: 121.0682 - fingerprint_loss: 1.0600 - key_hat_loss: 0.6000 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8253 - val_loss: 679.4244 - val_fingerprint_loss: 3.7092 - val_key_hat_loss: 3.3876 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4715\n",
      "Epoch 75/100\n",
      "89999/89999 [==============================] - 46s 516us/step - loss: 119.6437 - fingerprint_loss: 1.1185 - key_hat_loss: 0.5926 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8288 - val_loss: 674.1907 - val_fingerprint_loss: 1.2464 - val_key_hat_loss: 3.3770 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4747\n",
      "Epoch 76/100\n",
      "89999/89999 [==============================] - 46s 513us/step - loss: 117.7574 - fingerprint_loss: 0.9527 - key_hat_loss: 0.5839 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8313 - val_loss: 670.4595 - val_fingerprint_loss: 0.7418 - val_key_hat_loss: 3.3577 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4789\n",
      "Epoch 77/100\n",
      "89999/89999 [==============================] - 46s 516us/step - loss: 117.1448 - fingerprint_loss: 1.2045 - key_hat_loss: 0.5795 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8304 - val_loss: 675.4648 - val_fingerprint_loss: 0.8073 - val_key_hat_loss: 3.3814 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4780\n",
      "Epoch 78/100\n",
      "89999/89999 [==============================] - 51s 563us/step - loss: 115.0981 - fingerprint_loss: 1.1140 - key_hat_loss: 0.5699 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8348 - val_loss: 668.2981 - val_fingerprint_loss: 1.8009 - val_key_hat_loss: 3.3390 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4794\n",
      "Epoch 79/100\n",
      "89999/89999 [==============================] - 54s 598us/step - loss: 114.0776 - fingerprint_loss: 1.0901 - key_hat_loss: 0.5649 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8338 - val_loss: 678.6743 - val_fingerprint_loss: 1.1364 - val_key_hat_loss: 3.3903 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4749\n",
      "Epoch 80/100\n",
      "89999/89999 [==============================] - 51s 567us/step - loss: 111.4986 - fingerprint_loss: 0.8919 - key_hat_loss: 0.5530 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8385 - val_loss: 672.3519 - val_fingerprint_loss: 1.0277 - val_key_hat_loss: 3.3622 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4839\n",
      "Epoch 81/100\n",
      "89999/89999 [==============================] - 52s 575us/step - loss: 112.2902 - fingerprint_loss: 1.1639 - key_hat_loss: 0.5555 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8373 - val_loss: 659.1895 - val_fingerprint_loss: 2.7819 - val_key_hat_loss: 3.2933 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4853\n",
      "Epoch 82/100\n",
      "89999/89999 [==============================] - 54s 598us/step - loss: 110.5172 - fingerprint_loss: 0.9978 - key_hat_loss: 0.5474 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8398 - val_loss: 677.9028 - val_fingerprint_loss: 2.1576 - val_key_hat_loss: 3.3846 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4823\n",
      "Epoch 83/100\n",
      "89999/89999 [==============================] - 52s 583us/step - loss: 110.6728 - fingerprint_loss: 1.0025 - key_hat_loss: 0.5483 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8401 - val_loss: 659.3404 - val_fingerprint_loss: 1.4315 - val_key_hat_loss: 3.2953 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4933\n",
      "Epoch 84/100\n",
      "89999/89999 [==============================] - 50s 555us/step - loss: 108.2245 - fingerprint_loss: 1.0446 - key_hat_loss: 0.5357 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8441 - val_loss: 655.7616 - val_fingerprint_loss: 2.7766 - val_key_hat_loss: 3.2747 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4936\n",
      "Epoch 85/100\n",
      "89999/89999 [==============================] - 50s 556us/step - loss: 107.8465 - fingerprint_loss: 1.0442 - key_hat_loss: 0.5338 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8438 - val_loss: 670.3387 - val_fingerprint_loss: 1.4331 - val_key_hat_loss: 3.3517 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4912\n",
      "Epoch 86/100\n",
      "89999/89999 [==============================] - 55s 606us/step - loss: 107.3467 - fingerprint_loss: 1.0543 - key_hat_loss: 0.5315 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8435 - val_loss: 668.3020 - val_fingerprint_loss: 1.9650 - val_key_hat_loss: 3.3393 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4890\n",
      "Epoch 87/100\n",
      "89999/89999 [==============================] - 54s 604us/step - loss: 106.4628 - fingerprint_loss: 1.0427 - key_hat_loss: 0.5268 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8461 - val_loss: 664.4121 - val_fingerprint_loss: 2.4192 - val_key_hat_loss: 3.3182 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4926\n",
      "Epoch 88/100\n",
      "89999/89999 [==============================] - 51s 570us/step - loss: 105.2757 - fingerprint_loss: 1.0399 - key_hat_loss: 0.5211 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8478 - val_loss: 681.1467 - val_fingerprint_loss: 1.0102 - val_key_hat_loss: 3.4097 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4877\n",
      "Epoch 89/100\n",
      "89999/89999 [==============================] - 53s 587us/step - loss: 104.9044 - fingerprint_loss: 0.9621 - key_hat_loss: 0.5196 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8477 - val_loss: 670.7176 - val_fingerprint_loss: 0.8234 - val_key_hat_loss: 3.3559 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4931\n",
      "Epoch 90/100\n",
      "89999/89999 [==============================] - 52s 575us/step - loss: 102.8080 - fingerprint_loss: 1.0687 - key_hat_loss: 0.5085 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8503 - val_loss: 648.7334 - val_fingerprint_loss: 0.9345 - val_key_hat_loss: 3.2504 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4990\n",
      "Epoch 91/100\n",
      "89999/89999 [==============================] - 53s 584us/step - loss: 101.4195 - fingerprint_loss: 0.9951 - key_hat_loss: 0.5020 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8520 - val_loss: 662.0015 - val_fingerprint_loss: 1.7550 - val_key_hat_loss: 3.3085 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.5017\n",
      "Epoch 92/100\n",
      "89999/89999 [==============================] - 54s 602us/step - loss: 100.6274 - fingerprint_loss: 0.9546 - key_hat_loss: 0.4983 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8523 - val_loss: 645.4742 - val_fingerprint_loss: 1.0777 - val_key_hat_loss: 3.2306 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.5046\n",
      "Epoch 93/100\n",
      "89999/89999 [==============================] - 52s 580us/step - loss: 100.4488 - fingerprint_loss: 1.0351 - key_hat_loss: 0.4970 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8530 - val_loss: 660.1305 - val_fingerprint_loss: 1.6023 - val_key_hat_loss: 3.2997 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.4993\n",
      "Epoch 94/100\n",
      "89999/89999 [==============================] - 51s 570us/step - loss: 99.0652 - fingerprint_loss: 0.9158 - key_hat_loss: 0.4907 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8545 - val_loss: 652.5212 - val_fingerprint_loss: 2.0838 - val_key_hat_loss: 3.2627 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.5041\n",
      "Epoch 95/100\n",
      "89999/89999 [==============================] - 54s 595us/step - loss: 99.2232 - fingerprint_loss: 1.0689 - key_hat_loss: 0.4905 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8544 - val_loss: 663.0459 - val_fingerprint_loss: 2.0329 - val_key_hat_loss: 3.3126 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.5020\n",
      "Epoch 96/100\n",
      "89999/89999 [==============================] - 52s 580us/step - loss: 98.5326 - fingerprint_loss: 1.0446 - key_hat_loss: 0.4873 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8554 - val_loss: 662.6037 - val_fingerprint_loss: 1.3031 - val_key_hat_loss: 3.3150 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.5035\n",
      "Epoch 97/100\n",
      "89999/89999 [==============================] - 52s 576us/step - loss: 96.5827 - fingerprint_loss: 1.0568 - key_hat_loss: 0.4776 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8584 - val_loss: 660.0168 - val_fingerprint_loss: 1.5999 - val_key_hat_loss: 3.3004 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.5068\n",
      "Epoch 98/100\n",
      "89999/89999 [==============================] - 51s 571us/step - loss: 95.3222 - fingerprint_loss: 1.0086 - key_hat_loss: 0.4715 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8612 - val_loss: 656.6594 - val_fingerprint_loss: 0.8759 - val_key_hat_loss: 3.2878 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.5095\n",
      "Epoch 99/100\n",
      "89999/89999 [==============================] - 53s 586us/step - loss: 96.6606 - fingerprint_loss: 1.1468 - key_hat_loss: 0.4773 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8588 - val_loss: 644.0048 - val_fingerprint_loss: 1.1874 - val_key_hat_loss: 3.2225 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.5079\n",
      "Epoch 100/100\n",
      "89999/89999 [==============================] - 52s 574us/step - loss: 95.2770 - fingerprint_loss: 1.1239 - key_hat_loss: 0.4706 - fingerprint_accuracy: 0.0000e+00 - key_hat_accuracy: 0.8591 - val_loss: 646.4881 - val_fingerprint_loss: 0.7627 - val_key_hat_loss: 3.2397 - val_fingerprint_accuracy: 0.0000e+00 - val_key_hat_accuracy: 0.5008\n",
      "Time to Fit the Model 5633.225780963898\n"
     ]
    }
   ],
   "source": [
    "#regs = [1e-6]#0.01, 0.5, 1e-3, 1e-4, 1e-5, 1e-6 too. Looks like 1e-6 is the best (maybe 1e-7, 1e-8 too)\n",
    "#models = []\n",
    "r = 1e-6\n",
    "\n",
    "n_true_train, n_test = 100000-1, 5000-1\n",
    "t = n_true_train\n",
    "beg_time = time.time()\n",
    "x_fing_w, key_hat_w, epoch, batch = 1, 200, 100, 512\n",
    "std, max_fing_delay = 1, alpha\n",
    "\n",
    "print(\"Date : \", datetime.datetime.now())\n",
    "\n",
    "model_10 = get_encoder_decoder_conv_dense_slice_two_conv(sample_size=sample_size, key_length=key_length, chunk=chunk, reg = r)\n",
    "# losses.mean_squared_error# 0.001\n",
    "adam =optimizers.Adam(lr = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-7, decay = 0.0, amsgrad=False)\n",
    "\n",
    "model_10.compile(optimizer=adam, loss={'fingerprint': mean_pred_loss, 'key_hat': losses.categorical_crossentropy},\n",
    "          loss_weights={'fingerprint': x_fing_w, 'key_hat': key_hat_w},metrics=['accuracy'])#acc\n",
    "\n",
    "# model.summary()\n",
    "print(\"Model %s is Built and Compiled in %f\" % (t, time.time() - beg_time))\n",
    "beg_time = time.time()\n",
    "\n",
    "history_dense_decoder = model_10.fit([X_train[0:t], train_keys[0:t], array_mult_train[0:t], array_sub_train[0:t], noise_for_train[0:t]],\n",
    "      [y_train[0:t], train_keys[0:t]], epochs=epoch, validation_split=0.1,batch_size=batch)  # callbacks=callbacks_list, verbose=0)\n",
    "models.append(model_10)\n",
    "\n",
    "print(\"Time to Fit the Model\", time.time() - beg_time)\n",
    "\n",
    "#### This is when we test encoder and decoder together using the same model: model_encoder_decoder\n",
    "\n",
    "    \n",
    "# avg_d, max_d = compute_delay_on_each_packet(fingerprint_x2)\n",
    "\n",
    "#fingerprint_x2 = adjust_fingerprint_delays(fingerprint_x2)\n",
    "#avg_d, max_d = compute_delay_on_packets(fingerprint_x2)\n",
    "#learning_rates = [1e-3]# e-3 reached 0.21 when epochs = 50 [1e-2, e-3, e-5,e-4,1e-5, 5e-3, 2e-3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ext Rate:   0.49809885931558934\n",
      "Error: 0.24860630664112754\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(X_test_all[0:n_test-2]).reshape((-1, sample_size, 1))\n",
    "key_options = selecting_valid_fingerprints(key_length=key_length)  # we use 100 keys.\n",
    "test_keys = np.array(get_keys_for_fingerprinting_data(size=n_test, key_options=key_options))\n",
    "noise_for_test = np.squeeze(noise_for_test)\n",
    "pred = model_10.predict([x_test, test_keys, array_mult_test, array_sub_test, noise_for_test])\n",
    "\n",
    "fingerprint_x22, keys_true = pred[0], pred[1]\n",
    "ext_rate = compute_extract_rate(keys_true, true_keys=test_keys)\n",
    "\n",
    "print(\"Ext Rate:  \", ext_rate)\n",
    "###bit_rate-error = 0.0007004202521512907 and ext_rate: 0.0.9987992795677406 for : 64\n",
    "### bit_rate-error = 0.0031161554075302324 and ext_rate: 0.9939963978387032 for : 128\n",
    "### bit_rate-error = 0.0095 and ext_rate: 0.9815889533720232 for : 256\n",
    "###  bit rate error:0.022 andExt Rate: 0.95    : 512\n",
    "### bit rate error: 0.009443777511004402  and ext_rate: 0.98: 512*2\n",
    "###bit rate error: 0.08749249549729837 and Ext Rate:   0.839703822293376  : 512*4\n",
    "###bit rate error: 0.093 and Ext Rate:  0.81   : 512*8\n",
    "### bit rate error: 0.248        Ext rate:   0.498       : 512*32\n",
    "key_bin_size = math.log2(key_length)\n",
    "error = bit_rate_error(keys_true,test_keys, key_bin_size)\n",
    "print('Error:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_length = 1024 # to test sample size\n",
    "sample_size = [100, 200]#, 600, 900]\n",
    "\n",
    "for sample size 100 and train 100,000:\n",
    " key_length:  1024\n",
    "Ext Rate:   0.48789273564138486\n",
    "Error: 0.25533319991995196   \n",
    "    \n",
    "for sample size 100 and train 25 000\n",
    "Ext Rate:   0.18551130678407043\n",
    "Error: 0.40908545127076246\n",
    "for sample size 200  train 100, 00\n",
    "key_length:  1024\n",
    "Ext Rate:   0.816690014008405\n",
    "Error: 0.09115469281568941\n",
    "\n",
    "for sample size 200  train 25, 00\n",
    "key_length:  1024\n",
    "Ext Rate:   0.49109465679407643\n",
    "Error: 0.25451270762457473\n",
    "\n",
    "sample size 300\n",
    "### bit rate error: 0.009443777511004402  and ext_rate: 0.98: 512*2\n",
    "\n",
    "\n",
    "sample 400\n",
    "key_length:  1024\n",
    "Ext Rate:   0.9775865519311587\n",
    "Error: 0.0114268561136682\n",
    "\n",
    "25000:\n",
    "Ext Rate:   0.884930958575145\n",
    "Error: 0.05711426856113668   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_25000 = [0.18, 0.49, 0.81, 0.88]\n",
    "sample_1000 = [0.49, 0.82, 0.98, 0.98]\n",
    "sample_sizes = [100, 200, 300, 400]\n",
    "\n",
    "err_25 = [0.4, 0.25, 0.08, 0.04]\n",
    "err_100 = [0.25, 0.09, 0.009, 0.008]\n",
    "\n",
    "plt.plot(sample_sizes, sample_25000,marker='o',markersize=4)\n",
    "plt.plot([sample_sizes, sample_1000,marker='o',markersize=4)\n",
    "\n",
    "plt.ylabel('Extraction Rate',fontsize=15)\n",
    "plt.xlabel('Flow Length',fontsize=15)\n",
    "plt.grid()\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "#plt.xscale('log',basex=2)\n",
    "legend = ['Train size = 25,000','Train size = 100,000']\n",
    "plt.legend(legend,fontsize=14)#Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot training & validation loss values history2_just_last_conv\n",
    "#plt.plot(history.history['loss'])\n",
    "plt.plot(histories[0].history['val_key_hat_loss'],marker='o',markersize=2)##our arch\n",
    "#plt.plot(history2_no_last_conv.history['val_key_hat_loss'],marker='s',markersize=5)#without last conv\n",
    "#plt.plot(history2_just_last_conv.history['val_key_hat_loss'],marker='s',markersize=5)# with last conv only\n",
    "plt.plot(histories[1].history['val_key_hat_loss'],marker='s',markersize=2)# with just one conv\n",
    "plt.plot(histories[2].history['val_key_hat_loss'],marker='v',markersize=2)\n",
    "plt.plot(histories[3].history['val_key_hat_loss'],marker='*',markersize=2)\n",
    "plt.plot(histories[4].history['val_key_hat_loss'],marker='d',markersize=2)\n",
    "plt.plot(histories[5].history['val_key_hat_loss'],marker='X',markersize=2)\n",
    "plt.plot(histories[6].history['val_key_hat_loss'],marker='H',markersize=2)\n",
    "#plt.title('Model loss',fontsize=15)\n",
    "plt.ylabel('Loss',fontsize=15)\n",
    "plt.xlabel('Epoch',fontsize=15)\n",
    "plt.grid()\n",
    "\n",
    "legend = ['one_dense', 'zero_conv', 'one_conv', 'two_conv', 'one_dense_dec','zero_dense_dec','three_dense_dec']\n",
    "plt.legend(legend,fontsize=10)#Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot training & validation loss values\n",
    "#plt.plot(history.history['loss'])\n",
    "plt.plot(histories[0].history['val_key_hat_accuracy'],marker='o',markersize=2)\n",
    "plt.plot(histories[1].history['val_key_hat_accuracy'],marker='s',markersize=2)\n",
    "plt.plot(histories[2].history['val_key_hat_accuracy'],marker='v',markersize=2)\n",
    "plt.plot(histories[3].history['val_key_hat_accuracy'],marker='*',markersize=2)\n",
    "plt.plot(histories[4].history['val_key_hat_accuracy'],marker='d',markersize=2)\n",
    "plt.plot(histories[5].history['val_key_hat_accuracy'],marker='X',markersize=2)\n",
    "plt.plot(histories[6].history['val_key_hat_accuracy'],marker='H',markersize=2)\n",
    "\n",
    "#plt.title('Model Accuracy',fontsize=15)\n",
    "plt.ylabel('Accuracy',fontsize=15)\n",
    "plt.xlabel('Epoch',fontsize=15)\n",
    "plt.grid()\n",
    "legend = ['one_dense', 'zero_conv', 'one_conv', 'two_conv', 'one_dense_dec','zero_dense_dec','three_dense_dec']\n",
    "\n",
    "plt.legend(legend,fontsize=10)#Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "tar = open('val_acc_three_dense_dec.txt','w')\n",
    "write_array_to_file(histories[6].history['val_key_hat_accuracy'], tar, \" \")\n",
    "tar = open('val_loss_three_dense_dec.txt','w')\n",
    "write_array_to_file(histories[6].history['val_key_hat_loss'], tar, \" \")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEkCAYAAADJiI15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3hUZdr48e+dSU+ABEILEEBFisCCZsWCEkGxrAJrVwTxtf8WLGtfG764q6/lfW2ra2Gxrl0BsewqgkaWXlSqiFKkBQSSACH1/v1xZthJMoFkMuFMuT/XNVcy5zxz5j4ZOPc85TyPqCrGGGNiU5zbARhjjHGPJQFjjIlhlgSMMSaGWRIwxpgYZknAGGNimCUBY4yJYZYEjPEjInkioiIyvpHHGeM9zph6lh/vLZ/XmPc1pqEsCRhXeS98KiJVInL4AcrN8Cs75hCGaExUsyRgwkEFIMCVgXaKSDcgz1vOGBNClgRMONgKLACuEJH4APuv8v786NCFZExssCRgwsWLQDvgbP+NIpIAjAH+DSyv68Ui0k1EXhWRjSJSJiKbvM+71VG+rYhMFJGtIlIiIktE5PIDBSgiLUXkIRFZ4X1NoYhMF5GhDT3ZhhCRISLymYjsEJFSEflBRB4WkRYByh4mIi+IyI/eGHeIyPci8jcRaeVXLlFEbhCRRSKyU0T2ishaEZkiIqc25fmY8BLoW5cxbngT+F+cb/2T/bYPA9oAdwBHBHqhiPwW+AJoBkzFSRY9gMuA4SJyqqrO9yufhZNUDgO+8T7aA38D/lXHe3QGZgJdgHzgMyANJ2l9JiLXquqLDT/tAxORa4HngD3Au0ABTtPYHcA5InKiqu7ylm0PzAeaA58A7wPJQFdgFPAM8Kv30C8DlwBLgVeBEiAbGAicgfP3NLFAVe1hD9cegAK/eH9/Cafdv6Pf/s+AQiAVeNBbfozffgFWeLePrHHsi7zbVwJxfttf8G7/vxrlc4Fy777xNfbNBKqAi2tszwCW4FxE2/ptH1Mz1oP8HcZ7y+f5besMlAJFQI8a5Z/1ln/Bb9s477YbAxw/DUjx/t7Cey4LAE+Asq3c/ndhj0P3sOYgE05eBDzAf8H+b9+nAW+o6t46XnMCzrf+2ar6hv8OVX0b51t+d5xvuL7mpZFAMc6F17/8AqDaMbyv+Q0wCHhfVd+q8ZpdwP0437jPq/+p1stlQCLwjKqurLHvbpxzGCUiSTX2ldQ8kKruUVXfdsVJnqU4yaBm2V9rbjPRy5KACRuqOhf4HvgvEYnDaRqKw0kOdTna+/PLOvb7tvf3/uyBU6tYoqqFAcrPDLDteO/PFt7x/NUegK9PoOcB4gxGneemqjuBxTjJp4d381RgN/BXEXlfRK4RkaNERGq8tgink/0EYImI3Ccip4hIaojjNxHA+gRMuHkReAo4E7gCWKiqiw9Q3tc5urmO/b7tGTXKb62j/JYA23wdqqd5H3VJP8C+YDTo3FR1nYgci1PDOQM417t/g4g8pqpP+b32Ipx+hUuBB7zb9onIe8CtqlrX38dEGasJmHDzGk5zxt+ADjjt9wfi+zbfro797WuU8/1sW0f5QMfxveZGVZUDPK44SKwN1dBzQ1VXqOpFOIkrF7gT5//5kyJypV+5ElUdr6pHAjk4TU/feH++F9KzMGHNkoAJK9429veAjjgjYt48yEt8tYS8Ovaf4v25yPtzJbAX6BdoiGUdx5nj/XnSQWIJtTrPTUQygH7APpyO8WpUtUJVF6rq/+CMAgIYEehNVHWDtz/ldOBHYKD/cFIT3SwJmHB0D/B74HRVLT5I2VnAKpwL1/n+O7zPTwJ+wPmWi6qW43T+NqNGx7CI5OJ0Glfj7TDOB84Vkf8KFISI9BGRNgc9s4Z5HWe00jgRqTk8dgLOUNDXVbXUG8MxdSQ2X61nr7dcaxHpE6BcGk6TVgVQFoL4TQSwPgETdlR1PbC+nmXVe5PX58DbIjIF59t+d5xvvsXAaFX1HwXzJ2AIcJP3wu+7T+AinPH1wwK81aU4HbQTReQGYC6wC6fG0hfojdOBXNCwsz3gua0VkZuAvwKLROQdYBvOSKXjved5h99LRgHXisg3wBpgJ3A4cA7OSKAnvOU6AItF5HvgO2ADTkI5G6fp6al6JF8TJSwJmIinqnO9N4zdA5yKc9HbjtOUNEFVV9Uov11ETgT+4i2bi1ObuB5YS4AkoKq/iMgxOGPxz8OpMXhwOpKXA0/jjGwK9bk9KyI/Ard63zcV56L9KPAXb/OZz5tAEs6on2OAFGAj8BbwuKou9ZZbizOsNQ+nuSwL2IHzN7jTW97ECFHn5hBjjDExyPoEjDEmhlkSMMaYGGZJwBhjYpglAWOMiWERNzooKytLu3Tp4nYYxhgTMRYuXLhdVVsH2hdxSaBLly4sWLDA7TCMMSZiiMi6uvZZc5AxxsQwSwLGGBPDLAkYY0wMsyRgjDExzPWOYRFZizPJVyVQoaq57kZkjDGxw/Uk4HWKqm53OwhjjIk14ZIEmtaj3WBPjRl+09rAbavdiccYY8JEOPQJKPAvEVkoItcEKuBdMHuBiCzYtm1bw9+hZgKoa5sxxsSYcKgJDFTVjd5VmT4XkZWq+rV/AVV9Ae9as7m5uTb3dQQpLS1lx44dFBcXU1lZ6XY4xkQ8j8dDs2bNaNmyJUlJSY0+nutJQFU3en8WiMiHwLHA1wd+lYkEpaWlrF+/nszMTLp06UJCQgIi4nZYxkQsVaW8vJyioiLWr19PTk5OoxOBq81BIpImIs18vwNDgaUHflXDVFYdoOIwvgWMb8GeP3dl+oqtBy5rGmzHjh1kZmaSlZVFYmKiJQBjGklESExMJCsri8zMTHbs2NHoY7rdJ9AW+EZEvgXmAR+r6mehfIOZqwrYpoHW3v6PtPIdDHn7SDz/nYE+2i2Ubx/TiouLad68udthGBOVmjdvTnFx45eCdrU5SFV/An7TlO+xbFMRV5U+h+87/trkSw9YXvYUMH3FVvK6t8ETZ99cG6OyspKEhAS3wzAmKiUkJISkn831PoGmdlR2c1ISPewtq/8fa8jbRwKgaW0QG0baKNYEZEzTCNX/Lbebg5pcXvc29OuUQWqip8GvFRtGaoyJclFfE/DECa9dOYCZqwpYurGQHbMyaKm73A7LGGPCQtQnAXASwZCebRnSsy2Vg9cyfVUByzcVcc28M0gqtdkqjDGxK+qbg2ryJYRxQ7qRdNcaGF9I5X1WMzCR7ccff0REuOqqq6ptv+yyyxARfvnll3ofq2PHjhxxxBGhDrGauuJ10xdffIGI8OCDD7odyiEVc0kgEE+coGltau8ItM2Yeho5ciQiwrPPPnvQskOHDkVE+PDDDw9BZE2voqICEeHUU091OxRzEJYEvOS21awft5ku+/5BuSfV2binYP8NZdj9A6aBrr76agBeeumlA5Zbu3YtX3zxBe3bt+ecc84JaQyPPvooK1asoF27diE9bmN17tyZFStWxNy37nBkScBP+4xk4gQSKvfW3mkjhUwD5eXlceSRR7J48WIWLVpUZ7mJEyeiqlxxxRXEx4e2m659+/b06NEj5MdtrISEBHr06BF2ySkWWRLwk+CJo32LFLfDMA1UWaVMX7GVp6avDrvpP3y1gRdffDHg/srKSiZNmlSrfXzjxo088MADnHDCCbRr147ExEQ6dOjAyJEjWblyZb3fv64+AVXlqaeeolevXiQlJdGhQwduuOEGioqKAh5n165dPPLII5xyyil06NCBxMRE2rRpw4gRI5g7d261si+99NL+mwSnT5+OiOx/+L75H6hPYNOmTVx//fV07tyZpKQk2rRpw3nnncfixYtrlX3ppZcQEV5//XWmT5/OoEGDSE9Pp0WLFpxzzjmsWrWq3n+rA1m1ahWjRo0iOzubxMREsrOzufzyy1mzZk2tskVFRTzwwAP07t2bZs2a0axZM4444gguvvjiWucwefJkBg8eTLt27fZ/Dnl5efztb38LSdz1EV5fD8JATstU2OR2FKa+KquUURPnsmTDLkrKKklJ9NCvUwavXTkgLO74vvzyy7n77rt58803efzxx0lNTa22/9NPP2Xjxo2cdtppdO3adf/2GTNm7L/o9u/fn7S0NFavXs0777zDRx99xL///W969+4ddFxjx47l2WefJTs7m2uvvZaEhAQmT57MvHnzKC8vJzk5uVr5pUuXcs899zBo0CDOOeccMjIyWLduHVOnTuWTTz7hk08+2d/+f/TRR3PvvfcyYcIEunbtyujRo/cf5+STTz5gXGvWrGHgwIFs2bKFU089lUsvvZT169fz7rvv8vHHH/Phhx9y5pln1nrd5MmTmTJlCmeddRbXX389S5cuZdq0acyfP5/ly5fTsmXLoP9Wc+bMYejQoezevZvhw4fTo0cPVq5cyWuvvcbUqVOZPn06Rx99NOAk16FDhzJ37lxOOOEErr76ajweD7/88gszZswgLy+P/v37A/Dss8/yhz/8gfbt2zNs2DCysrIoKCjg22+/5ZVXXuG6664LOuaGsCRQQ6eWKZYEDoEHPlrG8k2Bv3U2xM69ZfxYsBvfl/+9ZZXM+elXznzyazJTExt17F7Zzbn/nKMadYzWrVszYsQI3nnnHd555x3GjBlTbb+vhnDNNdWX0jjttNPYunUr6enp1bYvXryYgQMHctddd/HRRx8FFdPXX3/Ns88+S7du3Zg7dy6ZmZkAPPjggwwaNIiCggKaNWtW7TW9e/dm8+bNtGrVqtr2devWMWDAAG6++Wa+//57wEkCffv2ZcKECRx22GGMHz++3rFdc801bNmyhYcffpg77rhj//brrruOvLw8Ro8ezbp162ol0ylTpvD555+Tl5e3f9ttt93GY489xssvv8wf//jHesfgr6qqitGjR1NcXMxbb73FRRddtH/fG2+8wWWXXcbo0aP5/vvvERGWLFnC3LlzOf/883n33XerHauysrJaTev5558nOTmZ7777jqysrGplt28/dEPXrTmohk6ZqYEnnLORQmFpb2klNVt/qtTZHi58F/iaHcSbN2/mk08+oU2bNgwfPrzavrZt29ZKAAD9+/dn0KBBTJ8+Peh5YyZNmgTAvffeuz8BAKSkpPCXv/wl4GsyMjJqJQBwOnjPPfdcli5dyqZNjfv2tHbtWr788ku6du3KLbfcUm3fSSedxIUXXsj27duZPHlyrdeOHDmyWgKA//zd582bF3RM+fn5rF69mpNOOqlaAvC953HHHceyZcuYPXt2tX0pKbWblT0eT7W/Nzh9I4Hm16qZFJqS1QRqyGmVym9Ln+ObC4SOH10CV3wKnU9wO6yo09hv2D7TV2xl3JuLq80NlZro4YHhRzGkZ9uQvEdjDR48mMMPP5xZs2axYsUKevbsCTgX44qKCsaMGRPwQjB16lSef/55Fi5cyK+//kpFRUW1/Tt27KB169YNjsfXST1o0KBa+04++WTi4gJ/N8zPz+epp55izpw5FBQUUFZWVm3/xo0byc7ObnA8Pr728pNPPjlgR/bgwYN56623WLx4MZdeWn0iyNzc3FrlO3XqBMDOnTuDjsn3txo8eHDA/YMHD2bOnDksXryYE044gT59+tCnTx9ee+01fv75Z4YNG8bAgQPJzc2t9RmPHDmSO+64g169enHRRRcxaNAgTjzxxEOaAMBqArV0zHSqmRvL05wNu21UUDjznxtKcBJAv04Z5HUPn5qbfweorzagqkycOBER2d957O/xxx9n+PDhzJkzh0GDBnHzzTdz3333cf/999OnTx/AWbQnGIWFhYBT26gpMTGx1rdVgHfffZe8vDw+/fRTcnNzGTt2LPfeey/3338/J510UqPiqRlX+/btA+73bd+1q/bNnRkZGbW2+RJJY2babGhM8fHxzJgxgxtuuIGff/6Z22+/nRNOOIGsrCxuvPFG9uzZs/+1t99+O5MmTaJjx4488cQTjBgxgjZt2jBkyJADjiYLNasJ1JDT0kkCP+9NYwDAniDWNDaHjP/cUMs3FdEru3lYTgN+xRVXcN999/Hqq6/y0EMPkZ+fz08//cTgwYNr3Z1bXl7OAw88QHZ2NosWLap1sc7Pz29ULC1aOM2dW7duJScnp9q+srIydu7cWeuieu+995KcnMzChQvp3r17tX0bNmxodEz+cW3ZsiXg/s2bN1crdygEE1OrVq148sknefLJJ1m9ejUzZ87k+eef56mnnqKoqGh/cxzAmDFjGDNmDLt27WLWrFl88MEHTJo0idNPP52VK1cGbIILNasJ1JCVnkhKgocf9yQCYkkgAvhPBTKkZ9uwSwDgfOseNmzY/jZtX42gZocwOBfn4uJiBg4cWCsBFBUVBRwq2RC+kSxfffVVrX1ff/01VVVVtbavWbOG3r1710oAlZWVzJo1q1Z5X5NSQ76F+0bN5OfnB3zdjBkzqsV/KPhimjlzZsD9B4upW7duXH311Xz11VekpKQE7M8Apybzu9/9jokTJzJq1Ci2b9/ON9980/gTqAdLAjWICB0zU1i/swxSW1kSMCHja/Z5/PHH+fDDD8nKyuL3v/99rXLt27cnKSmJ+fPnV2s+KCsrY9y4cY1q4wanVgIwYcKEak0rJSUl/OlPfwr4ms6dO7Nq1apq34hVlfvuuy/gWPy4uDgyMzNZv359vePq0qULp5xyCmvWrOHpp5+utm/WrFm8/fbbtGrVqlYnelM6+eSTOeKII5g5c2atC/hbb73F7Nmz6dmzJ8cffzwAP/30E2vXrq11nJ07d1JeXl5tVNOMGTNQrT6qQVUpKHCaoGuOgGoq1hwUQE7LVNbv2Atpra1PwITM0KFD6dKly/7RKmPHjiUxsfYwVo/Hw7hx43jsscfo06cPw4YNo7S0lC+//JLCwkIGDRoU8Ft8fZ188slcf/31PPfccxx11FGcf/75xMfHM3nyZFq3bk2bNrX7U26++WbGjh1Lv379OO+884iPjyc/P58ffviBs88+m2nTptV6zZAhQ3jvvfcYPnw4/fv3Jz4+nry8PAYOHFhnbM8//zwDBw7k5ptv5tNPP+WYY47Zf59AfHw8L7/8MmlpaUGfe0PFxcXxyiuvMHToUM477zxGjBhB9+7dWblyJVOmTKF58+a8+uqr+xd4WbRoERdeeCHHHnssPXv2pH379hQUFDBlyhQqKiqqDXs955xzyMzM5LjjjqNLly5UVlaSn5/PggULOPbYYznllFMOzUmqakQ9jjnmGG1q909Zqkfd95lWvXy26ktDm/z9otXy5cvdDiHsPPjggwoooCtXrqyzXHl5uT7yyCPao0cPTU5O1nbt2umoUaN0/fr1OnLkSAV0w4YN+8uvXr1aAb3yyiurHSdQWVXVyspKfeKJJ7RHjx6amJio2dnZOnbsWC0sLNQOHTro4YcfXiumiRMnat++fTUlJUVbtWqlv//973Xp0qV69913K6D5+fnVym/evFkvvvhibd26tcbFxSmgEyZMOGC8qqobNmzQa6+9Vjt16qQJCQn732v+/Pm1yr744osK6GuvvRbwbwjokCFD6vw7+/v888+rxehv+fLleumll2q7du00Pj5e27Vrp5dddpn+8MMP1cqtX79e77zzTj3++OO1bdu2mpiYqB07dtSzzjpLP/vss2pl//rXv+rw4cO1a9eumpKSopmZmdq/f3995JFHtLi4uF4x1/f/GLBA67imimr43GJfH7m5ubpgwYImfY+J3/zMhGnLWdXvXZIKvoUbGtcGG6v8h0MaY0Kvvv/HRGShqtYeR4v1CQTUKdO50aPIkwl7bNEZY0z0siQQQCfvMNFftTmUFkH5PpcjMsaYpmFJIIDsDKcmkL/Z6eyptM5hY0yUsiRQQ2WVcv3rCwGYs9X589z/jxlhNT2xMcaEiiWBGmauKmDJBmfs9K/eieS2b93IzFVWGzDGRB9LAjUs21REiXcysu04SaBZ5c6QTHtsjDHhxpJADUdlNycl0QPAdm0OQHtPMb2ym7sZljHGNAlLAjX4z0q5jyR2azI9mpWG1ayUxhgTKpYEavDNSvn0Jf35TccW7KA5p3aWsJyUzBhjGsvmDgrANytlRmoi2ya2IKlgI+GxPIkxxoSW1QQO4OicDEoSMindtdXtUIwxpkmERRIQEY+ILBaR2lMRukhEaJ7VgZTyHfz54+VMX7HV7hcwxkSVsEgCwI3ACreDqKmySllVnERLipiYv4Zxby5m1MS5lgiMMVHD9SQgIh2B3wEvuR1LTTNXFbBqdwoeUTLYzd6ySpZs2GU3jpmIsnv3bkSEs88+u8ne45lnnkFEeO+995rsPUzTcD0JAE8AtwO117TzEpFrRGSBiCzYtu3QrfS1bFMRWyqaAZAlzoLTJWWVduOYqRcRadDj5ZdfdjtkE4NcHR0kImcDBaq6UETy6iqnqi8AL4CznsAhCo+jspuzID4TgFZSBAopiR67cczUy/33319r2xNPPEFhYSE33nhjrcXc+/Xr1yRxpKWlsWLFCtLT05vk+CayuT1E9ERgmIicBSQDzUXkdVW9zOW4AOfGsU/bdYQCaE0hqYke+nXKsBvHTL2MHz++1raXX36ZwsJCbrrpJrp06XJI4hARevTocUjey0QeV5uDVPUuVe2oql2Ai4EvwyUBgHO/wP+MHgJAKynk4XP78NqVA+zGMdOkcnNzSU9Pp6SkhHvuuYcjjjiCxMRExo4dC8Cvv/7Kww8/zKBBg8jOziYxMZG2bdty3nnnsXDhwlrHq6tP4NZbb0VEWLBgAW+88QbHHHMMKSkpZGVlMWrUqP0LnjfW7NmzGT58OFlZWSQlJXHYYYdx0003Eahpd9OmTdx4440ceeSRpKamkpmZSc+ePbnyyivZsGHD/nJVVVW8+OKLDBgwgKysLFJSUsjJyeGss86qtSC8OTC3awJhz5OaSZXEkyWF5HZpaQkgHD3aDfbUuGCltYHbVrsTTwhUVVVx9tlns2rVKk4//XRatWpF586dAVi8eDH3338/eXl5DB8+nBYtWvDzzz8zdepUpk2bxueff87JJ59c7/d65JFHmDZtGsOHD+eUU05h1qxZvP766yxdupQFCxbg8XiCPo933nmHkSNH4vF4uOCCC+jYsSNz5szhySefZMqUKcyaNYvs7GwAioqKGDBgAJs2bWLo0KGMGDGC8vJy1q1bx3vvvceoUaPo1KkTADfddBNPP/003bp145JLLiE9PZ1NmzYxd+5cJk+ezIgRI4KOOdaETRJQ1ZnATJfDqC0ujrKkTFqVF7HXO7uoCYFP74Qt34fmWDUTgG/bpN817rjt+sCZDzfuGEEqKSmhuLiYpUuX1uo7OProo9myZQuZmZnVtq9Zs4YBAwZwyy23MH/+/Hq/1/Tp01myZAlHHnkkAKrKiBEjmDp1Kv/85z8566yzgjqHHTt2cNVVVyEifPPNN+Tm/meJ23vvvZcHH3yQsWPH8sEHHwDw8ccf88svv3DPPfcwYcKEasfat28fFRUVwH9qAYcffjjff/89SUlJ1cpu325LwjZEOIwOCntlyVlkSeH+KaaNORQeeuihWgkAoGXLlrUSAMDhhx/OsGHDWLBgATt27Kj3+9x22237EwA4fQhXXXUVAPPmzQsicse7775LcXExY8aMqZYAAO6++27atWvHlClTal20U1JSah0rOTm5Wse2iJCYmBiwlpKVlRV0zLEobGoCYevRbjTfU8CpHuClHGdbhDc1hIVQfsMe3yLw9is+Dt17uODYY4+tc9+MGTN4+umnmTdvHgUFBZSXl1fbv3HjRlq2bFmv96l5gQb2N7vs3LmzARFXt2jRIgAGDx5ca19ycjInnHACH3zwAd9++y1DhgzhtNNOo3Xr1tx77738+9//5swzz+TEE0+kb9++xMX95/tqXFwcF198MZMmTaJ3795ccMEFnHTSSRx//PE0a9Ys6HhjlSWBg6mrqcGYJpSamlrnBe31119n9OjRpKenc9ppp9G1a1fS0tIQEf71r38xe/ZsSktL6/1egWob8fHOpaGyMvjab2Ghc29N+/btA+73bd+1y1nJLysri7lz5zJ+/HimTZvGxx87Sbxt27bccMMN3HHHHfu/+T///PP06NGDV155hQcffBCAhIQEhg0bxuOPP76//8QcnCUBE/nS2gTuGI5gInUPQLjnnnto1qwZixcv5rDDDqu2b/Xq1cyePbupw6uXFi2cGtqWLVsC7t+8eXO1cgBdu3bllVdeoaqqiqVLlzJ9+nSeeeYZ7r77bjweD3fccQfgXPBvv/12br/9drZs2UJ+fj6vv/4677//PitXruTbb79tVId2LLE+ARP5blsN4wurP6K0ua6iooJ169bRr1+/WgmgvLw8bBIAQP/+/QGYOXNmrX2lpaXMnj0bEQl4k1xcXBx9+/bl5ptvZto0Z17JuoZ+tmvXjgsuuIApU6Zw7LHHsmzZMn788cfQnUiUsyRgTASJj4+nQ4cOLFu2rFqHalVVFXfddRc///yzi9FVd+GFF5Kens6kSZP49ttvq+176KGH2Lx58/77BwC+++67gCN7tm51pnJPTU0FnPseAnVYl5aW7m+CCtS5bAKz5qCDicKmBhPZbr75Zm699Vb69u3LueeeS1xcHF999RVr167lzDPP5NNPP3U7RMAZxfTCCy8watQojj/+eC644AI6dOjAnDlzmDFjBjk5OTzzzDP7y0+dOpX//u//5sQTT6Rbt25kZWWxbt06pkyZgsfj4dZbbwWcPoQBAwbQo0cP+vfvT05ODnv37uWzzz5j9erVXHrppeTk5Lh12hHHksDB3LaaqkWvETd1LH/PncJ/nZ3ndkQmxv3xj38kPT2dZ555hr///e+kpaWRl5fHO++8w4svvhg2SQDgkksuIScnh4cffphp06ZRXFxMdnY248aN45577qFNm/98oRo2bBjbtm0jPz+fDz74gN27d9O+fXvOOeccbrnllv2jmFq1asVf/vIXZsyYQX5+Ptu2baN58+Z069aNO+64g8svv9yt041IohpZc+Pn5ubqggULDu2bLvsQ3h3Di73f4Orzm2463mizYsUKevbs6XYYxkSt+v4fE5GFqlp7LDDWJ1A/ic5NKlWlu4444aoAABkGSURBVF0OxBhjQsuSQH0kpgGgpXtdDsQYY0LLkkB9eJMA5VYTMMZEF0sC9eFtDpKyPS4HYowxoWVJoD68NQEptyRgjIkulgTqw5sEPBXWJ2CMiS6WBOojwblT0ZJAw0XaEGRjIkWo/m9ZEqiPOA9lkkxCpSWBhvB4PLWmODbGhEZ5eXlIJsmzJFBPZZ4USwIN1KxZM4qKitwOw5ioVFRUFJL1EywJ1FO5J5WkqhK3w4goLVu2ZOfOnWzfvp2ysjJrGjKmkVSVsrIytm/fzs6dO+u9cNCB2NxB9VTpSSFZ91FZpbbYfD0lJSWRk5PDjh07WLt2baMWKDHGODweD82aNSMnJ6fW+srBsCRQT5XxqaSyj5LyStKT7M9WX0lJSbRv377O1aWMMe6y5qB6qkxII032sbeswu1QjDEmZCwJ1JMmpJFCKSVl1qRhjIkelgTqKzGNNPax15KAMSaKWBKor8Q0UqXUkoAxJqpYEqinuKR00thnzUHGmKhiSaCe4pLTSZEy9paWuh2KMcaEjCWBevIkO9NJl5fYmgLGmOhhSaCe4pOd27PLS4pdjsQYY0LHkkA9Jab4koDVBIwx0cOSQD0lpDpJoGqf1QSMMdHD1SQgIskiMk9EvhWRZSLygJvxHEiCt0+gstRqAsaY6OH2JDilwGBV3S0iCcA3IvKpqs5xOa7avOsMqyUBY0wUcTUJqDO3sO+qmuB9hOd8w94lJrHF5o0xUcT1PgER8YjIEqAA+FxV5wYoc42ILBCRBdu2bTv0QcJ/kkC5LSxjjIkericBVa1U1X5AR+BYEekdoMwLqpqrqrmtW7c+9EHC/uYgsZqAMSaKhDQJiEimiKQF81pV3QXMAM4IZUwh460JeCosCRhjokeDk4CIDBGRR0Qk029bGxH5CtgO7BCR/63nsVqLSIb39xTgNGBlQ2M6JDyJVODBU2HNQcaY6BFMTWAccK6q7vTb9hhwErAG+BW4UUQurMex2gMzROQ7YD5On8C0IGJqeiKUxqUQb0nAGBNFghkd9BvgK98T7zf483Eu4KeLSDPge+A64J0DHUhVvwP6BxGDK8riUkiotCRgjIkewdQE2gCb/J4PAJKBlwFUtRiYBnRvbHDhptyTSkJVidthGGNMyASTBEqBFL/nJ+GM7f/ab1sR0LIRcYWlCk8qSZYEjDFRJJgk8DMw2O/5ecBqVd3ot60TTidxVKmITyVZS3DucTPGmMgXTBJ4BegjInNFJB/oA/yjRpm+wKrGBhduquJTSGUfpRVVbodijDEhEUwSeA54C8gFTsRp//8f307vzV59gJkhiC+saEIaqdg6w8aY6NHg0UGqWg5cKiLXOU+15tzKW3BG/KxtfHjhRRPTSJN97C2roGVaotvhGGNMowU9gZyqFtWxfTtR2B8AQGIaqexjq9UEjDFRIpg7hjNFpJeIJNXYfoWITBGRf4jIsaELMXxIUjqplFJSVuF2KMYYExLB1AT+AlyGc78AACIyDngCEO+mESKSq6rLGx9i+IhLSideqijZVwJkHrS8McaEu2A6hk8Epquq/4D5W4GNwMmAb7qIPzYytrDj8a4uVr43YEuYMcZEnGBqAh2A6b4nItIL576AO1T1G++2C3ASQlSJT3bWGS7ba+sMG2OiQzA1gRRgn9/zE3HuGP7Cb9sanGQRVXxJoLzEkoAxJjoEkwQ2Aj38np+OM03Et37bMoGom18hIdVJArbYvDEmWgTTHDQDuFxExuLUCIYB76uq/220hwMbQhBfWEnyJYF9lgSMMdEhmJrAQziLwz8JvICTCMb7dopIc2Ag8O8QxBdWElOcJFBlNQFjTJQI5o7hn0XkKJw1BACmqup6vyJHAM9Tez6hiBeX5IwOwpKAMSZKBHXHsKpuAZ6pY98iYFFjggpb3nWGscXmjTFRIuhpIwBEJAGnkzgDKARWeOcWik7eJCDllgSMMdEhmD4BRKS5iPwN2AUswZkxdDGwS0T+5ls8PuokpAIQZ0nAGBMlGlwT8Hb8zgKOAoqBfGAzzqLx/YBrgIEickJdk8xFrDgP+0giriLqRr8aY2JUMDWBu3ASwHNAZ1XNU9VLVDUP6Az8FejlLRd1SuNSiK+wmoAxJjoEkwTOBeao6h9UdZf/DlUtVNVxwGycZSejTmlcCvGVVhMwxkSHYJJAZw6+athXOPMJRZ2yuBQSq/a6HYYxxoREMElgD37TSNehNRB1V8rKKmUvyXjK9zJ9xVYqq2zBeWNMZAsmCcwHLhCRboF2isjhONNJz29MYOGmskoZNXEuW/fFk6QljHtzMaMmzrVEYIyJaMEkgUeBdGC+iEwQkcEi0lNEThGRB3Au/unAY6EM1G0zVxWwZMMudmvS/sXml2zYxcxVBW6HZowxQWtwElDV6cD/A5KBPwGfA0txppK+F0gDxqrqF3UeJAIt21RESVkle0kmzTuTdklZJcs3RdcoWGNMbAl22ojnReRTYBTQH2iBc8fwYuB1VV0XuhDDw1HZzZmXdD2tpRCAtcmXAlA6PwuGrHEzNGOMCVrQ00Z4J437c6B9IpIMJEbTzWJ53dvg8SYAf0n7trsQjTHGhEZQ00bUw3PAjiY6tis8ceJ2CMYYE3JNlQQA7KppjDFhrimTwEGJSCcRmSEiy0VkmYjc6GY8xhgTa1xNAkAFcIuq9gKOA/4gIr1cjqluaQHukQu0zRhjIoSrSUBVN3sXoUFVi4EVQAc3Yzqg21az+ZqlACzqdSeML4TbVrsclDHGBM/tmsB+ItIFZ7jp3AD7rhGRBSKyYNu2bYc6tGpSM9pQrh48e+0mMWNM5AuLJCAi6cD7wE2BhpWq6guqmququa1btz70AfpJS0pgGy1IsCRgjIkC9bpPQEQqmyoA7xKV7wNvqOoHTfU+oRLviWM7maTvc7dGYowxoVDfmoAE8Tj4QUUEmIizNvH/NihyF+2Ma0lKmd0kZoyJfPVKAqoaF8TDU49Dn4gz9cRgEVnifZzVqDM6BAo9LWlWbknAGBP5gp42IhRU9Rsi8KayooRWpJcUQkUZxCe6HY4xxgQtLDqGI83exCznlz3WOWyMiWyWBIKwL8k7Qql4q7uBGGNMI1kSCEJpijcJ7N7ibiDGGNNIlgSCUJnW1vml2JKAMSayWRIIgqa1pkoFdltzkDEmslkSCEJqUjK/0pyqIqsJGGMimyWBIKQnx1OgGVQWbXY7FGOMaRRLAkFIT/JQoBmo9QkYYyKcJYEgpCXFU6CZxO2xPgFjTGSzJBCE9KR4CsjAs3c7VDXZ3HrGGNPkLAkEIT3J6RMQrYS9v7odjjHGBM2SQBB8HcOA3StgjIlolgSCkJYYzzZfErB7BYwxEcySQBCcPoFM54nVBIwxEcySQBDSkuLZpi2cJzZ/kDEmglkSCEJifBwan0yJp7nNJGqMiWiWBIKUnhRPUUJLqwkYYyKaJYEgpSfFUxjXymoCxpiI5urykpFscskYWuou2AuM9/YPpLWB21a7GpcxxjSE1QSC1FJ31d5oy00aYyKMJQFjjIlhlgSMMSaGWRIwxpgYZkkgSLvjW9bemNbm0AdijDGNYEkgSC8O+Cdd9v0D7X0+NO8I4wttZJAxJuJYEghSepIzura0dR8o+gV2b3M5ImOMaThLAkFKT3aSwN5WfZwNm5e4GI0xxgTHkkCQ0rw1gZ0ZvZwNmywJGGMijyWBIKUneQAo1hRodYTVBIwxEcmSQJDSkxIA2FNaAe37WU3AGBORLAkEKc1bE9hdWgHZ/axz2BgTkVxNAiLydxEpEJGlbsYRDN/ooN37KiC7v7PRmoSMMRHG7ZrAy8AZLscQFF8S2FNWAe36OhutScgYE2FcTQKq+jWww80YguUbHVS8rwKSmzudw5sWuxyVMcY0TESsJyAi1wDXAOTk5LgcjSMpPo74OHE6hh/t5kwj/euPtraAMSaiuN0cVC+q+oKq5qpqbuvWrd0OBwARIT053kkCgdYRsLUFjDERICKSQLhKS4ynuLTC7TCMMSZolgQaIT3JWxMwxpgI5fYQ0TeB2UB3EflFRK50M56GcpqDKt0OwxhjguZqx7CqXuLm+zdWWlI8hSXlTidwzT4AW1vAGBMBImJ0ULhKT/KwaVdJ9VFAr58H21bBjd+5F5gxxtST9Qk0QsA+gb4XQ+EGWDfLnaCMMaYBrCYQpMoqZceeMn7dXcb0FVvJ694GT5zAP+9yCrxy9n8K2z0DxpgwZTWBIFRWKaMmzuWrH7ZRVlnFuDcXM2riXCqrFPYEmETO7hkwxoQpSwJBmLmqgCUbdlFeqQDsLatkyYZdzFxlF3tjTGSxJBCEZZuKKCmrPjS0pKyS5ZuKXIrIGGOCY0kgCEdlNycl0VNtW0qih17ZzV2KyBhjgmNJIAh53dvQr1MGqd5E4IkT+nXKIK97m8D3B6RkHuIIjTGmfkRV3Y6hQXJzc3XBggVuh0FllTJzVQEPf7qSXXvLmfOnIc7oIH+lxfBQDlBVfbuNFjLGHEIislBVcwPts5pAkDxxwpCebTn/mI5s213Krr1ltQslNaNWAgAbLWSMCRuWBBqpf47T1LNkwy6XIzHGmIazJNBIfTq0wBMnlgSMMRHJ7hhupJRED93bNmt4ErAVyIwxYcBqAiHQLyeDJRt2UVUVoJP9YLOJWv+AMcZFVhMIgf6dMvjH3PX8tH03R7RpVn2n/7d837f/mqxWYIxxidUEQqB/TgYAi9c3sl/AagXGmEPMagIh0LllGikJcbw2Zx0t0xL/M6NoMKxWYIw5hKwm0EiVVcrlk+ZRWlHFd78UVp9RtKaGrDZmtQJjzCFgNYFG8s0o6rvm+88oOqRn2+qF69M/4M9qBcaYJmY1gUYKekbRhtYKxrdwHo92CyJKY4wJzGoCjeSbUXSvXyJITog7+IyiDa0V+PgSAlgNwRjTaFYTaCT/GUV9XcFxccL3GwuZvmJr4L6BmhpSK/BnNQRjTCPZLKIh4JtRdOnGQl6fu55txaUIzt3E/Tpl8NqVA+o/WqghtYK6WA3BGOPnQLOIWnNQCPhmFAXYU1oBgHKQTuK6pLVp/Mgg/yajmse25GCM8WNJIIQCdRLvLavko283sWxTEUdlNz/4PQT+F+lHu4V2qKglB2NMDZYEQihQJzHAx99tpqJKSU6Io3OrNM7o3Y4+HVq4mxD81ZUcDsQShzFRwfoEQqiyShk1cS5LNuyipKySBE8cZZW1F5URaHhC8NeUCaGpWNIwxjUH6hOwJBBivk7i5ZuKWLNtN1OWbOJAf+GaCeGo9s1BYMXm4vo1H0ViQmgqlmiMCciSgEumr9jKuDcX12oeOhDf9V617uTQs12zgL9fO/8MkvZtb6KzMfXiS0SBkrMlKeMSSwIu8W8eakgiCMSXHKo08O8HShrXzjuDpFJLDiaG+e7FidHEHNZJQETOAJ4EPMBLqvrwgcpHUhKA6vcQfLZ0C+t27G10QqgPEaep6WBJI99zLVkUNnk8xpgQamDyCtskICIe4AfgNOAXYD5wiaour+s1kZYE/LmVEEJpftL1tBZLGsa4bnz9/x+G881ixwI/qupPACLyFjAcqDMJRDLfTWVDerZl7OBuAROC/7f2cPTb0ucaVN6ShjHhze0k0AHY4Pf8F2CAS7EcUoESwvJNRfTwdvQu31RUZ3Ko6/dw1NCkEQxLNMYEz+0kUC8icg1wDUBOTo7L0YSef0LwOa1Xu4DJYeXm4oC/NzRp+PoEEuPjKK/UeicaN34/WKwDyp7b/3tdDkWyDJSMtqlzE54lKROu3O4TOB4Yr6qne5/fBaCqD9X1mkjuE2hq/vcoHCxprNxcTK/s5pzUrTX5q7fV+zVu/V6fWP0TYUlZ5f7RUmf2bk+v9sHXsGIpobr9e6jji9bErGltkCjpGI7H6RgeAmzE6Ri+VFWX1fUaSwLmQPwTYa86brZraLKMxYRq8YVnrHX9mz6YsE0CACJyFvAEzhDRv6vqnw9U3pKAMcY0TDiPDkJVPwE+cTsOY4yJRbaymDHGxDBLAsYYE8MsCRhjTAyzJGCMMTHM9dFBDSUi24B1Qb48C4i16TRj8ZwhNs87Fs8ZYvO8G3rOnVW1daAdEZcEGkNEFtQ1TCpaxeI5Q2yedyyeM8TmeYfynK05yBhjYpglAWOMiWGxlgRecDsAF8TiOUNsnncsnjPE5nmH7Jxjqk/AGGNMdbFWEzDGGOPHkoAxxsSwmEgCInKGiKwSkR9F5E6342kqItJJRGaIyHIRWSYiN3q3txSRz0VktfdnptuxhpqIeERksYhM8z7vKiJzvZ/52yKS6HaMoSYiGSLynoisFJEVInJ8tH/WInKz99/2UhF5U0SSo/GzFpG/i0iBiCz12xbwsxXHU97z/05Ejm7Ie0V9EvAuZv9X4EygF3CJiPRyN6omUwHcoqq9gOOAP3jP9U5guqp2A6Z7n0ebG4EVfs//B/g/VT0C2Alc6UpUTetJ4DNV7QH8Buf8o/azFpEOwA1Arqr2xpl+/mKi87N+GTijxra6PtszgW7exzVAg9Z0jfokgN9i9qpaBvgWs486qrpZVRd5fy/GuSh0wDnfV7zFXgFGuBNh0xCRjsDvgJe8zwUYDLznLRKN59wCOBmYCKCqZaq6iyj/rHGmv0/xLkiVCmwmCj9rVf0a2FFjc12f7XDgVXXMATJEpH193ysWkkCgxew7uBTLISMiXYD+wFygrapu9u7aArSt42WR6gngdqDK+7wVsEtVK7zPo/Ez7wpsAyZ5m8FeEpE0ovizVtWNwGPAepyLfyGwkOj/rH3q+mwbdY2LhSQQc0QkHXgfuElVi/z3qTMmOGrGBYvI2UCBqi50O5ZDLB44GnhOVfsDe6jR9BOFn3UmzrferkA2kEbtJpOYEMrPNhaSwEagk9/zjt5tUUlEEnASwBuq+oF381Zf9dD7s8Ct+JrAicAwEVmL09Q3GKetPMPbZADR+Zn/AvyiqnO9z9/DSQrR/FmfCvysqttUtRz4AOfzj/bP2qeuz7ZR17hYSALzgW7eEQSJOB1JU12OqUl428InAitU9X/9dk0FLvf+fjkw5VDH1lRU9S5V7aiqXXA+2y9VdSQwAzjfWyyqzhlAVbcAG0Sku3fTEGA5UfxZ4zQDHSciqd5/675zjurP2k9dn+1UYLR3lNBxQKFfs9HBqWrUP4CzgB+ANcDdbsfThOc5EKeK+B2wxPs4C6eNfDqwGvgCaOl2rE10/nnANO/vhwHzgB+Bd4Ekt+NrgvPtByzwft6Tgcxo/6yBB4CVwFLgNSApGj9r4E2cfo9ynFrflXV9toDgjIBcA3yPM3qq3u9l00YYY0wMi4XmIGOMMXWwJGCMMTHMkoAxxsQwSwLGGBPDLAkYY0wMsyRgTBgSkfEioiKS53YsJrpZEjBRyXsBPdgjz+04jXFb/MGLGBPRHjjAvrWHKghjwpUlARPVVHW82zEYE86sOcgYqrfBi8jl3umZS7yrO/1dRNrV8bpuIvKqiGwUkTIR2eR93q2O8h4RuU5EZolIofc9fvROBV3Xa84XkXkisldEdojIW94FVoxpNKsJGFPdzcBQ4G3gM5z5mK4A8kRkgKpu8xUUkd/izOHSDGcSr+VAD+AyYLiInKqq8/3KJwLTgNNw5n//B1AEdAF+D3yDMy+Mv/8HDPMe/ytgAHAR8BsR6aeqpaE8eRN7LAmYqCYi4+vYtU9VHw6w/UxggKou9jvG/wE3AQ/jXbrQO4vlq0Bz4DJVfcOv/EU401q/JiK9VNW32M14nATwEXCB/wVcRJK8x6rpDOC3qvq9X9l/AJfgzK3/Tp0nb0w92ARyJiqJyMH+YReqaoZf+fHA/cDfVbXaGrXepRzX4cxYmaGqpSJyIs4399mqekKA98/HqUUMUtWvvWtd/wokAkeo6qaDxO+L58+qek+NfacAXwKPq+qtBzlPYw7I+gRMVFNVqeORUcdLvgpwjEKcabmTgZ7ezUd7f35Zx3F82/t7f/YAWgDfHSwB1LAgwDbfUoKZDTiOMQFZEjCmuq11bN/i/dmixs+6Fu/wbc+o8bOhq17tCrDNt56up4HHMqYWSwLGVFfXwuy+0UGFNX4GHDUEtK9Rzncxt1E9JqxYEjCmukE1N3j7BPoB+4AV3s2+juO8Oo5zivfnIu/PlTiJoK+IZIckUmNCwJKAMdWNEpH+NbaNx2n+edNvRM8sYBUwUETO9y/sfX4SzpKm3wCoaiXwLJAC/M07Gsj/NYki0jrE52LMQdkQURPVDjBEFGCyqi6pse1TYJaIvIPTrj/Q+1gL3OkrpKoqIpcDnwNvi8gUnG/73YERQDEw2m94KDhTWAwAzgF+EJFp3nKdcO5NuA14OagTNSZIlgRMtLv/APvW4oz68fd/wIc49wVcBOzGuTD/SVUL/Auq6lzvDWP3AKfiXNy34ywSPkFVV9UoXyYiZwDXAaOBy3EWCd/kfc9vGn56xjSO3SdgDNXG5Z+iqjPdjcaYQ8f6BIwxJoZZEjDGmBhmScAYY2KY9QkYY0wMs5qAMcbEMEsCxhgTwywJGGNMDLMkYIwxMcySgDHGxLD/D0wFaC/oyWHkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot training & validation loss values\n",
    "#plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_key_hat_loss'],marker='o',markersize=5)\n",
    "plt.plot(history.history['key_hat_loss'],marker='s',markersize=5)\n",
    "\n",
    "plt.title('Model loss',fontsize=20)\n",
    "plt.ylabel('Loss',fontsize=20)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.grid()\n",
    "\n",
    "plt.legend(['Validation loss','Train loss'],fontsize=20)#Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEkCAYAAADeqh2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeXxTVfr48c/THcq+74uKIDKoyAAqQlFREBUVdFDUcUdG1GFGf+Muit8vfl1GRx0VFUXFUXBDQBQdEAVGVlFBkAGRHWRvi3RNnt8fNylpmrRJmzQkfd6vV19p7j2597lJe5+cc+49R1QVY4wxpjxJsQ7AGGPM0c+ShTHGmApZsjDGGFMhSxbGGGMqZMnCGGNMhSxZGGOMqZAlC5NQRCRLRFRExlVxO9d6tnNtZCIzJr5ZsjBV4jmhqoi4ReTYcsp96VP22moM0RgTAZYsTCQUAwLcEGiliHQCsjzljDFxyJKFiYRfgeXAdSKSEmD9jZ7HmdUXkjEmkixZmEh5BWgBXOC7UERSgWuB/wBrgr1YRDqJyJsisl1ECkVkh+d5pyDlm4vIJBH5VUTyROQ7EfljeQGKSCMRmSAiaz2vyRaRuSJybrgHG2DbrUTkQRFZJCK7fI7hXyLStZzX9RKRqZ7jLhCRnSLyuYhcXpmyFfXZiMgmEdnkt6ykf0ZEBonIfM97oz5lLhaRKSLyXxH5zfOzQkRuF5GA5xERqS0ifxOR5SKSKyKHPO/9syLS3FPmHc+++wfZxjDP+ueDvYemegT6FmhMZbwD/B2nFjHdZ/lFQDPgb8BxgV4oIr8H/g3UBWbgJJUuwFXAUBE5R1WX+ZRvgpN8jgEWen5aAi8BnwfZR3tgPtABWAB8BmTiJLfPRGSUqr4S/mGX6AfcDXwJfAAcAjoBw4GLROQMVf3eL6abgBcBl+e41+O8Vz2BPwHTKlO2CoYDg4BPcd7L9j7rHgPcwBJgO1AfOAv4B/B74Gq/Y2uI816cBKwDXgMKgWOB64APcWqkLwIjgJuBrwLENMrz+FJVD85Ukaraj/1U+gdQYJvn91dx+iXa+Kz/DMgGagOPespf67NegLWe5SP9tv0Hz/KfgCSf5S97lj/tV74nUORZN85v3Xyck90Iv+UNgO+APKC5z/Jr/WOt4H1oBtQNsPwknMTxqd/yrp5Y9wMnBnhdm0qWzQp0/D7rNwGb/JZ5j9UNDAryumMDLEsC3vC8trffun95lr/o+9l51tUB6vs8Xw3kA439yh3jiWlRrP/O7UetGcpE1CtAMnA9lHybHwi8raqHg7zmdJxaxDeq+rbvClWdilNr6Az09WwzFRgJ5ALj/MovB0ptw/Oak4D+wAeq+q7faw4CDwEZwLDQD7U0Vd2tqrkBln8PzAMGeGL3Go1Tsx+vqj8GeN22Spatio9V9bNAK1T15wDL3Dg1C4DzvMtFpBlOot8J3Okp5/u6Q6qa7bPoRSAdJ2n5ugnny8TE8A7DRIM1Q5mIUdUlIrIKuF5EHsVpkkrCSSLB9PA8zguyfh5OojgF+BonsdQGFvidcLzmA/59F6d5HusHactv6nk8oZw4KyQiQ4BbcGo4TSj7/9UE5wQK0Mfz+GkImw6nbFUsDbZCRBoDdwHn43zjz/Qr0trn99/jfO5fq+pvIez3TZxmrpuBpzz78/Z1HSAyTWymiixZmEh7BXgWGIzTNr1CVVeWU76+53FnkPXe5Q38yv8apPyuAMsaex4Hen6CqVPOunKJyB3AMzgnty+ALcBhnKaYi3Gao9J9XuI9nu0hbD6cslUR6L1DRBoAy4COOAnlTZwmsWJPbHdQ+WNDVXNFZApwi4gMUNUvcfq6WgDPqGp+JY7FRJglCxNpbwH/h9Mh2Rp4pILy3tpBiyDrW/qV8z42D1I+0Ha8r7lDVZ+tIJ6weS4XHodzsu2hqjv91p8W4GUHPY+tcfpkyhNOWW+TT7D/7QY+2/MXbCa0G3ESxcOqOs53hefY7vAr7xtvqF7EqZWNwukY93ZsvxzGNkwUWZ+FiShPH8D7QBvgN5yrpMrjrXVkBVk/wPP4refxJ5xv7CeLSP0A5QNtZ7Hn8cwKYqmsJjgn4f8ESBR1ONLUFiimwSFsP5yyBzyPbf1XiMhxHKmZhcN7FdsHAdYFuuR1KU7S6ici/s1VAanqD8Ai4BIR6Q2cg9OMtbYS8ZoosGRhouF+4BLgvECdvn4W4Vxa2VdEhvuu8Dw/E/gvTkc3qlqE04ldF78ObhHpidP5XYqn43sBcKmIXB8oCBH5nadjtjJ24ySwUz3JwbvNVJwO4CYBXvMiTjPOA4HuwxCRNpUs+xOQg3PJcTOfMrVwmgcrY5PnMctvv6cA9/gXVtU9wLs4tcIn/e/DEJE6QRL9i0AaTlIS7HLZo4o1Q5mIU9UtOG32oZRVz810XwBTReRjnBNeZ5y2/lzgGr8rau4Fzgb+7EkQ3vss/gDMxmnv9nclTmf5JBG5Hed+gYM4NaDuQDecjvDd4R2tc1WQiDyLc5/FKs8xpOHUihrhNKsM8HvNGhH5E84JcaXnNetx+ld+j3PCH1CJskUi8g/gAU/Zj3D+zwcCOzw/4XoTp3P7GREZ4Nl3J5x7VD7Eed/9jcF5T28BskRkDs59Fh1xrpy6COdiBF/vAU/jNF/t9WzbHC1ife2u/cT3Dz73WYRQtsx9Fj7rOuP0d+zEuadgJzAF6BxkWy1wbvTag3OPxHc4V89kEeQ+A5zayL3ACpx7H/KAX4BPcK7EyfQpe22wWIPEkwL8BeeGwjyc/ou3cG5sm+zZVocArzsN55v0bpyT6Q6ce1OGV7Yszrfyu4GfPeW2AI/jXEW2ieD3WQQ9Vpx7PWZ49v2b5z28EecmRwUmB3hNJnAf8ANOzSvX8/48AzQLsp+nPdt7ItZ/2/ZT+kc8H5AxxsSciMzHuRu+s6quj3E4xof1WRhjjgoi0gunw3yOJYqjj/VZGGNiSkRG4/RTXIdzFdVDsY3IBGLNUMaYmPKMgtsG2IjT1/Sv2EZkArFkYYwxpkIJ2QzVpEkT7dChQ6zDMMaYuLJixYq9qto00LqETBYdOnRg+fLlsQ7DGGPiiohsDrbOroYyxhhTIUsWxhhjKmTJwhhjTIUsWRhjjKlQTJOFiLwmIrtFZHWQ9SIiz4rIBhH5QUQCDfVsjDEmymJ9NdRk4HmcUS0DGYwzumUnoDfOEMa9qyUyY6LM5Vbmr9vNjztyOLFVPbI6NyM5SWId1lHN9z07oUVdEFi7Mzfo+xdK+fI+h2Drgm23Kr+Hsv0TW9XjzE5NWbB+T8jvQaTENFmo6tci0qGcIkOBN9W5c3CxiDQQkZbqN8GMiU/hnizD/ceP5D9xsH/Qyv7+444c5qzexeb9h8krdJGRmkT7xpkM6taCE1vWi3l80fq9KrH6vmeHC114/1RUCfj+hVL+3BOb88WPv5Z8DrXSkjmpTX2u79sx6Gfk+xrf7bqVSv8eLKZAcaelJFHk0nLfg9+1rh/xxBHzO7g9yWKWqnYLsG4W8JiqLvQ8nwv8TZ3JbPzL3owzzDTt2rU7dfPmoJcL13jROKFW5vfX/7OJ77YeDOlkGe4/fqT/iQP9g1Zlu+5y/u3CjS89xYmv2B3Z+CL9e2XfSwEQ5/WhEHFeU957XNHrU5KEIlf8jm5ROy2Zk9s24K0beoeVMERkhar2DLQu1s1QEaOqL+OZr7dnz57x+ymHKdzqarCTbrROFILzz+fWI//EqpCS7NQCvP/QeUVuftqVy0+7ckM6ufo+931tsDJV+T2vyE1ekTus14TyezDhbie/2E1+ceTji8bvlXkvS2ZNCZFqWMUDvj5QoliWPpqmkh3gFY49Wp/fF7wYtfLl2aPOxIOlXr8dCh5vQvLdP1dqm/6O9mSxndJzCbfxLKtxAiWFir5tB/sG5yvaJwflyDdC33/i8r61hXtyNVUT6CQV8ORjytVUstmUcWXUyle0rUDS8/dGZPtw9CeLGcAYEXkXp2M7uyb1V3gTxKrt2UFrA75C/QZnqldVvjHGSrzFa6IvpslCRN7BmQaziYhswxnHPhVAVV/CmU/5fGADzrSM18Um0ugKpdbgK1FO/EkCqclJFBS7Ky4c4LVQubb/eDx5GxNrsb4a6ooK1itwazWFExMut3L1pCV8t/VgubWGaIlVR6fvVSdrduTwWQX9KL4d2YO7teSWZYNIL4hcFdsYU76jvRkqYXlrEzO/38GKzQdKvl1XJUmEe4nd4G4t6drSqcn8tDOXLi2q7/euPpe7DuzagttXDkGSdkNGBQd5EFhY+ffImBols1nENhXzS2ejoWfPnno0D1HuX5sIVygn/q4+V0Ot2ZET9EQddU90gt92R38/xlSXzGZwl88U4RX9jVe1fHkCbSuc1/sp79JZSxYxMHftr9z2zsqQE4VQflKI2Z2/lggSi/dbaARPPia+1Ij7LOLJjztyyAuSKILVGrq1LpsUBnZtUR3hWlKIFDvpmjhmyaIaefspfth2sMxNQ+kpSQzu1oIhv2sZu1pDTUsKdvI2JmSWLKqJt59i5ZaD5BU5tYokOXJl0MltG/DU5SeXJAarNYTITvjGVAtLFtVk/rrdzjhIRUean1KTndrEhSe1shqEl538jTkqWbKoJoH6KQqL3RzbtA5nn9A8+gHEOkFYEjAmrlmyqCYntqpHSnLpkSxrpSXTtVW96O20uhKEJQJjEp4li2qS1bkZ6SlJFLtd4NNPkdU5cjfNlBHpRGFJwZgay5JFNfk1J59DBS4uPaU1HZtkRudKp0jVJCwpGGP8WLKoJrNXOYPl3nZ2Jzo2yYzchi1BGGOqgSWLajJ71U5OaFkvsokCqpYoLEEYY0JkySLKXG7lw2+38e2Wg1xySitcbq1601NVahOWIIwxlWDJIoq8N+It27QfgM9W7+LXnCVhz4tbRriJYpzN3WCMqZqkWAeQyLw34nkvl80rcvPd1oPMX1eN9ztEcIhiY0zNZTWLKAp0I15eoYs1O3LCvxEvnKYna2oyxkSYJYsoOrFVPWqlJZcairzSN+KFkiisuckYEyXWDBVFWZ2b0c0nMdSO5o141txkjIkiq1lEUXKS8Pjwk8h6cj7nndicy3u2De9GvFCanqw2YYypBpYsouy3wmIALjmldfj9FEfryLDGmBrHmqGi7FC+kyzqZqRGfuPW9GSMqSZWs4iyXE+yqJMe5lu9e23wddb0ZIypZpYsouxQgbdmEeJbHet5J4wxJgBrhoqy3PwiAOqEmiwqShTW9GSMiQGrWURZrqdmUa+qfRbW9GSMiSGrWUTZofxiUpKE9JQQ3mq3q+IyxhgTA5Ysoiw3v5i6GSmIhHBvxffvRD8gY4ypBGuGirJDBcUV91dU1Klt/RTGmBizZBFluflF1E2voL8iWKKwfgpjzFHCmqGiLDc/hJqFMcYc5WKeLERkkIisE5ENInJ3gPXtRORLEVkpIj+IyPmxiLOycvOLqWfJwhgT52KaLEQkGfgnMBjoClwhIl39it0PTFPVU4ARwAvVG2XVHCooDv/ubWOMOcrEumbRC9igqhtVtRB4FxjqV0YB7zjf9YEd1RhfleXmF5U/LtSBzYGXW6e2MeYoEuuvvK2BrT7PtwG9/cqMAz4XkduATOCcQBsSkZuBmwHatWsX8UArQ1Urvhrq2zdBkuCOH6BB2+oLzhhjwhDrmkUorgAmq2ob4HzgLREpE7eqvqyqPVW1Z9OmTas9yEAKit0UuTT4uFCuIlg5BY4baInCGHNUi3XNYjvge5Zs41nm6wZgEICqfiMiGUAT4Kgfbc874mzdQH0WvvdWrN8F4+rb3NnGmKNWrGsWy4BOItJRRNJwOrBn+JXZApwNICInABnAnmqNspK8gwgG7LMIdG+FjTZrjDlKxTRZqGoxMAaYA6zFuerpRxF5REQu8hT7K3CTiHwPvANcq6oam4jD4x2e3K6GMsbEu5ifxVR1NjDbb9mDPr+vAc6o7rgioaQZyu6zMMbEuVg3QyW0klnyLFkYY+KcJYso8vZZBJzLIinAMru3whhzlLKvvFEUtM+i8LDzePrtcO74ao7KGGPCZzWLKAraDLV1MbiLoGP/GERljDHhs2QRRYcKislITSI12e9t/uVrSEqBdn1iE5gxxoTJkkUUBR0X6pcF0PpUSK9T/UEZY0wlWLKIotz84rJ3b+dnw45voWO/2ARljDGVYMkiirzzb5ey+RtQN3Q4MzZBGWNMJdjVUFFUZsRZ3/Gg3vTcoG7jQRlj4oDVLKIoN7+o9GWzNh6UMSZOWbKIokP5xeVPfGSMMXEi5GQhIj2iGUgiys23KVWNMYkhnJrFchFZIiLXi0jtqEWUINxu5VBhMfVsXChjTAIIJ1l8AvQAXgF2iMhzIvK76IQV/34rLEbV7+7ttAD3Vdh4UMaYOBDy115VvVBE2gA3AtcDtwJ/EpHFwERgqqoWRCfM+OMdF6pUn0WPa2DFZLh3B4jEJjBjjKmEsDq4VXWbqo4DOgBDceah6AW8jlPbeNozm12NVzIulG+fxb4N0OhYSxTGmLhTqauhVNWtqjNV9UKgI/AIUAjcDqwWkfkiMjyCccadgBMf7dsAjY+NUUTGGFN5kbh0tivQHWgMCLAPOBOYKiIrRKRDBPYRd47Mv+1JFq4iOLDZkoUxJi5VKlmISDMRuVtEfgY+BS4G5gOXAi2A43D6MU4GXohMqPGlTJ/Fgc2gLmh8XAyjMsaYygnruk4RORsYhdNfkQocAJ4BXlTVDT5Ff8Hp/E4HLo9QrHGlTJ/F/p+dx0ZWszDGxJ+Qk4WIrAeOwWlqWo5TY3hXVfPLedl6ILNKEcapQ/59Fvs8udRqFsaYOBROzaI1MBl4QVVXhPiat4Fvwg0qEeTmFyECmWneZPEzZNSH2o1iG5gxxlRCOMmilaoeDGfjqroV2BpeSIkht6CYOmkpJCV5LpPdt8GpVdhls8aYOBRyB3e4iaKmy833G558/0brrzDGxK1wBhK8RUR+FpFWQda39qy/IXLhxa9DvhMfFeVB9lbrrzDGxK1wLp29EtipqjsCrVTV7cA24KpIBBbvcgt85rLY/4vzaPdYGGPiVDjJojPwfQVlfgC6VD6cxFFqLouSK6EsWRhj4lM4yaI+UFG/RQ7QsPLhJI5SfRZ2j4UxJs6Fkyx24gzrUZ7uwJ7Kh5MYXG5l728FbNn3G3PX/op77wZnKPKMerEOzRhjKiWcS2e/BK4Wkb6qutB/pYicCQwGpkQquHjkcitXT1pCTl4xq7bn0P3d35Mk2c7KcfWdx8xmcNf62AVpjDFhCqdm8X84I8v+W0T+LiLnisiJnsengS+AAk+5Gmv+ut18t/VIa11Tb6Lw9dvuaozIGGOqLpz7LNbhjPNUAPwZZwDBHzyPdwD5wGWqujacAERkkIisE5ENInJ3kDKXi8gaEflRRP4Vzvar2487csgrdMU6DGOMiaiwBhJU1U9E5BjgWqA30ACn03sx8Iaq7gtneyKSDPwTGIhz2e0yEZmhqmt8ynQC7gHOUNUDInJUz0N6Yqt6ZKQmk1dkCcMYkzjCShYAnoTwVIT23wvYoKobAUTkXZwRbdf4lLkJ+KeqHvDs/6huw8nq3IwTW9Vj+eYDsQ7FGGMiJhKTH1VFa0qPHbXNs8zX8cDxIrJIRBaLyKBAGxKRm0VkuYgs37MndhdkJScJT152EgDnndicorT6ZQtlHtWVI2OMKSPsmgWAiLTBOamnB1qvql9XJSg/KUAnIAtoA3wtIr/zH6tKVV8GXgbo2bOnRnD/YSt2uwEY0r0Vqb9/Cd69Am76Elr3iGVYxhhTaeFOfnQu8DQV36WdHOImtwNtfZ638SzztQ1YoqpFwC8i8l+c5LEsxH1Uu4JiJ1mkJSfBYU83Tu3GMYzIGGOqJpyBBPsAs3A6tZ/HmQTpa+AV4CfP85nAI2HsfxnQSUQ6ikgaMAKY4VdmOk6tAhFpgtMstTGMfVS7Qk+ySE9Jgrz9zkJLFsaYOBZOn8U9OJfH/l5V7/As+1JVbwG6AY8C5wDvh7pBVS0GxgBzgLXANFX9UUQeEZGLPMXmAPtEZA3OjYF3hXvVVXUr8E0Wh/dBchqk1cgJA40xCSKcZqjTgBl+o84mAaiqAg+KyGDgYWB4qBtV1dnAbL9lD/r8rsBfPD9xwVuzSEtJgsP7nVqFTXpkjIlj4Q4kuMXneSFl59deBPSralDxriBQsjDGmDgWTrLYTekRZXcD/sOopgK1qhpUvDvSZ5HsNEPVsoF4jTHxLZxk8V9KJ4fFwEAROR5ARFoAw4AaP0Jeocu5ezvN28FtNQtjTJwLJ1l8BvQXkUae5//AqUWsFJFlOFdENQWeiWyI8aegyK+D25KFMSbOhZMsJuL0RxQBqOoi4DLgF5yroXYCo1X1zUgHGW8KXd77LIC8A1C7UfkvMMaYo1zIV0Opag6wxG/ZR8BHkQ4q3pVcDVWcC+q2moUxJu6Fc1PeayIyNprBJArv1VAZhZ7BBC1ZGGPiXDjNUFcCNgJeCLzJIrXAkyxqWTOUMSa+hZMsNmHJIiSFxW7SkpOQPG/NwpKFMSa+hZMs/gUMFhG7aaACBcWuI1dCgTVDGWPiXjjJYgKwHPhSRC4QkeZRiinuFRa7PXdve5OF1SyMMfEtnLGh8j2PAnwMIIHHO1JVrdQ8GYniSLLY7xlEsE6sQzLGmCoJ56S+AIjppELxoqDYXfqGPBtE0BgT58K5zyIrinEklFI1C7sSyhiTAGI9B3dCKnS5nUEE8/Zbf4UxJiFYsoiCgmLXkQ5uuxLKGJMAQm6GEpEHKy4FOB3c4ysZT0Lw3mdB7j6rWRhjEkI4Hdzjylnn7fgWz+81OlkUFLupUzvJM4ig1SyMMfEvnGQxIMjyBsDvgduBT4CXqhpUvCssdlNfDtsggsaYhBHO1VBflbP6YxGZCiwF3q1yVHGusNhNI8l1ntjVUMaYBBCxDm5VXYVzs969kdpmvCoodtOAQ84Tq1kYYxJApK+G2oIzEVKNVlDspj45zhPr4DbGJIBIJ4veQF6Etxl3Cotd1FdPM5QlC2NMAgjn0tl25WyjLXAT0BeYFoG44lpBsZu6bm/NwpqhjDHxL5yroTZR/thQAqwH7qxKQPFOVSl0uanrzrZBBI0xCSOcZPEmgZOFGziAcyXUx6paEInA4lWxW1GFTFeOcyWUDSJojEkA4Vw6e20U40gY3ilVaxdnWxOUMSZh2NhQEVZYkiwOWue2MSZhhJwsRORYEblGRAJ+XRaRJp71x0QuvPjjTRYZxdmWLIwxCSOcPou7gYuBd4KszwaeBD4ARlcxrrhVUOxiWfpo6h/KhjUbYVx9Z0VmM7hrfWyDM8aYSgqnGSoL+LeqFgVa6Vn+BXBWBOKKW4XFbppKdtkVv+2u/mCMMSZCwkkWrXEuny3PFqBVOAGIyCARWSciG0Tk7nLKDRMRFZGe4Wy/unk7uI0xJpGEkywKgXoVlKlLGPN0i0gy8E9gMNAVuEJEugYoVxe4A1gScrQxYsnCGJOIwkkWq4EhIpIaaKWIpAEXAGvC2GYvYIOqblTVQpwRa4cGKDce+D8gP4xtx0ShJQtjTAIKJ1lMAdoB00Skhe8Kz/NpOMN+vBnGNlsDW32eb/Ms8912D6Ctqn5S3oZE5GYRWS4iy/fs2RNGCJFV6HJzQAPctZ3ZrPqDMcaYCAnnaqiXgUtxvvkPFJEfgO04J/fuQG3g30Rw8iMRSQL+DlxbUVlVfdkTIz179gy5KSzSCopcjCocy7T08XDNDDimf6xCMcaYiAm5ZqGqbmAI8BhQBPQBhnkeC4H/BYZ4yoVqO05txKuNZ5lXXZwhz+eLyCbPvmYczZ3chS43meJpLbNxoYwxCSKcmoX38th7ReR+oAvOlKoHgZ/CTBJey4BOItIRJ0mMAK702V820MT7XETmA3eq6vJK7KtaFBS5qeMdpT3dkoUxJjGElSy8PIkhnI7sYNspFpExwBwgGXhNVX8UkUeA5ao6o6r7qG6FLje1xTOWYlpmbIMxxpgICWc+i2OBM4BPVHVfgPVNgPOBhaq6MdTtqupsYLbfsgeDlM0KdbuxUljsU7OwZihjTIII52qou4GnwDtfaBne4T7uqmpQ8ayg2EVtrM/CGJNYbLiPCCssdjq4NSUDkivVymeMMUedmA/3kWi8ycJqFcaYRBLT4T4SUUGxm3qSj1jntjEmgcR6uI+EU1Dspk5SAaTXjXUoxhgTMbEe7iPhFLrc1JF8u2zWGJNQjurhPuKRc1NePqTZWFDGmMQR6+E+Ek7JcB9WszDGJJBwmqFQ1SJVvRdojDNmU1/PYxNVvR9wiUigIcZrjMJiF7U1z/osjDEJJSLDfYhIexG5EbgOaIkzdEeNVFDsphbRrVkUFBSwf/9+cnNzcblcUduPMSZ+JScnU7duXRo1akR6enqVt1fpu8Y8s9wNBW4GzsGppShOv0WNVVjkopbmRe0+i4KCArZs2ULDhg3p0KEDqampiEhU9mWMiU+qSlFRETk5OWzZsoV27dpVOWGEnSxE5BjgJpw5Jry9uHuBicAkVd1cpYjinLu4gBRcURtxdv/+/TRs2JAmTZpUXNgYUyOJCGlpaSXnif3799OyZcsqbTOkPgsRSRGRy0TkC+C/wN+AhsCHgAAfq+qDNT1RACQX/eb8EqWaRW5uLvXqVXRvpDHGOOrVq0dubm6Vt1NuzUJEOuHUIv6IM6+EACuAycC/VPWAiNToq5/8JRdHN1m4XC5SUwPeF2mMMWWkpqZGpG+zomaodTj9EL/iTG86WVV/rPJeE1hK8WHnlyh2cFsfhTEmVJE6X4TSDKXAp8AHligqluKtWdgsecaYBFJRsngAZyTZ64BFIrJGRP6fiFStpySBpbq8NQtLFsaYxFFuslDV/1HVY4DBwEfAsTh3cG8RkU9E5PJqiDGupFmyMMYkoJCuhlLVOao6HGegwHuBzTgJ5B2cZqqTReTUqEUZR9Lc3ilVbbiPeLdhwwZEhBtvvLHU8quuugoRYdu2bSFvq02bNhx33HGRDrGUYPEaEwnhDvexW1UfU9XjgIHA+zjjRPUElorIShG5NQpxxgVVJd3tqVnYcB9RMXLkSESEF154of4Dae4AACAASURBVMKy5557LiLCRx99VA2RRV9xcTEiwjnnnBPrUEwNFFay8KWqc1X1D0Ab4P8B64GTgGcjFFvcKXS5yaTAeWLNUFFx0003AfDqq6+WW27Tpk38+9//pmXLllx44YURjeGJJ55g7dq1tGjRouLC1ah9+/asXbuWRx99NNahmARU6WThpap7VfVJVe2CM//2O1UPKz45U6rm4ZZkSKn6WCymrKysLI4//nhWrlzJt99+G7TcpEmTUFWuu+46UlIiOxd6y5Yt6dKlS8S3W1Wpqal06dLlqEtiJjFUOVn4UtX5qnpVJLcZTwqL3WSST1FybYjzeyFcbmXu2l95du565q79FZf76Jkt11u7eOWVVwKud7lcvP7662Xa77dv387DDz/M6aefTosWLUhLS6N169aMHDmSn376KeT9B+uzUFWeffZZunbtSnp6Oq1bt+b2228nJycn4HYOHjzI448/zoABA2jdujVpaWk0a9aMiy++mCVLlpQq++qrr5bcjDl37lxEpOTHW5Mor89ix44djB49mvbt25Oenk6zZs0YNmwYK1euLFP21VdfRUSYMmUKc+fOpX///tSpU4f69etz4YUXsm7dupDfq4KCAp577jkGDx5csu9GjRoxcOBA5syZE/R1W7du5bbbbqNTp05kZGTQuHFjevXqxf/8z/9UqmxFTXiBPlPf93PdunVcdtllNG3alKSkJBYuXAjA8uXLuf322+nevTsNGzYkIyOD448/nrvuuouDBw8GPb533nmHs846i0aNGpGRkUGHDh248sorS74A/fOf/0REAh4vOH/LKSkpnHLKKUH3EWlH11ejOFfgSRaulNqxDqVKXG7l6klL+G7rQfIKXdRKS+bktg1464beJCfFPgn+8Y9/5L777uOdd97hqaeeonbt0u/3p59+yvbt2xk4cCAdO3YsWf7ll1+WnJxPOeUUMjMzWb9+PdOmTWPmzJn85z//oVu3bpWOa8yYMbzwwgu0atWKUaNGkZqayvTp01m6dClFRUVkZGSUKr969Wruv/9++vfvz4UXXkiDBg3YvHkzM2bMYPbs2cyePbvk5NajRw8eeOABxo8fT8eOHbnmmmtKttOvX79y4/r555/p27cvu3bt4pxzzuHKK69ky5YtvPfee3zyySd89NFHDB48uMzrpk+fzscff8z555/P6NGjWb16NbNmzWLZsmWsWbOGRo0aVfie7Nmzhz//+c+cfvrpDBw4kKZNm7Jz505mzJjB4MGDee2117j22mtLvWbJkiUMHjyYAwcOkJWVxaWXXspvv/3GmjVreOSRR7jvvvsqVbay/vvf/9KrVy+6du3KVVddxeHDh6lb1+mTfOmll/jkk0/o168fAwcOxOVysWLFCp588kk+++wzFi9eTGbmkYtdVJWrr76at99+m6ZNm3LppZfStGlTtm7dypdffknXrl3p0aMHV199NXfffTevvvoq99xzD0lJpb/XT5o0CZfLxahRo6p8fKGyZBFB3mao4pTYXAn18MwfWbMj8LfYcBw4XMiG3YfwViYOF7pYvHEfg//xNQ1rp1Vp211b1eOhC0+s0jaaNm3KxRdfzLRp05g2bVqZk423xnHzzTeXWj5w4EB+/fVX6tQp3Z+0cuVK+vbtyz333MPMmTMrFdPXX3/NCy+8QKdOnViyZAkNGzYE4NFHH6V///7s3r275ATj1a1bN3bu3Enjxo1LLd+8eTO9e/dm7NixrFq1CnCSRffu3Rk/fjzHHHMM48aNCzm2m2++mV27dvHYY4/xt7/9rWT5LbfcQlZWFtdccw2bN28uk3Q//vhjvvjiC7KyskqW3XXXXTz55JNMnjyZv/zlLxXuu0mTJmzZsoXWrVuXWn7w4EFOO+007rrrLq644oqSEVELCgq47LLLOHDgAFOnTuXyy0tfne/7zT+cslWxYMECHnjgAR555JEy6x544AEmTpxIcnLpWRkmTpzILbfcwksvvcRf//rXkuUvvvgib7/9Nn369GHOnDmlxnlzuVzs3r0bcMZzGjlyJBMnTuTzzz9n0KBBJeXcbjeTJk2iTp06jBw5MiLHGIqINkPVdN4ObndqfF82e7jAhX+rk1ud5UcLbyLw7+jeuXMns2fPplmzZgwdWnoerubNm5dJFACnnHIK/fv3Z+7cuZUeQ+f1118HnJOHN1EA1KpVi//93/8N+JoGDRqUSRTgdFRfeumlrF69mh07dlQqHq9NmzYxb948OnbsWOqkBXDmmWdy+eWXs3fvXqZPn17mtSNHjiyVKODI+7506dKQ9p+RkVEmUYBz7Ndddx179+5lxYoVJcunT5/O1q1bufTSS8uc/MG5BLkyZauiVatW3H///QHXtW/fvkyiAKepNDMzs0xT23PPPYeIMHHixDIDgiYnJ5caGXb06NGAk3h8ffrpp2zZsoUrrriizBeQaLKaRQQVFDk1C1dqxdXzaKjqN3avuWt/5bZ3VnK48MiJs3ZaMg8PPZGzT2gekX1U1VlnncWxxx7LokWLWLt2LSeccALgnLSLi4u59tprAw64OGPGDCZOnMiKFSvYt28fxcXFpdbv37+fpk2bhh2Pt625f//+Zdb169evTDOC14IFC3j22WdZvHgxu3fvprCwsNT67du306pVq7Dj8fL2SfTr1y9gh/xZZ53Fu+++y8qVK7nyyitLrevZs2eZ8m3btgXgwIEDIcewatUqnnjiCRYuXMiOHTsoKCgotX779u0lvy9evBggYLOYv3DKVsXJJ59MWlrgGnVRUREvvvgiU6dOZc2aNeTk5OB2Hxlb1ffYsrOz+emnn2jdujXdu3evcL8nnXQSp59+OrNmzWLHjh0lfwcvv/wy4NQMq5MliwgqdLnIpACN85pFVudmnNy2QZk+i6zOzSp+cTXxdjzec889vPrqqzz11FOoKpMmTUJESjrBfT311FPceeedNGrUiHPOOYf27dtTq1YtRIQPP/yQVatWlTmRhSo7Oxtwai/+0tLSStU2vN577z1GjBhBrVq1GDhwIMcccwyZmZkkJSUxb948FixYUOl4/OMKNpeBd3mgztgGDRqUWeZNOKHWwBYtWsQ555yD2+3m7LPPZujQodStW5ekpCS+/fZbZs6cWeoYvXEEqo34C6dsVZR3ddmwYcOYOXMmxx57LJdccgnNmzcvaVL7+9//Xulj8/rTn/7Ef/7zHyZNmsQDDzzA9u3b+eSTT+jZsyc9evSo5BFVjiWLCCoodtOEPDTO77FIThLeuqE389ftZs2OHLq2qkdW52ZHRee2r+uuu44HH3yQN998kwkTJrBgwQI2btzIWWedVeZu6aKiIh5++GFatWrFt99+W+akvmDBgirFUr9+fQB+/fVX2rVrV2pdYWEhBw4cKHPyfeCBB8jIyGDFihV07ty51LqtW7dWOSbfuHbt2hVw/c6dO0uVi7Tx48eTn5/PggUL6Nu3b5l1/n1E3vfI9xt5MOGU9dbs/GuSXuVduRRs1NbFixczc+ZMzjvvPGbNmlWq5uZyuZgwYUKl4/UaPnw4Y8eO5dVXX+W+++6LSce2l/VZRFBBsZtMyU+IEWeTk4SzT2jObWd34uwTmh91iQKcb/EXXXRRSZu7t//Cv2MbnJN4bm4uffv2LZMocnJyAl5CGg7vt7yvvvqqzLqvv/66VNOE188//0y3bt3KJAqXy8WiRYvKlPee8MLpV/FeWrlgwYKAr/vyyy9LxR9pGzZsoFmzZmUSBQR+r/r06QM47fIVCadsUlIS9erVY+vWrWXWFRcX8/3331e4DX8bNmwAYOjQoWWa+L755psyTYr169enS5cu7Nixgx9++CGkfaSnp3P99dezZcsWPvnkEyZNmkS9evW44oorwo63qixZRJD3PguJ85pFPPE2Nz311FN89NFHNGnShEsuuaRMuZYtW5Kens6yZcv47bffSpYXFhZy2223hdUGH8h1110HON+Wfb+l5uXlce+99wZ8Tfv27Vm3bl2pb/2qyoMPPhjwXoakpCQaNmzIli1bQo6rQ4cODBgwgJ9//pnnnnuu1LpFixYxdepUGjduXOZigEjp0KEDe/bs4ccfS89uMHHiRObOnVum/MUXX0zbtm358MMPee+998qs973CKZyyAL169WLjxo3Mmzev1PKHH364UldOdejQAYD58+eXWv7rr79y2223BXzN7bffjqoyatSoMvffuFyugDXAUaNGkZSUxOjRo9myZQtXXXVVqctxq0vMm6FEZBDwDyAZeFVVH/Nb/xfgRqAY2ANcf7RO31pUWEgtKeRwAtQs4sW5555Lhw4dSq7OGTNmTMDOyOTkZG677TaefPJJfve733HRRRdRUFDAvHnzyM7Opn///gG/6YaqX79+jB49mhdffJETTzyR4cOHk5KSwvTp02natCnNmpXt7xk7dixjxozh5JNPZtiwYaSkpLBgwQL++9//csEFFzBr1qwyrzn77LN5//33GTp0KKeccgopKSlkZWUF/ObuNXHiRPr27cvYsWP59NNPOfXUU0vus0hJSWHy5MlRO/mMHTuWuXPncvrpp3P55ZdTr149li5dyjfffMOwYcP44IMPSpVPT0/nvffeY9CgQVx++eUMGDCAXr16kZeXx9q1a/n666/Jz88PuyzAnXfeydy5cxkyZAgjRoygYcOGLFq0iC1bttCvXz++/vrrsI7ttNNOo0+fPkybNo1t27ZxxhlnsGvXLmbPnk23bt0C9l/dcsstLFy4kH/961906tSJiy66iKZNm7J9+3bmzZvHqFGjylx51bFjRwYNGsTs2bMBYtIEBTjfZGL1g5MgfgaOAdKA74GufmUGALU9v48Gpla03VNPPVVj4aNv1qg+VE/3f/FU1PaxZs2aqG07Xj366KOKM/qx/vTTT0HLFRUV6eOPP65dunTRjIwMbdGihV599dW6ZcsWHTlypAK6devWkvLr169XQG+44YZS2wlUVlXV5XLpM888o126dNG0tDRt1aqVjhkzRrOzs7V169Z67LHHlolp0qRJ2r17d61Vq5Y2btxYL7nkEl29erXed999CuiCBQtKld+5c6eOGDFCmzZtqklJSQro+PHjy41XVXXr1q06atQobdu2raamppbsa9myZWXKvvLKKwroW2+9FfA9BPTss88O+j77+/jjj7VXr15ap04dbdCggZ577rm6YMGCcvezadMmHTVqlLZv317T0tK0cePG2rt3b50wYUKVyn744Yfao0cPTUtL00aNGukVV1wR9ufva+/evXrLLbdou3btND09XY899li999579fDhw0E/c7fbrW+88YaeeeaZWq9ePc3IyNCOHTvqVVddpStXrgy4n/fff18B7dOnT9BYyhPqeQNYrsHO18FWVMcPcBowx+f5PcA95ZQ/BVhU0XZjlSw+/HKJ6kP1NHvBy1HbhyULY2oe75eHyZMnV+r1kUgWse6zaA349jht8ywL5gacKV7LEJGbRWS5iCzfs2dPBEMMnRYeAiApw4YnN8ZERk5ODhMnTqRJkyb84Q9/iFkcMe+zCJWIXIUzb0bZu54AVX0ZeBmgZ8+esRn1rsBJFim1LFkYY6pm1qxZrFy5ko8//pi9e/fyzDPPlBlfrDrFOllsx5l9z6uNZ1kpInIOcB/QX1WrdpdSNBU6V9mkWs3CGFNF7777Lm+//TYtWrTg/vvvD3qFVXWJdbJYBnQSkY44SWIEUGrMARE5BZgIDFLV3dUfYujE0wyVbDULY0wVTZkyhSlTpsQ6jBIx7bNQ1WJgDDAHWAtMU9UfReQREbnIU+wJoA7wnoh8JyIzYhRuhZKKnGRBmiULY0xiiXXNAlWdDcz2W/agz+9xM+FwUpFn/u20+B4byhhj/MX6aqiEklzsqVnYTXnGmARjySKCkr01izgfddYYY/xZsoigFNdv5JEBQeYuMMaYeGVntQhKKT5MnsTuOmhjjIkWSxYRlOY6TH5S7YoLGmNMnLFkEUFprsMUSK1Yh2GMMRFnySKC0tx5FCRbsjDGJB5LFhGU4T5MoTVD1QiHDh1CRLjgggtiHYox1cKSRQRlaB6FyZYsoklEwvqZPHlyrEM2JiHE/A7uRJKheRRZsoiqhx56qMyyZ555huzsbO644w4aNGhQat3JJ58clTgyMzNZu3YtderYDZimZrBkEUG1NJ/iFEsW0TRu3LgyyyZPnkx2djZ//vOfS+ZFjjYRoUuXLtWyL2OOBtYMFSlPdKIOhzlz3/swrr7z80SnWEdlPHr27EmdOnXIy8vj/vvv57jjjiMtLY0xY8YAsG/fPh577DH69+9Pq1atSEtLo3nz5gwbNowVK1aU2V6wPos777wTEWH58uW8/fbbnHrqqdSqVYsmTZpw9dVXs3t36AMnhxuT16pVq7jmmmto164d6enpNG/enKysLF577bVKlV29ejUiUvJe+fO+t75mzZqFiPDkk0+ycOFCzjvvPBo2bIiIsHfvXgA+//xzrr/+erp06ULdunWpXbs23bt3Z8KECRQVFQXcV1FREc899xx9+vShXr161K5dm+OPP55Ro0axefNmAG677TZEpMz83l5fffUVIsKIESOCvoemLKtZRMpvAU4CgZbFiyc6lY0/sxnctT428USA2+3mggsuYN26dZx33nk0btyY9u3bA7By5UoeeughsrKyGDp0KPXr1+eXX35hxowZzJo1iy+++IJ+/fqFvK/HH3+cWbNmMXToUAYMGMCiRYuYMmUKq1evZvny5SQnJ1e4jcrE9P777zNy5EhcLhdDhgyha9eu7N+/n5UrV/L0009z/fXXV6psZc2bN4977rmHs846ixtvvJFdu3aRkuKcdh555BF27dpF7969GTp0KIcOHWLBggXce++9LFy4sCTheB0+fJjzzjuPhQsX0rFjR6655hoyMzP55ZdfmDZtGgMHDqR9+/aMHj2a559/npdffplhw4aViWnixIkA3HLLLVU+vprEkkUi+fRu2LUqMtsKlvxeH1K17bb4HQx+rGrbqKS8vDxyc3NZvXp1mb6NHj16sGvXLho2bFhq+c8//0zv3r3561//yrJly0Le19y5c/nuu+84/vjjAWeu+4svvpgZM2YwZ84czj///Aq3EW5M27Zt45prriEpKYkFCxbQq1evUq/btm1bpcpWxaeffsqUKVMYOXJkmXVvvvkmxxxzTJnlY8eO5ZlnnmH27NkMGXLk7+3uu+9m4cKFXH755UyZMoXU1NSSdXl5eRw+7IzN1rVrV/r3788XX3zBxo0bS+1j3759fPjhh3Tu3JmsrKyIHGNNYc1QpkaZMGFCmUQB0KhRozInZYBjjz2Wiy66iOXLl7N///6Q93PXXXeVJApw+jhuvPFGAJYuXRrSNsKNadKkSeTl5fGXv/ylzMkfoE2bNpUqWxV9+/YNmCiAgIkCnGQBMGfOnJJl+fn5vPLKK9SrV49//vOfpRIFQK1atWjcuHHJ89GjR6OqvPLKK6XKTZ48mYKCAm6++eZKHU9NZjWLCHC5lYobFapBJL+xj6sfePl1n0RuHzEQ6MTo9eWXX/Lcc8+xdOlSdu/eXabdfPv27TRq1Cik/fTs2bPMsrZtnRmEDxw4EHK84cS0ePFiAAYPHlzhdsMpWxXlvd85OTk8/fTTfPzxx2zYsIFDhw6hqiXrt28/MsPy999/T35+PmeccQZNmjSpcL+XXnopLVq04PXXX+eRRx4pSS6vvPIKGRkZXHvttZU/qBrKkkUEzF+3m76aQroUl1pekNGE9BjFZMqqXbs2desGnsVwypQpXHPNNdSpU4eBAwfSsWNHMjMzERE+//xzvvnmGwoKQp/+PVDtxdtW73K5QtpGuDEdPHgQgNatW1e47XDKVkWLFi0CLs/Pz6dv376sWrWKk046iSuvvJLGjRuTmppKYWEhEyZMqPSxAaSmpnLjjTfy6KOPMn36dC677DK++uor1q1bx1VXXRVy0jdHWLKIgB935NCVeix2ncDYolsBEOAvZx5PbKdYr4LMZoE7uOOYb2epv/vvv5+6deuycuXKMs0j69ev55tvvol2eFWOyZugtm/fTseOHcvddjhlkzxD7hcXFwdc7z2RBxLsPX/33XdZtWoVt956K88//3ypdevXr2fChAlB4w3VzTffzIQJE5g4cSKXXXZZScf2qFGjQt6GOcL6LCLglEaFtJT9rHZ3KFlWKy2Zrq3qxS6oqrprPYzLLv0Tx1dClae4uJjNmzdz8sknlzkpFxUVxSRRVCamPn36AE6nckXCKevtN9m6dWuZdXv37mXTpk0VbsPfhg0bAAJerfTVV1+VWXbSSSdRq1Ytli1bVnLpbUXatm3LBRdcwLx581iyZAkffvghJ554In379g07XmPJIiI6Fjl/+D9xDALUTkvm5LYNyOoc39/Ea4qUlBRat27Njz/+WOpE5Ha7ueeee/jll1/iIqYbb7yRWrVq8fe//z1gJ7rvFU7hlG3ZsiVt2rRh7ty5bNy4sWR5UVERt99+e8jNar68N0/Onz+/1PJ169bxwAMPlCmfkZHBTTfdRE5ODmPGjClTy8nPz2ffvn1lXuft6B42bBgFBQVWq6gCa4aKgFXLv6INMGLoEPrkptC1VT2yOjcjOSl4s4c5uowdO5Y777yT7t27c+mll5KUlMRXX33Fpk2bGDx4cEjfwGMdU+vWrXnjjTcYOXIkp59+OhdccAFdu3bl4MGDfPfdd+Tm5rJq1aqwy4Jzddcdd9xB7969GT58OMnJycydO5e0tDS6dOkSsNZRnuHDh/PII48wfvx4li9fTrdu3di0aRMzZ87koosuYurUqWVeM2HCBFasWMHUqVNZunQpQ4YMITMzk82bNzNnzhxefvllhg8fXuo15557LscddxwbNmygVq1aXH311WHFaXyoasL9nHrqqVodil1unbpsi352/9m6c/wJWuxyR32fa9asifo+4k379u0V0F9++SVomVNPPVUzMzODrne73frSSy9pt27dtFatWtqkSRMdPny4/vTTT/rXv/5VAV22bFlJ+dzcXAV0yJAhpbYTqKzXqlWrFNBbb701pOMKNyavlStX6ogRI7RFixaampqqzZs31wEDBujkyZOrVPb555/Xzp07a2pqqrZs2VJvvfVWPXjwYMD3dubMmQroE088EfT4fv75Z73sssu0RYsWmpGRod26ddNnnnlGs7OzA763qqr5+fn61FNPaY8ePbR27dqamZmpxx9/vI4ePVo3b94ccD+PPvqoAnrttdcGjSXRhXreAJZrkPOqqM+laomiZ8+eunz58qjuw+VWrp60hKW/7Gd+6m38oJ2Y0nYcb93QO6o1irVr13LCCSdEbfvGJJrhw4fzwQcfsHjxYnr37h3rcGIi1POGiKxQ1bLXfWN9FpU2f91uVm45SB13Dm1kL9+5OvDd1oPMXxfHQ3wYk2DWr1/P9OnT6dmzZ41NFJFifRaV9OOOHPKKXJyatAmA1dqRvEIXa3bkcPYJzWMbnDE13BtvvMHGjRuZMmUKLpeL8ePHxzqkuGfJopI6t3Bu7vqdOFelrHZ3iP/LZY1JEM899xwrV66kXbt2vPTSSwwaNCjWIcU9SxaVVFjkBqB78ia2uJtSnFbfLpc15igR7T7LmsiSRSW9uXgTKzL+RGOcu1fX8AfYDjwV38N4G2NMINbBHSaXW3lt4S8s23SgJFGUEs9zWBhjTBBWswjA5Vbmr9vNjztyONHnBjuXW8l9tCPXuw9wfUbs4lPVcsc5MsYYr0jdHmHJwsObIFZtz2bO6l1s3n+YvEIXS9NHkyzZACQDZccSrV7JyckUFRWRlpYW40iMMfGgqKgopJkZKxLzZCEig4B/4JyLX1XVx/zWpwNvAqcC+4A/qOqmSMbgrTGc7T7A2cCfwWmgi2HtIZi6deuSk5MT0pj+xhiTk5MTdGj+cMS0z0JEkoF/AoOBrsAVItLVr9gNwAFVPQ54Gvi/SMcxf91uGrhDn5CmXFEexrtRo0YcOHCAvXv3UlhYGLEqpjEmcagqhYWF7N27lwMHDkRk/o5Y1yx6ARtUdSOAiLwLDAXW+JQZCozz/P4+8LyIiEbwLPnjjhzOrupGxmVHIpQKpaen065dO/bv38+mTZsqNeKnMSbxJScnU7duXdq1a0d6etWnYYt1smgN+A5XuQ3wvye/pIyqFotINtAYKDWovYjcDNwM0K5du7CCOLGqN9JV86RA6enptGzZkpYtW1brfo0xNVesk0XEqOrLwMvgDCQYzmvDvZFOM5shdi+FMaYGiXWy2A609XnexrMsUJltIpIC1Mfp6I6Y5CRxEkA590j8ltqIxZcutnkqjDE1UqyTxTKgk4h0xEkKI4Ar/crMAP4IfAMMB+ZFsr/Cq6KaQiZUvV/DGGPiVEyThacPYgwwB+fS2ddU9UcReQRnEo4ZwCTgLRHZAOzHSSjGGGOqUaxrFqjqbGC237IHfX7PBy6r7riMMcYcYWNDGWOMqZAlC2OMMRWyZGGMMaZCkojDRYjIHmBzJV/eBL8b/mqImnjcNfGYoWYed008Zgj/uNuratNAKxIyWVSFiCxX1Z6xjqO61cTjronHDDXzuGviMUNkj9uaoYwxxlTIkoUxxpgKWbIo6+VYBxAjNfG4a+IxQ8087pp4zBDB47Y+C2OMMRWymoUxxpgKWbIwxhhTIUsWPkRkkIisE5ENInJ3rOOJBhFpKyJfisgaEflRRO7wLG8kIl+IyHrPY8NYxxppIpIsIitFZJbneUcRWeL5vKeKSFqsY4w0EWkgIu+LyE8islZETqshn/VYz9/3ahF5R0QyEu3zFpHXRGS3iKz2WRbwsxXHs55j/0FEeoS7P0sWHiHOB54IioG/qmpXoA9wq+c47wbmqmonYK7neaK5A1jr8/z/gKc987sfwJnvPdH8A/hMVbsAJ+Ecf0J/1iLSGrgd6Kmq3XBGtB5B4n3e0lZhnQAABjNJREFUk4FBfsuCfbaDgU6en5uBF8PdmSWLI0rmA1fVQsA7H3hCUdWdqvqt5/dcnJNHa5xjfcNT7A3g4thEGB0i0gYYArzqeS7AWTjzukNiHnN9oB/OMP+oaqGqHiTBP2uPFKCWZ8K02sBOEuzzVtWvcaZt8BXssx0KvKmOxUADEQlrXmZLFkcEmg+8dYxiqRYi0gE4BVgCNFfVnZ5Vu4DmMQorWp4B/h/g9jxvDBxU1WLP80T8vDsCe4DXPc1vr4pIJgn+WavqduBJYAtOksgGVpD4nzcE/2yrfH6zZFFDiUgd4APgz6qa47vOMxNhwlxTLSIXALtVdUWsY6lmKUAP4EVVPQX4Db8mp0T7rAE87fRDcZJlK5yJLv2baxJepD9bSxZHhDIfeEIQkVScRPG2qn7oWfyrt1rqeQw+IXn8OQO4SEQ24TQvnoXTlt/A00wBifl5bwO2qeoSz/P3cZJHIn/WAOcAv6jqHlUtAj7E+RtI9M8bgn+2VT6/WbI4omQ+cM9VEiNw5v9OKJ62+knAWlX9u88q71zneB4/ru7YokVV71HVNqraAedznaeqI4EvceZ1hwQ7ZgBV3QVsFZHOnkVnA2tI4M/aYwvQR0Rqe/7evced0J+3R7DPdgZwjeeqqD5Atk9zVUjsDm4fInI+Ttu2dz7w/4lxSBEnIn2BBcAqjrTf34vTbzENaIczvPvlqurfeRb3RCQLuFNVLxCRY3BqGo2AlcBVqloQy/giTUROxunUTwM2AtfhfElM6M9aRB4G/oBz9d9K4EacNvqE+bxF5B0gC2cY8l+Bh4DpBPhsPUnzeZzmuMPAdaq6PKz9WbIwxhhTEWuGMsYYUyFLFsYYYypkycIYY0yFLFkYY4ypkCULY4wxFbJkYUwcE5FxIqKeS4KNiRpLFqZG85xoK/rJinWcxsRaSsVFjKkRHi5n3abqCsKYo5UlC2MAVR0X6xiMOZpZM5QxYfDtIxCRP3qG/s7zzFj2moi0CPK6TiLypohsF5FCEdnhed4pSPlkEblFRBaJSLZnHxs8w4wHe81wEVkqIodFZL+IvOuZCMiYKrOahTGVMxY4F5gKfAb0xRl3KUtEeqvqHm9BEfk98G+gLs6AbmuALsBVwFAROUdVl/mUTwNmAQNx5iD4F5ADdAAuARYC6/3i+RNwkWf7XwG9ccZGOklETo7nMZDM0cGShTE4NYYgq/JV9bEAywcDvVV1pc82ngb+DDyGZ8pOzwBubwL1cAaue9un/B9wBrZ7S0S6qqp3YMdxOIliJnCZ74leRNI92/I3CPi9qq7yKfsv4AqcuR2mBT14Y0JgAwmaGk1EKvoHyFbVBj7lx+GM7vmaqpaaw9kzjelmIB1ooKoFInIGTk3gG1U9PcD+F+DUSvqr6teeueD34YwSe5yq7qggfm88/6Oq9/utGwDMA55S1TsrOE5jymV9FsYAqipBfhoEeclXAbaRDXwHZAAneBb38DzOC7Id7/JTPI9dgPrADxUlCj+Bhpv2TqPZMIztGBOQJQtjKufXIMt3eR7r+z0Gm2jGu7yB32O4s7gdDLDMO990cpjbMqYMSxbGVE7zIMu9V0Nl+z0GvEoKaOlXznvSt6uYzFHFkoUxldPff4Gnz+JkIB9Y61ns7QDPCrKdAZ7Hbz2PP+EkjO4i0ioikRoTAZYs/n87d6gSQRQFYPg/RfABjGazyaJBMFgEg2BSqy8giAgKPoBNjLZFiwqCwWLQYLPupk0GsWkS5BjuCMOGvbiKlv+DCTNzhplb5nDnnjPSaNYiYnrg2D7ls1OnVcF0D3SB2YhYaQc3+3NAj7IITmZ+AEfAOHDcVD+1rxmLiIlfHotUZemsxNDSWYCLzHwcOHYN3EfEGWXdYbbZ+sD2V1BmZkRsADfAaURcUmYPU8Ay8Aqst8pmofx6ZAZYAnoRcdXETVJ6O7aAk5EGKo3IZCEVe0PO9SlVTm2HwDmlr2IVeKO8wHcy87kdmJkPTWPeLrBASQIvQAc4yMzuQPx7RCwCm8A6sAEE8NTc8+77w5N+xj4L6RtafQ3zmXn7v08j/R3XLCRJVSYLSVKVyUKSVOWahSSpypmFJKnKZCFJqjJZSJKqTBaSpCqThSSp6hM5le3FmsqBSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot training & validation loss values\n",
    "#plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_key_hat_accuracy'],marker='o',markersize=5)\n",
    "plt.plot(history.history['key_hat_accuracy'],marker='s',markersize=5)\n",
    "\n",
    "plt.title('Model accuracy',fontsize=20)\n",
    "plt.ylabel('Accuracy',fontsize=20)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.legend(['Validation accuracy','Train accuracy'],fontsize=20)#Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.021733039823894337\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ext Rate:   0.839703822293376\n",
      "Error: 0.08749249549729837\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(X_test_all[0:4997]).reshape((-1, sample_size, 1))\n",
    "key_options = selecting_valid_fingerprints(key_length=key_length)  # we use 100 keys.\n",
    "test_keys = np.array(get_keys_for_fingerprinting_data(size=n_test, key_options=key_options))\n",
    "noise_for_test = np.squeeze(noise_for_test)\n",
    "pred = model_10.predict([x_test, test_keys, array_mult_test, array_sub_test, noise_for_test])\n",
    "\n",
    "fingerprint_x22, keys_true = pred[0], pred[1]\n",
    "ext_rate = compute_extract_rate(keys_true, true_keys=test_keys)\n",
    "\n",
    "print(\"Ext Rate:  \", ext_rate)\n",
    "#28% with 75, with 150 it is 0.41, with 225, we go to 0.43\n",
    "error = bit_rate_error(keys_true,test_keys)\n",
    "print('Error:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = np.array(noise_for_test[0:n_test]).reshape((-1, sample_size, 1))\n",
    "fing_ipds = fingerprint_x22 + x_test\n",
    "non_fing_ipds = noise + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ext Rate:   0.04700940188037608\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(X_test_all[0:n_test-1]).reshape((-1, sample_size, 1))\n",
    "key_options = selecting_valid_fingerprints(key_length=key_length)  # we use 100 keys.\n",
    "test_keys = np.array(get_keys_for_fingerprinting_data(size=n_test, key_options=key_options))\n",
    "noise_for_test = np.squeeze(noise_for_test)\n",
    "pred = model_10.predict([x_test, test_keys, array_mult_test, array_sub_test, noise_for_test])\n",
    "\n",
    "fingerprint_x22, keys_true = pred[0], pred[1]\n",
    "ext_rate = compute_extract_rate(keys_true, true_keys=test_keys)\n",
    "\n",
    "print(\"Ext Rate:  \", ext_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "We have 0.947 ext_rate when we have 300 pkt, 200, 000 training data and 250 epochs (loss comes down to 0.18), and\n",
    "key_size is 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Time to Fit the Model 22027.91614151001, is ~6 hours.\n",
    "Ext Rate:   1.0 when 1000000 traiing wiht key_length = 500\n",
    "\n",
    "Same thing with key_length = 1000 is : It stoped before finishing, but it would be 1 since the loss reduced after 16\n",
    " epochs to 0.1 in epoch 30.    \n",
    "#### try the sample_size = 600....\n",
    ".9838 with 200, 000 training data and key_length = 1000\n",
    "%88 with 200000 training data and sample size = 300, key Length =1000, epoch = 50\n",
    "for the sample size 200 to work, we need 200 epochs. since it is improving 0.01 in each epoch after we reach epoch\n",
    "= 75. Or maybe we needed more training data. (we were using 200K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alpha =25\n",
    "#pkt = 10,  ext_rate = 0.701, key_length = 20, epoch = 100, n_train = 5000\n",
    "#usiing uniform (0,alpha) for fingerprint same parameters as above line: ext_rate: 0.54\n",
    "\n",
    "Time to Fit the Model 2291.7441816329956 = 2291/3600 = 36 minutes?\n",
    "Ext Rate:   0.978 with 10000 training and 20 keys, with 20,000 it goes to ext_rate = 1\n",
    "    10000 training and 200 key  ext_rate =0.019\n",
    "    with 20000 and 200 key ext_rate =0.53\n",
    "    and with 40, 000 it goes to ext_rate = 1\n",
    ".\n",
    "\n",
    "#n_train = 24000 with key_length = 200, epoch = 50, pkt  =100 , ext_rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fingerprints_for_ipds(n_train, sample_size, alpha):\n",
    "    \n",
    "    #Previous one was all + and the largest value was 50.\n",
    "   \n",
    "    fingerprint_output = []\n",
    "    thrshold = 100\n",
    "    while len(fingerprint_output) < n_train:\n",
    "        finger = [0]#[random.uniform(0, 250)]\n",
    "        neg_numbers = 0\n",
    "        delay = 0\n",
    "        for i in range(sample_size - 1):\n",
    "            #if random.randrange(0, 3) == 0:\n",
    "            rnd = random.randrange(0, 2)\n",
    "            if rnd == 1 and delay < thrshold:\n",
    "                finger.append(alpha)\n",
    "            elif rnd ==1 and delay>= thrshold:\n",
    "                finger.append(-alpha)\n",
    "                \n",
    "            elif rnd == 0 and delay <= 0 and  delay >-thrshold: # random.randrange(0, 2) == 0:# and np.abs(delay) <50:\n",
    "                finger.append(-1 * alpha)#\n",
    "            elif rnd ==0 and delay <=0 and delay <=-thrshold:\n",
    "                finger.append(alpha)\n",
    "            elif rnd == 0 and delay > 0:\n",
    "                finger.append(-1 * alpha)\n",
    "            delay += finger[-1]\n",
    "            #print(delay)\n",
    "            if sum(finger) < 0:\n",
    "                neg_numbers += 1\n",
    "#             else:\n",
    "#                 finger.append(0) \n",
    "        #if neg_numbers < 50:  ## this can be a hyperparameter\n",
    "        fingerprint_output.append(finger)\n",
    "    return fingerprint_output\n",
    "\n",
    "\n",
    "\n",
    "y = get_fingerprints_for_ipds(1, 1500, alpha=25) \n",
    "y = np.expand_dims(y, axis=1).reshape((-1, 1500, 1))\n",
    "y = adjust_fingerprint_delays(y)\n",
    "avg_d, max_d = compute_delay_on_packets(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_fingerprint_delays(fingerprint_x2):\n",
    "    number_of_train, sample_size = len(fingerprint_x2), len(fingerprint_x2[0])\n",
    "    for f in range(0, len(fingerprint_x2)):\n",
    "            delay, min_delay = 0, 0\n",
    "            for p in range(0, len(fingerprint_x2[f])):\n",
    "                    delay += fingerprint_x2[f][p][0]\n",
    "                    #print(delay)\n",
    "                    if delay < min_delay:\n",
    "                        min_delay = delay \n",
    "            fingerprint_x2[f][0][0] -= 1.001 * min_delay\n",
    "           # print(\"min\",min_delay)\n",
    "           # break\n",
    "    return fingerprint_x2\n",
    "\n",
    "def compute_delay_on_packets(fingerprint_x2):\n",
    "#######Compute the average delay on each packet.        \n",
    "    average_delay = []\n",
    "    max_d, pos = 0, 0\n",
    "    for fing in fingerprint_x2:\n",
    "        delay, neg = 0, 0\n",
    "        delays = []\n",
    "        for n in fing:\n",
    "            delay += n[0]\n",
    "            if delay > max_d:\n",
    "                max_d = delay\n",
    "            delays.append(delay)\n",
    "\n",
    "            if delay < 0:\n",
    "                neg += 1\n",
    "        if neg == 0:\n",
    "            pos += 1\n",
    "            average_delay.append(sum(delays)/sample_size)\n",
    "   # print(sum(delays)/sample_size,\" Average Delay\")\n",
    "   # print(sample_size, number_of_train)\n",
    "    print(\"Negative delay: \",pos, \"Average delay for them:\",sum(average_delay)/pos, \"Max Delay: \", max_d)\n",
    "    return sum(average_delay)/pos, max_d\n",
    "fingerprint_x2 = adjust_fingerprint_delays(fingerprint_x2)\n",
    "avg_d, max_d = compute_delay_on_packets(fingerprint_x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(x_test),sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_for_test = np.array(noise_for_test[0:n_test]).reshape((-1, sample_size, 1))\n",
    "fingerprinted_ipds =  x_test + noise_for_test+ fingerprint_x22 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    target = open(\"/home/fatemeh/MyProjects/Fingerprint/KS/fing/lap_\" + str(i) + \".txt\", 'w')\n",
    "    array = fingerprinted_ipds[i]#x_test[i] + fingerprint_x22[i]\n",
    "    array = np.squeeze(array)\n",
    "    write_array_to_file(array, target, \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: I want to check to see if I 0 the negative fingerprints, I can have the same extraction rate.\n",
    "model_decoder = load_decoder(key_length, sample_size)\n",
    "#model_decoder.set_weights(model.get_weights())\n",
    "beg_time = time.time()\n",
    "i = 0\n",
    "for layer in model_10.layers:\n",
    "  #  w_target=layer.get_weights()\n",
    "    for dec_layer in model_decoder.layers:\n",
    "        if layer.name ==dec_layer.name:\n",
    "            print(layer.name, i)\n",
    "            dec_layer.set_weights(layer.get_weights())\n",
    "    i += 1\n",
    "print(\"Time it takes to load the decoder: \", time.time() - beg_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fingerprinted_ipds():\n",
    "    path = '/home/fatemeh/MyProjects/Fingerprint/encoder/ext_ipds/'\n",
    "    all_ipds = []\n",
    "    for i in range(11):\n",
    "        string_ipds = read_from_file(path + str(i) + \".txt\").split(\" \")\n",
    "        ipds = convert_stringArrays_to_floatArray(string_ipds)\n",
    "        all_ipds.append(ipds)\n",
    "    return all_ipds\n",
    "all_ipds = read_fingerprinted_ipds()\n",
    "fingerprinted_ipds=np.array(all_ipds).reshape((-1, sample_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "noise_for_test = np.squeeze(noise_for_test)\n",
    "noise_for_test = get_noise_simulation_array(n_test, std=1, sample_size=sample_size)\n",
    "noise_for_test=np.array(noise_for_test[0:n_test]).reshape((-1, sample_size, 1))\n",
    "fingerprinted_ipds = fingerprint_x2 + x_test + noise_for_test\n",
    "'''\n",
    "\n",
    "\n",
    "key_hat = model_decoder.predict(fingerprinted_ipds)\n",
    "ext_rate = compute_extract_rate(key_hat, true_keys=test_keys)\n",
    "print(ext_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# avg_d, max_d = compute_delay_on_each_packet(fingerprint_x2)\n",
    "rate=100\n",
    "with open('sep_results.csv', mode='a') as csv_file:\n",
    "    fieldnames = ['sample_size', 'key_length', \"number_training\", 'ext_rate', 'average_delay', 'max_delay',\n",
    "                  'packet_rate', 'std', 'max_train_noise','date']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    #writer.writeheader()\n",
    "    writer.writerow(\n",
    "        {'sample_size': sample_size, 'key_length': key_length, \"number_training\": n_true_train, 'ext_rate': ext_rate,\n",
    "         'average_delay': avg_d, 'max_delay': max_d, 'packet_rate': rate, 'std': std, 'max_train_noise': max_fing_delay,'date': datetime.datetime.now()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(X_train[0][0:100])\n",
    "# print(fingerprint_x2[0][0:100])\n",
    "array_mult_test2, array_sub_test2, noise_for_test2 = get_arrays_mult_noise_sub(10,max_delay=5,chunk=10,std=5,sample_size=sample_size)\n",
    "\n",
    "d = 0\n",
    "import numpy as np\n",
    "for f in noise_for_test2:\n",
    "    dd = []\n",
    "    for p in f:\n",
    "        dd.append(p)\n",
    "    std = np.std(dd, axis=0)\n",
    "    print(std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "    Ext Rate:   0.9986 for key_length = 20\n",
    "    5000 52.243792017179196 1500 Max Delay:  194.5090960264206\n",
    "\n",
    "    Ext Rate:   0.9594 for key_length = 100\n",
    "    5000 115.39134879171382 1500 Max Delay:  560.9818127155304\n",
    "\n",
    "    Ext Rate:   0.9344\n",
    "    5000 240.32056540118285 1500 Max Delay:  1266.3458748834673\n",
    "\n",
    "    Ext Rate:   0.709,    key_len = 500\n",
    "    92.47834091258049\n",
    "    1500 5000\n",
    "    5000 84.65399134224361 1500 Max Delay:  459.50667464733124\n",
    "\n",
    "    Ext Rate: 0.5602, key_len = 1000\n",
    "    28.44295782939593\n",
    "    1500 5000\n",
    "    5000 53.95885500007159 1500 Max Delay:  244.45183670520782\n",
    "'''\n",
    "\n",
    "'''\n",
    "Noise is uniform in these experiments:\n",
    "maxDelay = 5, rate =100\n",
    "    std = 1\n",
    "        Ext Rate:   1.0\n",
    "        34.646455238024394\n",
    "        1500 4000\n",
    "        4000 45.05813633905002 1500 Max Delay:  209.10854732990265\n",
    "    std = 5\n",
    "        Ext Rate:   1.0\n",
    "        22.97654592792193\n",
    "        1500 4000\n",
    "        4000 36.03301963561987 1500 Max Delay:  146.38326346874237\n",
    "    std = 100\n",
    "        Ext Rate:   0.0485\n",
    "        29.65366893227895\n",
    "        1500 4000\n",
    "        4000 28.555992046196685 1500 Max Delay:  157.52952599525452\n",
    "maxDelay =100, rate =100\n",
    "    std = 100\n",
    "        Ext Rate:   0.9985\n",
    "        422.7813040936788\n",
    "        1500 4000\n",
    "        4000 557.8424517351626 1500 Max Delay:  2539.529760360718   \n",
    "      \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ext_rate = compute_extract_rate(keys_true, true_keys = test_keys)\n",
    "\n",
    "print(\"Ext Rate:  \", ext_rate)\n",
    "compute_delay_on_each_packet(fingerprint_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "n_false_train = 0\n",
    "x_fing_w, key_hat_w, epoch, batch = 1, 200, 50, 64\n",
    "\n",
    "beg_time = time.time()\n",
    "key_length = 100\n",
    "key_options = selecting_valid_fingerprints(key_length = key_length)\n",
    "sample_sizes = [1500, 1800]#, 600, 1200]\n",
    "#models = []\n",
    "trains = [60000, 10000]\n",
    "for sam in sample_sizes:\n",
    "    sample_size = sam\n",
    "    X_train_all = create_sample_size_dataset(all_ipds_for_train, sample_size = sample_size)\n",
    "    X_test_all = create_sample_size_dataset(all_ipds_for_test, sample_size = sample_size)\n",
    "    print(len(X_train_all),len(X_test_all), \"Numbre of training and testing data\")\n",
    "    model = get_encoder_decoder_conv_dense_slice(sample_size=sample_size, key_length=key_length, chunk=10)\n",
    "    ad = optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad=False)\n",
    "\n",
    "    model.compile(optimizer=ad, loss={'fingerprint':mean_pred_loss, 'key_hat': losses.categorical_crossentropy},\n",
    "                                    loss_weights={'fingerprint': x_fing_w, 'key_hat': key_hat_w})\n",
    "    X_train, y_train, train_keys = get_false_true_data(X_train_all, key_options)#get_only_true_data\n",
    "    train_keys = np.array(train_keys)\n",
    "    n_test = 4000\n",
    "    for t in trains:\n",
    "        # model.summary()\n",
    "        beg_time = time.time()\n",
    "        array_mult_train, array_sub_train, noise_for_train = get_arrays_mult_noise_sub(t,max_delay=5,chunk=10,std=1,sample_size=sample_size)\n",
    "        model.fit([X_train[0:t], train_keys[0:t], array_mult_train[0:t], array_sub_train[0:t], \n",
    "                   noise_for_train[0:t]], [y_train[0:t], train_keys[0:t]], epochs=epoch,\n",
    "                  validation_split=0.1, batch_size=batch,verbose =1)#, validation_split=0.1,callbacks=callbacks_list, verbose=0)\n",
    "\n",
    "        print(\"Time to Fit the Model\", time.time() - beg_time)\n",
    "        models.append(model) \n",
    "        array_mult_test, array_sub_test, noise_for_test = get_arrays_mult_noise_sub(n_test,max_delay=5,chunk=10,std=1,sample_size=sample_size)\n",
    "\n",
    "        #### This is when we test encoder and decoder together using the same model: model_encoder_decoder\n",
    "        x_test = np.array(X_test_all[0:n_test]).reshape((-1, sample_size, 1))\n",
    "        key_options = selecting_valid_fingerprints(key_length = key_length)# we use 100 keys.\n",
    "        test_keys = np.array(get_keys_for_fingerprinting_data(size=n_test, key_options=key_options))\n",
    "        noise_for_test = np.squeeze(noise_for_test[0:n_test])\n",
    "        pred = model.predict([x_test, test_keys, array_mult_test, array_sub_test, noise_for_test])\n",
    "\n",
    "        fingerprint_x2, keys_true = pred[0],  pred[1]\n",
    "        ext_rate = compute_extract_rate(keys_true, true_keys = test_keys)\n",
    "\n",
    "        print(\"Ext Rate:  \", ext_rate)\n",
    "        compute_delay_on_each_packet(fingerprint_x2)\n",
    "'''\n",
    "\n",
    "    size = 1800\n",
    "    Ext Rate:   0.992\n",
    "    4000 95.84566262555747 1800 Max Delay:  415.03377401828766\n",
    "    Ext Rate:   0.9765\n",
    "    4000 93.27346397158448 1800 Max Delay:  380.78301668167114\n",
    "    \n",
    "    \n",
    "    size 1200\n",
    "    \n",
    "    Ext Rate:   0.948\n",
    "    4000 72.26921833757295 1200 Max Delay:  357.55537247657776\n",
    "\n",
    "    Ext Rate:   0.943\n",
    "    4000 72.2022527100891 1200 Max Delay:  356.89986884593964\n",
    "    \n",
    "    size = 600\n",
    "    Ext Rate: 0.788\n",
    "    4000 38.018    max delay: 235.928\n",
    "    \n",
    "    size 600, and 10000 training:\n",
    "    Ext Rate:   0.731\n",
    "    4000 37.918288900979874 600 Max Delay:  233.056\n",
    "    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_test = 5000\n",
    "print(sample_size)\n",
    "array_mult_test, array_sub_test, noise_for_test = get_arrays_mult_noise_sub(n_test,max_delay=5,chunk=10,std=1,sample_size=sample_size)\n",
    "\n",
    "x_test = np.array(X_test_all[0:n_test]).reshape((-1, sample_size, 1))\n",
    "key_options = selecting_valid_fingerprints(key_length = 200)# we use 100 keys.\n",
    "test_keys = np.array(get_keys_for_fingerprinting_data(size=n_test, key_options=key_options))\n",
    "noise_for_test = np.squeeze(noise_for_test[0:n_test])\n",
    "pred = model.predict([x_test, test_keys, array_mult_test, array_sub_test, noise_for_test])\n",
    "\n",
    "fingerprint_x2, keys_true = pred[0],  pred[1]\n",
    "ext_rate = compute_extract_rate(keys_true, true_keys = test_keys)\n",
    "\n",
    "print(\"Ext Rate:  \", ext_rate)\n",
    "compute_delay_on_each_packet(fingerprint_x2)\n",
    "'''\n",
    "sample size = 1800, n_train = 10000, and key = 100:\n",
    "1800\n",
    "Ext Rate:   0.0842\n",
    "52.90532826509741\n",
    "1800 4444\n",
    "4444 47.894631279740935 1800 Max Delay:  182.74153697490692\n",
    "when we only change n_train = 60000:\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def decide_if_fingerprinted(keys, threshold):\n",
    "    fing = 0\n",
    "    for key in keys:\n",
    "        index = np.argmax(key)\n",
    "        if key[index] > threshold and index > 0:\n",
    "            fing += 1\n",
    "    return fing / float(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Loading encoder takes too much time (hours), so we just use the model_encoder_decoder for encoding.\n",
    "model_decoder = load_decoder(key_length, sample_size)\n",
    "decoder_weights = []\n",
    "j = 0\n",
    "for i in range(0, 24):\n",
    "    if 'dec' in model.layers[-(24 - i)].name or 'key_hat' in model.layers[-(24 - i)].name:\n",
    "        model_decoder.layers[j].set_weights(model.layers[-(24 - i)].get_weights())\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_for_test = noise_for_test.reshape((-1, sample_size, 1))\n",
    "\n",
    "output_fin = noise_for_test[0:n_test] + x_test\n",
    "keys_true_fp = model_decoder.predict([output_fin])\n",
    "\n",
    "###### True positve:\n",
    "output_fin = noise_for_test[0:n_test] + x_test + fingerprint_x2\n",
    "\n",
    "keys_true_tp = model_decoder.predict([output_fin])\n",
    "ext_rate = compute_extract_rate(keys_true_tp, test_keys)\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "\n",
    "\n",
    "for t in thresholds:\n",
    "    fp = decide_if_fingerprinted(keys_true_fp, t)\n",
    "    tp = decide_if_fingerprinted(keys_true_tp, t)\n",
    "    \n",
    "    print(fp, tp)\n",
    "print(ext_rate, 'Extraction Rate')\n",
    "'''\n",
    "\n",
    "key = 100 training with 1/100 number of false data. sample size = 1800, number of training=20000\n",
    "0.2395 0.9845\n",
    "0.156 0.9695\n",
    "0.093 0.9535\n",
    "0.043 0.931\n",
    "0.014 0.8975\n",
    "0.0055 0.867\n",
    "0.0005 0.766\n",
    "0.9685 Extraction Rate\n",
    "Ext Rate:   0.969\n",
    "1800 2000\n",
    "2000 138.32507355565957 1800 Max Delay:  556.0820367336273\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "sample size 3300, training data = 48000, key = 1000\n",
    "\n",
    "0.293 0.9925\n",
    "0.1925 0.98\n",
    "0.115 0.9685\n",
    "0.0655 0.941\n",
    "0.022 0.905\n",
    "0.007 0.8525\n",
    "0.0 0.734\n",
    "0.9695 Extraction Rate\n",
    "2000 80.0513701567251 3300 Max Delay:  369.6583148241043\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_false_train = 0\n",
    "x_fing_w, key_hat_w, epoch, batch = 1, 200, 100, 64\n",
    "model_name = str(sample_size) + \"_\" + str(key_length) + \"_\" + str(\n",
    "    n_true_train) + \"_\" + str(n_false_train) + \"_\" + str(epoch) + \"_\" + str(x_fing_w) + \"_\" + str(key_hat_w)\n",
    "\n",
    "beg_time = time.time()\n",
    "#models_key_length = []\n",
    "keys = [100]\n",
    "n_true_train = 30000\n",
    "for k in keys:\n",
    "\n",
    "    key_options = selecting_valid_fingerprints(key_length = k)# we use 100 keys.\n",
    "    X_train, y_train, train_keys = get_false_true_training(X_train_all[0:n_true_train], key_options)\n",
    "    train_keys = np.array(train_keys)\n",
    "    print(\"Finished radinf\")\n",
    "\n",
    "    model= get_encoder_decoder_conv_dense_slice(sample_size=sample_size, key_length=k)\n",
    "    #losses.mean_squared_error\n",
    "    ad = optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad=False)\n",
    "\n",
    "    model.compile(optimizer=ad, loss={'fingerprint':mean_pred_loss, 'key_hat': losses.categorical_crossentropy},\n",
    "                                    loss_weights={'fingerprint': x_fing_w, 'key_hat': key_hat_w})\n",
    "\n",
    "\n",
    "    # model.summary()\n",
    "    print(\"Model %s is Built and Compiled in %f\" % (model_name ,time.time() - beg_time))\n",
    "    beg_time = time.time()\n",
    "\n",
    "    model.fit([X_train, train_keys, array_mult_train[0:n_true_train], array_sub_train[0:n_true_train], noise_for_train[0:n_true_train]], [y_train, train_keys], epochs=epoch, validation_split=0.1, batch_size=batch)#, validation_split=0.1,callbacks=callbacks_list, verbose=0)\n",
    "\n",
    "    print(\"Time to Fit the Model\", time.time() - beg_time)\n",
    "\n",
    "    \n",
    "    models_key_length.append(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_for_results = '/home/fatemeh/Dropbox/Fingerprint/Results/'\n",
    "def compute_ROC_data(n_train):\n",
    "    target_name = open(path_for_results + str(n_train)+\"_\" + str(sample_size)+\"_\"+str(key_length) + '.txt', 'w')\n",
    "    sample_size = 900\n",
    "    key_length = 100\n",
    "    n_test = 5000\n",
    "    thresholds = [0.6, 0.7, 0.8, 0.9]\n",
    "    X = create_sample_size_dataset(all_ipds, sample_size = sample_size)\n",
    "    key_options = selecting_valid_fingerprints(key_length = key_length)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    model_decoder, model_encoder = load_model_for_testing(key_length, sample_size, n_train)\n",
    "    X_test = np.expand_dims(X[n_train:n_train + n_test], axis=1)\n",
    "    test_keys = np.expand_dims(get_fingerprint_for_data(size = n_test, key_options = key_options), axis=1)\n",
    "    fingerprint_x = model_encoder.predict([test_keys])\n",
    "    false_poses, true_poses = [], []\n",
    "    \n",
    "     ########## True positve:\n",
    "    output_fin = add_gussian_noise_to_ipds_fingerprinted(fingerprint = fingerprint_x, x_test = X_test, std =10)\n",
    "    keys_true = model_decoder.predict([output_fin])\n",
    "\n",
    "    ########## False positve: \n",
    "    output_non = add_gussian_noise_to_ipds_non_fingerprinted(X_test, std =10)\n",
    "    keys_false = model_decoder.predict([output_non])\n",
    "    for t in thresholds:\n",
    "        true_pos = decide_if_fingerprinted(keys_true, threshold = t)\n",
    "        false_pos = decide_if_fingerprinted(keys_false, threshold = t)\n",
    "        false_poses.append(false_pos)\n",
    "        true_poses.append(true_pos)\n",
    "        \n",
    "    write_array_to_file(array = false_poses, target =target_name, delimiter =' ')\n",
    "    write_array_to_file(array = true_poses, target =target_name, delimiter =' ')\n",
    "    target_name.close()\n",
    "    \n",
    "compute_ROC_data(n_train=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_impact_of_jitter():\n",
    "    sample_size = 600\n",
    "    key_length = 10\n",
    "    n_train = 50000\n",
    "    n_test = 5000\n",
    "    X = create_sample_size_dataset(all_ipds, sample_size = sample_size)\n",
    "    key_options = selecting_valid_fingerprints(key_length = key_length)\n",
    "\n",
    "    target_name = open(path_for_results + str(n_train)+\"_\" + str(sample_size)+\"_\"+str(key_length) + '.txt', 'w')\n",
    "\n",
    "    jitters = [1, 10, 50, 100]\n",
    "   \n",
    "    model_decoder, model_encoder = load_model_for_testing(key_length, sample_size, n_train)\n",
    "    X_test = np.expand_dims(X[n_train:n_train + n_test], axis=1)\n",
    "    test_keys = np.expand_dims(get_fingerprint_for_data(size = n_test, key_options = key_options), axis=1)\n",
    "    fingerprint_x = model_encoder.predict([test_keys])\n",
    "    false_poses, true_poses, ext_rates = [], [], []\n",
    "\n",
    "    for std in jitters:      \n",
    "        ########## True positve:\n",
    "        output_fin = add_gussian_noise_to_ipds_fingerprinted(fingerprint = fingerprint_x, x_test = X_test, std =std)\n",
    "        keys_true = model_decoder.predict([output_fin])\n",
    "        true_pos = decide_if_fingerprinted(keys_true, threshold=4)\n",
    "        key_pred = extract_keys_from_key_hat(keys_true)\n",
    "        error_rate = compute_error_rate_flowwise(predict_key = key_pred, true_key = test_keys)\n",
    "\n",
    "        ########## False positve: \n",
    "        output_non = add_gussian_noise_to_ipds_non_fingerprinted(X_test, std =std)\n",
    "        keys_false = model_decoder.predict([output_non])\n",
    "        false_pos = decide_if_fingerprinted(keys_false, threshold=4)\n",
    "        false_poses.append(false_pos)\n",
    "        true_poses.append(true_pos)\n",
    "        ext_rates.append(1 - error_rate)\n",
    "    write_array_to_file(array = ext_rates, target =target_name, delimiter =' ')\n",
    "    write_array_to_file(array = false_poses, target =target_name, delimiter =' ')\n",
    "    write_array_to_file(array = true_poses, target =target_name, delimiter =' ')\n",
    "    target_name.close()\n",
    "# compute_impact_of_jitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_fing_w, key_hat_w, epoch = 1, 50, 100\n",
    "def call_fit_load_eval_Main():\n",
    "    n_all_true_trains =[5000]# [5000, 10000, 20000, 50000]#5000,, \n",
    "    sample_sizes = [600]#[400, 200, 600]\n",
    "    key_lengths = [10]#, 15, 20]\n",
    "\n",
    "    for sample_size in sample_sizes:\n",
    "        X = create_sample_size_dataset(all_ipds, sample_size = sample_size)\n",
    "        for key_length in key_lengths:\n",
    "            key_options = selecting_valid_fingerprints(key_length = key_length)\n",
    "            false_poses, true_poses, ext_rates = [], [], []\n",
    "            target_name = open(path_for_results + str(sample_size)+\"_\"+str(key_length) + '.txt', 'w')\n",
    "\n",
    "            for train_number in n_all_true_trains:\n",
    "                false_pos, true_pos, ext_rate = fit_model_load_evaulte(n_true_train =train_number, key_length=key_length, sample_size=sample_size,X=X,key_options=key_options)\n",
    "                false_poses.append(false_pos)\n",
    "                true_poses.append(true_pos)\n",
    "                ext_rates.append(ext_rate)\n",
    "                print(false_pos, true_pos, ext_rate)\n",
    "            write_array_to_file(array = ext_rates, target =target_name, delimiter =' ')\n",
    "            write_array_to_file(array = false_poses, target =target_name, delimiter =' ')\n",
    "            write_array_to_file(array = true_poses, target =target_name, delimiter =' ')\n",
    "            target_name.close()\n",
    "call_fit_load_eval_Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reload_model_for_more_epochs():\n",
    "    sample_size, key_length, n_true_train, epoch = 600, 10, 50000, 250\n",
    "    n_false_train = int(n_true_train/10)\n",
    "    x_fing_w, key_hat_w = 1, 50\n",
    "    model_name = \"march_10\" + str(sample_size) + \"_\" + str(key_length) + \"_\" + str(\n",
    "    n_true_train) + \"_\" + str(n_false_train) + \"_\" + str(epoch) + \"_\" + str(x_fing_w) + \"_\" + str(key_hat_w)\n",
    "\n",
    "    model = load_NN_model(path + model_name)\n",
    "    model_encoder_decoder.compile(optimizer='adam', \n",
    "                              loss=losses.mean_absolute_error,\n",
    "                                  loss_weights={'fingerprint':x_fing_w, 'key_hat':key_hat_w})\n",
    "\n",
    "    model_encoder_decoder.fit([X_train, training_keys], [y_train, training_keys],\n",
    "                        batch_size = 64, epochs = epoch + 250, verbose = 0)\n",
    "    #save_model_weights(model_encoder_decoder, name=model_name)\n",
    "# reload_model_for_more_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_all_Main():\n",
    "    n_all_true_trains = [10000]# 5000, 10000, 20000, 50000]\n",
    "    sample_sizes = [600]\n",
    "    key_lengths = [10]\n",
    "    x_fing_w, key_hat_w, epoch = 1, 50, 100\n",
    "    n_test = 1000\n",
    "    for sample_size in sample_sizes:\n",
    "            \n",
    "            X = create_sample_size_dataset(all_ipds_for_test, sample_size = sample_size)\n",
    "            for key_length in key_lengths:\n",
    "                key_options = selecting_valid_fingerprints(key_length = key_length)\n",
    "                false_poses, true_poses, ext_rates = [], [], []\n",
    "                #target_name = open('/home/fatemeh/Dropbox/Fingerprint/Results/500_' + str(sample_size)+\"_\"+str(key_length) + '.txt', 'w')\n",
    "\n",
    "                for train_number in n_all_true_trains:\n",
    "                    model_decoder, model_encoder = load_model_for_testing(key_length, sample_size, train_number)\n",
    "                    false_pos, true_pos, ext_rate = evalute_encoder_decoder(model_decoder,model_encoder, X, sample_size, key_length,\n",
    "                                                                            key_options, train_number, int(train_number/10), n_test=n_test)\n",
    "                    false_poses.append(false_pos)\n",
    "                    true_poses.append(true_pos)\n",
    "                    ext_rates.append(ext_rate)\n",
    "                    print(sample_size, key_length, train_number, \"Result: \", false_pos, true_pos, ext_rate)\n",
    "#                 write_array_to_file(array = ext_rates, target =target_name, delimiter =' ')\n",
    "#                 write_array_to_file(array = false_poses, target =target_name, delimiter =' ')\n",
    "#                 write_array_to_file(array = true_poses, target =target_name, delimiter =' ')\n",
    "#                 target_name.close() \n",
    "load_test_all_Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_true_trains = [5000, 10000, 20000, 50000, 100000]\n",
    "sample_size, key_length = 600, 10\n",
    "epoch = 250\n",
    "for n_true_train in n_true_trains:\n",
    "    n_false_train = int(n_true_train/10)\n",
    "    key_hat_w, x_hat_w = 50, 1\n",
    "    model_name = \"march10_\" + str(sample_size) + \"_\" + str(key_length) + \"_\" + str(\n",
    "        n_true_train) + \"_\" + str(n_false_train) + \"_\" + str(epoch) + \"_\" + str(x_hat_w) + \"_\" + str(key_hat_w)\n",
    "\n",
    "    model = load_NN_model(path + model_name)\n",
    "\n",
    "    X_train, y_train, training_keys = get_false_true_training(n_true_train, n_false_train, key_length, X, key_options)\n",
    "    print(\"Finished reading dataset\")\n",
    "\n",
    "    model.compile(optimizer='adam', \n",
    "                                  loss=losses.mean_absolute_error,\n",
    "                                      loss_weights={'fingerprint':1, 'key_hat':50})\n",
    "    model.fit([X_train, training_keys], [y_train, training_keys],\n",
    "                            batch_size = 64, epochs = epoch, verbose = 0)\n",
    "    \n",
    "    model_name = \"march10_\" + str(sample_size) + \"_\" + str(key_length) + \"_\" + str(\n",
    "        n_true_train) + \"_\" + str(n_false_train) + \"_\" + str(500) + \"_\" + str(x_hat_w) + \"_\" + str(key_hat_w)\n",
    "\n",
    "    save_model_weights(model, name= model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_encoder(key_length, sample_size):\n",
    "    chunk, p = 10, 0\n",
    "    Input_ipd = Input(shape=(sample_size, 1), name='input1')  # this is needed just for the decoding\n",
    "    Input_key = Input(shape=(key_length,), name='input2')\n",
    "    fingerprint_mult = Input(shape=(chunk,), name='input3')\n",
    "    fingerprint_sub = Input(shape=(chunk,), name='input4')\n",
    "    \n",
    "    ipd = Flatten(name =\"ipd_flatten1\")(Input_ipd)\n",
    "    outputs = []\n",
    "    \n",
    "    quant = int(sample_size/chunk)\n",
    "    def slice(x):\n",
    "        return x[:, p * chunk:(1 + p) * chunk]\n",
    "    \n",
    "    key1 = Dense(32, name='key1')(Input_key)\n",
    "\n",
    "    sliced_ipd = Lambda(slice)(ipd)\n",
    "    x_fingerprint = sliced_ipd\n",
    "    for i in range(0, quant):\n",
    "        sliced_ipd = Lambda(slice)(ipd)\n",
    "        ss = Concatenate(name = 'concat'+ str(p))([x_fingerprint, sliced_ipd]) \n",
    "        ipd1 = Dense(32, name = 'dense'+ str(p))(ss)\n",
    "        batch_2 = BatchNormalization(name = 'batch'+ str(p))(ipd1)\n",
    "        relu_2 = Activation('relu', name = 'act'+ str(p))(batch_2)\n",
    "        \n",
    "        ipds_merged_all = Concatenate(name = 'concat_key_'+ str(p))([relu_2, key1])\n",
    "        dense_enc1 = Dense(64, name = 'dense_enc1' + str(p))(ipds_merged_all)\n",
    "        batch_2 = BatchNormalization(name = 'batch2_'+ str(p))(dense_enc1)\n",
    "        relu_2 = Activation('relu', name = 'act2_'+ str(p))(batch_2)\n",
    "        dense_drop_enc1 = Dropout(0.3, name = 'dense_drop_enc1' + str(p))(relu_2)\n",
    "        \n",
    "        x_fingerprint_sig = Dense(chunk, name = 'fingerprint_sig' + str(p), activation = 'sigmoid')(dense_drop_enc1)\n",
    "        x_fingerprint_mult = Multiply(name = 'fingerprint_mult' + str(p))([x_fingerprint_sig, fingerprint_mult])\n",
    "        x_fingerprint = Add(name = 'ipd_delay' + str(p))([x_fingerprint_mult, fingerprint_sub])\n",
    "        outputs.append(x_fingerprint)\n",
    "        p += 1\n",
    "    x_fingerprint = Concatenate(name = 'fingerprint2')(outputs)\n",
    "    x_fingerprint_output = Reshape((sample_size,1), name='fingerprint')(x_fingerprint)\n",
    "    model_encoder = Model(inputs=[Input_key,Input_ipd,  fingerprint_mult, fingerprint_sub], outputs=[x_fingerprint_output])\n",
    "    #model_encoder.load_weights(filepath=path + model_name + \".h5\", by_name=True)\n",
    "    return model_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
